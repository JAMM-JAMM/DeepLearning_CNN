{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ac1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527d98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86f319b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bostonDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c245f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "print(bostonDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4483447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
      "        4.9800e+00],\n",
      "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
      "        9.1400e+00],\n",
      "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
      "        4.0300e+00],\n",
      "       ...,\n",
      "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        5.6400e+00],\n",
      "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
      "        6.4800e+00],\n",
      "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        7.8800e+00]]), 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
      "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
      "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
      "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
      "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
      "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
      "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
      "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
      "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
      "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
      "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
      "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
      "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
      "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
      "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
      "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
      "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
      "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
      "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
      "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
      "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
      "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
      "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
      "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
      "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
      "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
      "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
      "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
      "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
      "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
      "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
      "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
      "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
      "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
      "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
      "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
      "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
      "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
      "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
      "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
      "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
      "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
      "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
      "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
      "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
      "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
      "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'), 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\", 'filename': '/Users/jamm/miniforge3/envs/tf/lib/python3.9/site-packages/sklearn/datasets/data/boston_house_prices.csv'}\n"
     ]
    }
   ],
   "source": [
    "print(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc333013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bostonDF['PRICE'] = boston.target\n",
    "print(bostonDF.shape)\n",
    "bostonDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e4805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_update_weights_value(bias, w1, w2, rm, lstat, target, learning_rate=0.01):\n",
    "    \n",
    "    N = len(target)\n",
    "    \n",
    "    predicted = w1 * rm + w2 * lstat + bias\n",
    "    \n",
    "    diff = target - predicted\n",
    "    \n",
    "    bias_factors = np.ones((N,))\n",
    "    \n",
    "    w1_update = -(2/N)*learning_rate*(np.dot(rm.T, diff))\n",
    "    w2_update = -(2/N)*learning_rate*(np.dot(lstat.T, diff))\n",
    "    bias_update = -(2/N)*learning_rate*(np.dot(bias_factors.T, diff))\n",
    "    \n",
    "    mse_loss = np.mean(np.square(diff))\n",
    "    \n",
    "    return bias_update, w1_update, w2_update, mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb0e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(features, target, iter_epochs=1000, verbose=True):\n",
    "    w1 = np.zeros((1, ))\n",
    "    w2 = np.zeros((1, ))\n",
    "    bias = np.zeros((1, ))\n",
    "    print('최초 w1, w2, bias: ', w1, w2, bias)\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    rm = features[:, 0]\n",
    "    lstat = features[:, 1]\n",
    "    \n",
    "    for i in range(iter_epochs):\n",
    "        bias_update, w1_update, w2_update, loss = get_update_weights_value(bias, w1, w2, rm, lstat, target, learning_rate)\n",
    "        w1 = w1 - w1_update\n",
    "        w2 = w2 - w2_update\n",
    "        bias = bias - bias_update\n",
    "        if verbose:\n",
    "            print('Epoch: ', i+1, '/', iter_epochs)\n",
    "            print('w1: ', w1, 'w2: ', w2, 'bias: ', bias, 'loss: ', loss)\n",
    "            \n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ccee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57750527 0.08967991]\n",
      " [0.5479977  0.2044702 ]\n",
      " [0.6943859  0.06346578]\n",
      " ...\n",
      " [0.65433991 0.10789183]\n",
      " [0.61946733 0.13107064]\n",
      " [0.47307913 0.16970199]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])\n",
    "print(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7533207c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최초 w1, w2, bias:  [0.] [0.] [0.]\n",
      "Epoch:  1 / 1000\n",
      "w1:  [0.252369] w2:  [0.10914761] bias:  [0.45065613] loss:  592.1469169960474\n",
      "Epoch:  2 / 1000\n",
      "w1:  [0.4982605] w2:  [0.21458377] bias:  [0.8890071] loss:  564.6567515182813\n",
      "Epoch:  3 / 1000\n",
      "w1:  [0.73785103] w2:  [0.31641055] bias:  [1.315389] loss:  538.6424811965484\n",
      "Epoch:  4 / 1000\n",
      "w1:  [0.97131229] w2:  [0.41472723] bias:  [1.73012873] loss:  514.0245946883915\n",
      "Epoch:  5 / 1000\n",
      "w1:  [1.1988113] w2:  [0.50963037] bias:  [2.13354428] loss:  490.72786471250174\n",
      "Epoch:  6 / 1000\n",
      "w1:  [1.42051052] w2:  [0.60121392] bias:  [2.52594493] loss:  468.6811172230454\n",
      "Epoch:  7 / 1000\n",
      "w1:  [1.63656797] w2:  [0.68956922] bias:  [2.90763152] loss:  447.81701302090454\n",
      "Epoch:  8 / 1000\n",
      "w1:  [1.84713735] w2:  [0.77478516] bias:  [3.27889669] loss:  428.07184113172934\n",
      "Epoch:  9 / 1000\n",
      "w1:  [2.05236818] w2:  [0.85694818] bias:  [3.64002506] loss:  409.3853233168043\n",
      "Epoch:  10 / 1000\n",
      "w1:  [2.25240586] w2:  [0.93614234] bias:  [3.9912935] loss:  391.700429116892\n",
      "Epoch:  11 / 1000\n",
      "w1:  [2.44739187] w2:  [1.01244944] bias:  [4.3329713] loss:  374.9632008615359\n",
      "Epoch:  12 / 1000\n",
      "w1:  [2.63746378] w2:  [1.08594902] bias:  [4.66532042] loss:  359.1225881068813\n",
      "Epoch:  13 / 1000\n",
      "w1:  [2.82275543] w2:  [1.15671846] bias:  [4.98859562] loss:  344.1302909940069\n",
      "Epoch:  14 / 1000\n",
      "w1:  [3.00339699] w2:  [1.22483301] bias:  [5.30304476] loss:  329.9406120471257\n",
      "Epoch:  15 / 1000\n",
      "w1:  [3.17951508] w2:  [1.29036588] bias:  [5.60890888] loss:  316.510315956918\n",
      "Epoch:  16 / 1000\n",
      "w1:  [3.35123288] w2:  [1.35338828] bias:  [5.90642246] loss:  303.7984969187526\n",
      "Epoch:  17 / 1000\n",
      "w1:  [3.51867017] w2:  [1.41396946] bias:  [6.19581358] loss:  291.76645311874114\n",
      "Epoch:  18 / 1000\n",
      "w1:  [3.68194348] w2:  [1.47217679] bias:  [6.47730407] loss:  280.37756798249774\n",
      "Epoch:  19 / 1000\n",
      "w1:  [3.84116617] w2:  [1.52807579] bias:  [6.75110972] loss:  269.5971978222294\n",
      "Epoch:  20 / 1000\n",
      "w1:  [3.99644848] w2:  [1.58173021] bias:  [7.01744043] loss:  259.3925655374141\n",
      "Epoch:  21 / 1000\n",
      "w1:  [4.14789765] w2:  [1.63320202] bias:  [7.27650034] loss:  249.7326600428979\n",
      "Epoch:  22 / 1000\n",
      "w1:  [4.29561799] w2:  [1.68255154] bias:  [7.52848803] loss:  240.58814111581867\n",
      "Epoch:  23 / 1000\n",
      "w1:  [4.43971097] w2:  [1.72983741] bias:  [7.77359668] loss:  231.9312493693882\n",
      "Epoch:  24 / 1000\n",
      "w1:  [4.58027526] w2:  [1.77511669] bias:  [8.01201415] loss:  223.7357210772968\n",
      "Epoch:  25 / 1000\n",
      "w1:  [4.71740688] w2:  [1.81844487] bias:  [8.24392319] loss:  215.9767075873894\n",
      "Epoch:  26 / 1000\n",
      "w1:  [4.85119919] w2:  [1.85987591] bias:  [8.46950157] loss:  208.63069907734152\n",
      "Epoch:  27 / 1000\n",
      "w1:  [4.98174302] w2:  [1.89946232] bias:  [8.68892219] loss:  201.67545241838855\n",
      "Epoch:  28 / 1000\n",
      "w1:  [5.10912671] w2:  [1.93725517] bias:  [8.90235322] loss:  195.0899229257653\n",
      "Epoch:  29 / 1000\n",
      "w1:  [5.2334362] w2:  [1.97330412] bias:  [9.10995826] loss:  188.85419978643986\n",
      "Epoch:  30 / 1000\n",
      "w1:  [5.35475506] w2:  [2.00765749] bias:  [9.31189642] loss:  182.94944496600834\n",
      "Epoch:  31 / 1000\n",
      "w1:  [5.47316461] w2:  [2.04036227] bias:  [9.50832248] loss:  177.3578354072935\n",
      "Epoch:  32 / 1000\n",
      "w1:  [5.58874391] w2:  [2.07146416] bias:  [9.69938699] loss:  172.062508343289\n",
      "Epoch:  33 / 1000\n",
      "w1:  [5.7015699] w2:  [2.10100763] bias:  [9.88523637] loss:  167.04750955664886\n",
      "Epoch:  34 / 1000\n",
      "w1:  [5.8117174] w2:  [2.12903592] bias:  [10.06601306] loss:  162.29774442696143\n",
      "Epoch:  35 / 1000\n",
      "w1:  [5.91925918] w2:  [2.15559109] bias:  [10.24185561] loss:  157.79893161560156\n",
      "Epoch:  36 / 1000\n",
      "w1:  [6.02426604] w2:  [2.18071405] bias:  [10.41289877] loss:  153.53755924604891\n",
      "Epoch:  37 / 1000\n",
      "w1:  [6.12680682] w2:  [2.20444461] bias:  [10.57927363] loss:  149.50084344521488\n",
      "Epoch:  38 / 1000\n",
      "w1:  [6.22694852] w2:  [2.22682145] bias:  [10.74110768] loss:  145.676689118568\n",
      "Epoch:  39 / 1000\n",
      "w1:  [6.32475628] w2:  [2.24788225] bias:  [10.89852494] loss:  142.05365283870015\n",
      "Epoch:  40 / 1000\n",
      "w1:  [6.42029347] w2:  [2.26766361] bias:  [11.05164604] loss:  138.6209077334609\n",
      "Epoch:  41 / 1000\n",
      "w1:  [6.51362172] w2:  [2.28620115] bias:  [11.20058832] loss:  135.36821026592287\n",
      "Epoch:  42 / 1000\n",
      "w1:  [6.604801] w2:  [2.30352952] bias:  [11.3454659] loss:  132.2858688042469\n",
      "Epoch:  43 / 1000\n",
      "w1:  [6.69388962] w2:  [2.31968242] bias:  [11.48638979] loss:  129.364713885006\n",
      "Epoch:  44 / 1000\n",
      "w1:  [6.7809443] w2:  [2.33469263] bias:  [11.62346799] loss:  126.59607007872516\n",
      "Epoch:  45 / 1000\n",
      "w1:  [6.86602023] w2:  [2.34859203] bias:  [11.75680551] loss:  123.9717293713085\n",
      "Epoch:  46 / 1000\n",
      "w1:  [6.94917108] w2:  [2.36141163] bias:  [11.88650453] loss:  121.48392597967883\n",
      "Epoch:  47 / 1000\n",
      "w1:  [7.03044904] w2:  [2.37318159] bias:  [12.01266441] loss:  119.12531252435281\n",
      "Epoch:  48 / 1000\n",
      "w1:  [7.1099049] w2:  [2.38393125] bias:  [12.13538181] loss:  116.88893748584081\n",
      "Epoch:  49 / 1000\n",
      "w1:  [7.18758806] w2:  [2.39368915] bias:  [12.25475075] loss:  114.76822387569831\n",
      "Epoch:  50 / 1000\n",
      "w1:  [7.26354655] w2:  [2.40248304] bias:  [12.37086268] loss:  112.75694905678354\n",
      "Epoch:  51 / 1000\n",
      "w1:  [7.3378271] w2:  [2.41033993] bias:  [12.48380655] loss:  110.84922565080183\n",
      "Epoch:  52 / 1000\n",
      "w1:  [7.41047519] w2:  [2.41728606] bias:  [12.59366889] loss:  109.03948347455372\n",
      "Epoch:  53 / 1000\n",
      "w1:  [7.48153501] w2:  [2.42334699] bias:  [12.70053386] loss:  107.32245244945985\n",
      "Epoch:  54 / 1000\n",
      "w1:  [7.55104957] w2:  [2.42854755] bias:  [12.80448331] loss:  105.69314643192291\n",
      "Epoch:  55 / 1000\n",
      "w1:  [7.61906072] w2:  [2.43291192] bias:  [12.90559687] loss:  104.14684791491104\n",
      "Epoch:  56 / 1000\n",
      "w1:  [7.68560913] w2:  [2.43646359] bias:  [13.00395199] loss:  102.67909355382201\n",
      "Epoch:  57 / 1000\n",
      "w1:  [7.7507344] w2:  [2.43922542] bias:  [13.09962401] loss:  101.28566047221524\n",
      "Epoch:  58 / 1000\n",
      "w1:  [7.81447501] w2:  [2.44121965] bias:  [13.1926862] loss:  99.96255330539252\n",
      "Epoch:  59 / 1000\n",
      "w1:  [7.87686843] w2:  [2.44246792] bias:  [13.28320984] loss:  98.70599194207213\n",
      "Epoch:  60 / 1000\n",
      "w1:  [7.93795106] w2:  [2.44299125] bias:  [13.37126426] loss:  97.5123999265428\n",
      "Epoch:  61 / 1000\n",
      "w1:  [7.99775836] w2:  [2.4428101] bias:  [13.4569169] loss:  96.37839348571094\n",
      "Epoch:  62 / 1000\n",
      "w1:  [8.05632477] w2:  [2.44194439] bias:  [13.54023334] loss:  95.30077114737185\n",
      "Epoch:  63 / 1000\n",
      "w1:  [8.11368382] w2:  [2.44041347] bias:  [13.62127739] loss:  94.27650391784937\n",
      "Epoch:  64 / 1000\n",
      "w1:  [8.16986812] w2:  [2.43823616] bias:  [13.70011112] loss:  93.30272598886572\n",
      "Epoch:  65 / 1000\n",
      "w1:  [8.22490938] w2:  [2.43543078] bias:  [13.77679487] loss:  92.37672594512593\n",
      "Epoch:  66 / 1000\n",
      "w1:  [8.27883846] w2:  [2.43201514] bias:  [13.85138738] loss:  91.49593844563864\n",
      "Epoch:  67 / 1000\n",
      "w1:  [8.33168537] w2:  [2.42800657] bias:  [13.92394574] loss:  90.65793635324842\n",
      "Epoch:  68 / 1000\n",
      "w1:  [8.3834793] w2:  [2.42342191] bias:  [13.99452553] loss:  89.86042328822937\n",
      "Epoch:  69 / 1000\n",
      "w1:  [8.43424863] w2:  [2.41827757] bias:  [14.06318075] loss:  89.10122658309236\n",
      "Epoch:  70 / 1000\n",
      "w1:  [8.48402099] w2:  [2.41258948] bias:  [14.12996399] loss:  88.37829061698744\n",
      "Epoch:  71 / 1000\n",
      "w1:  [8.53282324] w2:  [2.40637315] bias:  [14.19492636] loss:  87.68967050925002\n",
      "Epoch:  72 / 1000\n",
      "w1:  [8.58068151] w2:  [2.39964367] bias:  [14.25811759] loss:  87.03352615273884\n",
      "Epoch:  73 / 1000\n",
      "w1:  [8.62762121] w2:  [2.39241569] bias:  [14.31958604] loss:  86.4081165686587\n",
      "Epoch:  74 / 1000\n",
      "w1:  [8.67366708] w2:  [2.38470349] bias:  [14.37937877] loss:  85.81179456554575\n",
      "Epoch:  75 / 1000\n",
      "w1:  [8.71884315] w2:  [2.37652095] bias:  [14.43754153] loss:  85.24300168602741\n",
      "Epoch:  76 / 1000\n",
      "w1:  [8.76317283] w2:  [2.36788157] bias:  [14.49411885] loss:  84.70026342585105\n",
      "Epoch:  77 / 1000\n",
      "w1:  [8.80667886] w2:  [2.35879847] bias:  [14.54915401] loss:  84.18218471051223\n",
      "Epoch:  78 / 1000\n",
      "w1:  [8.84938337] w2:  [2.34928442] bias:  [14.60268914] loss:  83.68744561560254\n",
      "Epoch:  79 / 1000\n",
      "w1:  [8.8913079] w2:  [2.33935186] bias:  [14.65476519] loss:  83.21479731774545\n",
      "Epoch:  80 / 1000\n",
      "w1:  [8.93247338] w2:  [2.32901284] bias:  [14.70542202] loss:  82.7630582636963\n",
      "Epoch:  81 / 1000\n",
      "w1:  [8.97290019] w2:  [2.31827914] bias:  [14.75469837] loss:  82.33111054585146\n",
      "Epoch:  82 / 1000\n",
      "w1:  [9.01260812] w2:  [2.30716217] bias:  [14.80263196] loss:  81.91789647304546\n",
      "Epoch:  83 / 1000\n",
      "w1:  [9.05161647] w2:  [2.29567305] bias:  [14.84925943] loss:  81.52241532611389\n",
      "Epoch:  84 / 1000\n",
      "w1:  [9.08994397] w2:  [2.28382259] bias:  [14.89461648] loss:  81.14372028826682\n",
      "Epoch:  85 / 1000\n",
      "w1:  [9.12760885] w2:  [2.27162131] bias:  [14.93873778] loss:  80.78091554085418\n",
      "Epoch:  86 / 1000\n",
      "w1:  [9.16462886] w2:  [2.25907943] bias:  [14.98165708] loss:  80.43315351561138\n",
      "Epoch:  87 / 1000\n",
      "w1:  [9.20102124] w2:  [2.24620691] bias:  [15.02340721] loss:  80.09963229495429\n",
      "Epoch:  88 / 1000\n",
      "w1:  [9.23680278] w2:  [2.23301342] bias:  [15.06402009] loss:  79.77959315234658\n",
      "Epoch:  89 / 1000\n",
      "w1:  [9.2719898] w2:  [2.21950836] bias:  [15.10352679] loss:  79.47231822519217\n",
      "Epoch:  90 / 1000\n",
      "w1:  [9.30659818] w2:  [2.2057009] bias:  [15.1419575] loss:  79.17712831311268\n",
      "Epoch:  91 / 1000\n",
      "w1:  [9.34064336] w2:  [2.19159994] bias:  [15.1793416] loss:  78.89338079485361\n",
      "Epoch:  92 / 1000\n",
      "w1:  [9.37414037] w2:  [2.17721412] bias:  [15.21570769] loss:  78.62046765742802\n",
      "Epoch:  93 / 1000\n",
      "w1:  [9.40710382] w2:  [2.16255188] bias:  [15.25108356] loss:  78.35781363144997\n",
      "Epoch:  94 / 1000\n",
      "w1:  [9.43954792] w2:  [2.14762141] bias:  [15.28549624] loss:  78.10487442693646\n",
      "Epoch:  95 / 1000\n",
      "w1:  [9.47148651] w2:  [2.13243067] bias:  [15.31897204] loss:  77.86113506416439\n",
      "Epoch:  96 / 1000\n",
      "w1:  [9.50293302] w2:  [2.11698741] bias:  [15.35153654] loss:  77.62610829446118\n",
      "Epoch:  97 / 1000\n",
      "w1:  [9.53390055] w2:  [2.10129916] bias:  [15.38321463] loss:  77.39933310608332\n",
      "Epoch:  98 / 1000\n",
      "w1:  [9.56440181] w2:  [2.08537326] bias:  [15.41403051] loss:  77.18037331059816\n",
      "Epoch:  99 / 1000\n",
      "w1:  [9.59444918] w2:  [2.06921684] bias:  [15.44400772] loss:  76.96881620543178\n",
      "Epoch:  100 / 1000\n",
      "w1:  [9.62405472] w2:  [2.05283682] bias:  [15.47316916] loss:  76.76427130847858\n",
      "Epoch:  101 / 1000\n",
      "w1:  [9.65323012] w2:  [2.03623996] bias:  [15.50153711] loss:  76.5663691608906\n",
      "Epoch:  102 / 1000\n",
      "w1:  [9.68198678] w2:  [2.01943281] bias:  [15.52913324] loss:  76.3747601943721\n",
      "Epoch:  103 / 1000\n",
      "w1:  [9.71033578] w2:  [2.00242174] bias:  [15.55597862] loss:  76.18911365950495\n",
      "Epoch:  104 / 1000\n",
      "w1:  [9.7382879] w2:  [1.98521297] bias:  [15.58209375] loss:  76.00911661181549\n",
      "Epoch:  105 / 1000\n",
      "w1:  [9.76585362] w2:  [1.96781253] bias:  [15.60749856] loss:  75.83447295247232\n",
      "Epoch:  106 / 1000\n",
      "w1:  [9.79304315] w2:  [1.95022629] bias:  [15.63221246] loss:  75.66490252067138\n",
      "Epoch:  107 / 1000\n",
      "w1:  [9.8198664] w2:  [1.93245995] bias:  [15.65625431] loss:  75.50014023492336\n",
      "Epoch:  108 / 1000\n",
      "w1:  [9.84633303] w2:  [1.91451906] bias:  [15.67964245] loss:  75.33993528060847\n",
      "Epoch:  109 / 1000\n",
      "w1:  [9.87245242] w2:  [1.89640903] bias:  [15.70239474] loss:  75.18405034130595\n",
      "Epoch:  110 / 1000\n",
      "w1:  [9.8982337] w2:  [1.87813511] bias:  [15.72452853] loss:  75.03226087153946\n",
      "Epoch:  111 / 1000\n",
      "w1:  [9.92368575] w2:  [1.8597024] bias:  [15.74606072] loss:  74.88435440870717\n",
      "Epoch:  112 / 1000\n",
      "w1:  [9.94881722] w2:  [1.84111586] bias:  [15.76700773] loss:  74.74012992208469\n",
      "Epoch:  113 / 1000\n",
      "w1:  [9.97363651] w2:  [1.82238034] bias:  [15.78738553] loss:  74.5993971969042\n",
      "Epoch:  114 / 1000\n",
      "w1:  [9.99815179] w2:  [1.80350053] bias:  [15.80720967] loss:  74.46197625161913\n",
      "Epoch:  115 / 1000\n",
      "w1:  [10.02237101] w2:  [1.78448099] bias:  [15.82649527] loss:  74.32769678656662\n",
      "Epoch:  116 / 1000\n",
      "w1:  [10.04630191] w2:  [1.76532618] bias:  [15.84525702] loss:  74.19639766233622\n",
      "Epoch:  117 / 1000\n",
      "w1:  [10.06995201] w2:  [1.74604041] bias:  [15.86350923] loss:  74.06792640624403\n",
      "Epoch:  118 / 1000\n",
      "w1:  [10.09332863] w2:  [1.72662788] bias:  [15.8812658] loss:  73.94213874539784\n",
      "Epoch:  119 / 1000\n",
      "w1:  [10.1164389] w2:  [1.70709269] bias:  [15.89854028] loss:  73.81889816492102\n",
      "Epoch:  120 / 1000\n",
      "w1:  [10.13928973] w2:  [1.68743881] bias:  [15.91534582] loss:  73.69807548997905\n",
      "Epoch:  121 / 1000\n",
      "w1:  [10.16188786] w2:  [1.6676701] bias:  [15.93169522] loss:  73.57954849032653\n",
      "Epoch:  122 / 1000\n",
      "w1:  [10.18423984] w2:  [1.64779033] bias:  [15.94760094] loss:  73.4632015061613\n",
      "Epoch:  123 / 1000\n",
      "w1:  [10.20635206] w2:  [1.62780315] bias:  [15.96307508] loss:  73.34892509413729\n",
      "Epoch:  124 / 1000\n",
      "w1:  [10.2282307] w2:  [1.60771212] bias:  [15.97812944] loss:  73.23661569245048\n",
      "Epoch:  125 / 1000\n",
      "w1:  [10.24988181] w2:  [1.5875207] bias:  [15.99277546] loss:  73.12617530396973\n",
      "Epoch:  126 / 1000\n",
      "w1:  [10.27131124] w2:  [1.56723225] bias:  [16.0070243] loss:  73.01751119644068\n",
      "Epoch:  127 / 1000\n",
      "w1:  [10.2925247] w2:  [1.54685004] bias:  [16.0208868] loss:  72.91053561884256\n",
      "Epoch:  128 / 1000\n",
      "w1:  [10.31352775] w2:  [1.52637726] bias:  [16.03437351] loss:  72.80516553302775\n",
      "Epoch:  129 / 1000\n",
      "w1:  [10.33432578] w2:  [1.50581699] bias:  [16.04749467] loss:  72.70132235982048\n",
      "Epoch:  130 / 1000\n",
      "w1:  [10.35492405] w2:  [1.48517225] bias:  [16.06026028] loss:  72.5989317387958\n",
      "Epoch:  131 / 1000\n",
      "w1:  [10.37532767] w2:  [1.46444596] bias:  [16.07268004] loss:  72.4979233010015\n",
      "Epoch:  132 / 1000\n",
      "w1:  [10.39554161] w2:  [1.44364097] bias:  [16.08476338] loss:  72.39823045392598\n",
      "Epoch:  133 / 1000\n",
      "w1:  [10.4155707] w2:  [1.42276004] bias:  [16.09651949] loss:  72.29979017805171\n",
      "Epoch:  134 / 1000\n",
      "w1:  [10.43541965] w2:  [1.40180587] bias:  [16.1079573] loss:  72.20254283437059\n",
      "Epoch:  135 / 1000\n",
      "w1:  [10.45509303] w2:  [1.38078107] bias:  [16.11908549] loss:  72.10643198227034\n",
      "Epoch:  136 / 1000\n",
      "w1:  [10.47459529] w2:  [1.35968818] bias:  [16.12991253] loss:  72.01140420723296\n",
      "Epoch:  137 / 1000\n",
      "w1:  [10.49393077] w2:  [1.33852969] bias:  [16.14044663] loss:  71.91740895781696\n",
      "Epoch:  138 / 1000\n",
      "w1:  [10.51310366] w2:  [1.31730799] bias:  [16.15069578] loss:  71.82439839142289\n",
      "Epoch:  139 / 1000\n",
      "w1:  [10.53211808] w2:  [1.29602543] bias:  [16.16066776] loss:  71.73232722836889\n",
      "Epoch:  140 / 1000\n",
      "w1:  [10.55097801] w2:  [1.27468429] bias:  [16.17037013] loss:  71.64115261382878\n",
      "Epoch:  141 / 1000\n",
      "w1:  [10.56968731] w2:  [1.25328677] bias:  [16.17981026] loss:  71.55083398720869\n",
      "Epoch:  142 / 1000\n",
      "w1:  [10.58824977] w2:  [1.23183503] bias:  [16.18899529] loss:  71.46133295856184\n",
      "Epoch:  143 / 1000\n",
      "w1:  [10.60666905] w2:  [1.21033116] bias:  [16.1979322] loss:  71.37261319166198\n",
      "Epoch:  144 / 1000\n",
      "w1:  [10.62494872] w2:  [1.18877719] bias:  [16.20662775] loss:  71.2846402933767\n",
      "Epoch:  145 / 1000\n",
      "w1:  [10.64309225] w2:  [1.16717511] bias:  [16.21508853] loss:  71.19738170900132\n",
      "Epoch:  146 / 1000\n",
      "w1:  [10.66110302] w2:  [1.14552684] bias:  [16.22332094] loss:  71.11080662323226\n",
      "Epoch:  147 / 1000\n",
      "w1:  [10.67898431] w2:  [1.12383424] bias:  [16.23133122] loss:  71.02488586647578\n",
      "Epoch:  148 / 1000\n",
      "w1:  [10.69673932] w2:  [1.10209915] bias:  [16.23912542] loss:  70.93959182620483\n",
      "Epoch:  149 / 1000\n",
      "w1:  [10.71437116] w2:  [1.08032332] bias:  [16.24670945] loss:  70.85489836309188\n",
      "Epoch:  150 / 1000\n",
      "w1:  [10.73188285] w2:  [1.05850847] bias:  [16.25408904] loss:  70.77078073166058\n",
      "Epoch:  151 / 1000\n",
      "w1:  [10.74927734] w2:  [1.03665629] bias:  [16.26126976] loss:  70.68721550521258\n",
      "Epoch:  152 / 1000\n",
      "w1:  [10.76655748] w2:  [1.01476839] bias:  [16.26825705] loss:  70.60418050479932\n",
      "Epoch:  153 / 1000\n",
      "w1:  [10.78372606] w2:  [0.99284636] bias:  [16.27505617] loss:  70.52165473202066\n",
      "Epoch:  154 / 1000\n",
      "w1:  [10.80078578] w2:  [0.97089174] bias:  [16.28167227] loss:  70.43961830544438\n",
      "Epoch:  155 / 1000\n",
      "w1:  [10.81773929] w2:  [0.94890601] bias:  [16.28811033] loss:  70.3580524004514\n",
      "Epoch:  156 / 1000\n",
      "w1:  [10.83458915] w2:  [0.92689063] bias:  [16.29437521] loss:  70.27693919232183\n",
      "Epoch:  157 / 1000\n",
      "w1:  [10.85133784] w2:  [0.90484703] bias:  [16.30047164] loss:  70.19626180238784\n",
      "Epoch:  158 / 1000\n",
      "w1:  [10.86798779] w2:  [0.88277656] bias:  [16.30640422] loss:  70.11600424708757\n",
      "Epoch:  159 / 1000\n",
      "w1:  [10.88454137] w2:  [0.86068056] bias:  [16.3121774] loss:  70.03615138976396\n",
      "Epoch:  160 / 1000\n",
      "w1:  [10.90100087] w2:  [0.83856034] bias:  [16.31779554] loss:  69.95668889506071\n",
      "Epoch:  161 / 1000\n",
      "w1:  [10.91736852] w2:  [0.81641716] bias:  [16.32326287] loss:  69.87760318577527\n",
      "Epoch:  162 / 1000\n",
      "w1:  [10.93364649] w2:  [0.79425225] bias:  [16.32858351] loss:  69.79888140203656\n",
      "Epoch:  163 / 1000\n",
      "w1:  [10.9498369] w2:  [0.77206679] bias:  [16.33376144] loss:  69.72051136268216\n",
      "Epoch:  164 / 1000\n",
      "w1:  [10.9659418] w2:  [0.74986195] bias:  [16.33880057] loss:  69.64248152871643\n",
      "Epoch:  165 / 1000\n",
      "w1:  [10.9819632] w2:  [0.72763886] bias:  [16.34370467] loss:  69.56478096873752\n",
      "Epoch:  166 / 1000\n",
      "w1:  [10.99790304] w2:  [0.70539861] bias:  [16.34847744] loss:  69.48739932622695\n",
      "Epoch:  167 / 1000\n",
      "w1:  [11.01376321] w2:  [0.68314228] bias:  [16.35312245] loss:  69.41032678860184\n",
      "Epoch:  168 / 1000\n",
      "w1:  [11.02954555] w2:  [0.66087089] bias:  [16.35764319] loss:  69.33355405793435\n",
      "Epoch:  169 / 1000\n",
      "w1:  [11.04525186] w2:  [0.63858545] bias:  [16.36204304] loss:  69.25707232324882\n",
      "Epoch:  170 / 1000\n",
      "w1:  [11.06088388] w2:  [0.61628695] bias:  [16.36632531] loss:  69.18087323431139\n",
      "Epoch:  171 / 1000\n",
      "w1:  [11.0764433] w2:  [0.59397634] bias:  [16.37049319] loss:  69.10494887683198\n",
      "Epoch:  172 / 1000\n",
      "w1:  [11.09193177] w2:  [0.57165454] bias:  [16.3745498] loss:  69.02929174900203\n",
      "Epoch:  173 / 1000\n",
      "w1:  [11.10735091] w2:  [0.54932245] bias:  [16.37849819] loss:  68.95389473929666\n",
      "Epoch:  174 / 1000\n",
      "w1:  [11.12270226] w2:  [0.52698095] bias:  [16.38234129] loss:  68.87875110547262\n",
      "Epoch:  175 / 1000\n",
      "w1:  [11.13798736] w2:  [0.50463089] bias:  [16.38608198] loss:  68.80385445469783\n",
      "Epoch:  176 / 1000\n",
      "w1:  [11.15320767] w2:  [0.48227308] bias:  [16.38972305] loss:  68.72919872475143\n",
      "Epoch:  177 / 1000\n",
      "w1:  [11.16836464] w2:  [0.45990835] bias:  [16.39326722] loss:  68.65477816623684\n",
      "Epoch:  178 / 1000\n",
      "w1:  [11.18345966] w2:  [0.43753746] bias:  [16.39671712] loss:  68.5805873257531\n",
      "Epoch:  179 / 1000\n",
      "w1:  [11.1984941] w2:  [0.41516118] bias:  [16.40007533] loss:  68.50662102997278\n",
      "Epoch:  180 / 1000\n",
      "w1:  [11.21346927] w2:  [0.39278025] bias:  [16.40334434] loss:  68.4328743705778\n",
      "Epoch:  181 / 1000\n",
      "w1:  [11.22838648] w2:  [0.37039538] bias:  [16.40652658] loss:  68.359342690007\n",
      "Epoch:  182 / 1000\n",
      "w1:  [11.24324696] w2:  [0.34800726] bias:  [16.40962443] loss:  68.28602156797126\n",
      "Epoch:  183 / 1000\n",
      "w1:  [11.25805195] w2:  [0.32561658] bias:  [16.41264017] loss:  68.21290680869545\n",
      "Epoch:  184 / 1000\n",
      "w1:  [11.27280263] w2:  [0.30322399] bias:  [16.41557605] loss:  68.13999442884756\n",
      "Epoch:  185 / 1000\n",
      "w1:  [11.28750014] w2:  [0.28083014] bias:  [16.41843424] loss:  68.06728064611829\n",
      "Epoch:  186 / 1000\n",
      "w1:  [11.30214562] w2:  [0.25843564] bias:  [16.42121685] loss:  67.99476186841567\n",
      "Epoch:  187 / 1000\n",
      "w1:  [11.31674016] w2:  [0.2360411] bias:  [16.42392595] loss:  67.9224346836422\n",
      "Epoch:  188 / 1000\n",
      "w1:  [11.33128482] w2:  [0.2136471] bias:  [16.42656354] loss:  67.8502958500224\n",
      "Epoch:  189 / 1000\n",
      "w1:  [11.34578064] w2:  [0.19125422] bias:  [16.42913157] loss:  67.77834228695173\n",
      "Epoch:  190 / 1000\n",
      "w1:  [11.36022862] w2:  [0.16886301] bias:  [16.43163192] loss:  67.70657106633824\n",
      "Epoch:  191 / 1000\n",
      "w1:  [11.37462974] w2:  [0.14647401] bias:  [16.43406644] loss:  67.63497940441106\n",
      "Epoch:  192 / 1000\n",
      "w1:  [11.38898496] w2:  [0.12408774] bias:  [16.43643693] loss:  67.56356465396983\n",
      "Epoch:  193 / 1000\n",
      "w1:  [11.4032952] w2:  [0.10170471] bias:  [16.43874513] loss:  67.49232429705188\n",
      "Epoch:  194 / 1000\n",
      "w1:  [11.41756136] w2:  [0.07932542] bias:  [16.44099273] loss:  67.42125593799447\n",
      "Epoch:  195 / 1000\n",
      "w1:  [11.43178433] w2:  [0.05695034] bias:  [16.44318139] loss:  67.35035729687065\n",
      "Epoch:  196 / 1000\n",
      "w1:  [11.44596495] w2:  [0.03457994] bias:  [16.4453127] loss:  67.2796262032789\n",
      "Epoch:  197 / 1000\n",
      "w1:  [11.46010406] w2:  [0.01221467] bias:  [16.44738823] loss:  67.20906059046723\n",
      "Epoch:  198 / 1000\n",
      "w1:  [11.47420247] w2:  [-0.01014502] bias:  [16.44940949] loss:  67.13865848977393\n",
      "Epoch:  199 / 1000\n",
      "w1:  [11.48826096] w2:  [-0.03249871] bias:  [16.45137797] loss:  67.0684180253676\n",
      "Epoch:  200 / 1000\n",
      "w1:  [11.5022803] w2:  [-0.05484598] bias:  [16.4532951] loss:  66.99833740927085\n",
      "Epoch:  201 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:  [11.51626124] w2:  [-0.07718644] bias:  [16.45516227] loss:  66.92841493665178\n",
      "Epoch:  202 / 1000\n",
      "w1:  [11.5302045] w2:  [-0.09951968] bias:  [16.45698085] loss:  66.85864898136927\n",
      "Epoch:  203 / 1000\n",
      "w1:  [11.54411078] w2:  [-0.12184533] bias:  [16.45875215] loss:  66.78903799175826\n",
      "Epoch:  204 / 1000\n",
      "w1:  [11.55798078] w2:  [-0.14416302] bias:  [16.46047746] loss:  66.71958048664196\n",
      "Epoch:  205 / 1000\n",
      "w1:  [11.57181516] w2:  [-0.16647239] bias:  [16.46215804] loss:  66.65027505155886\n",
      "Epoch:  206 / 1000\n",
      "w1:  [11.58561457] w2:  [-0.18877309] bias:  [16.4637951] loss:  66.58112033519326\n",
      "Epoch:  207 / 1000\n",
      "w1:  [11.59937965] w2:  [-0.21106478] bias:  [16.46538981] loss:  66.51211504599762\n",
      "Epoch:  208 / 1000\n",
      "w1:  [11.613111] w2:  [-0.23334714] bias:  [16.46694334] loss:  66.4432579489973\n",
      "Epoch:  209 / 1000\n",
      "w1:  [11.62680924] w2:  [-0.25561984] bias:  [16.46845681] loss:  66.3745478627671\n",
      "Epoch:  210 / 1000\n",
      "w1:  [11.64047494] w2:  [-0.27788257] bias:  [16.46993129] loss:  66.30598365657085\n",
      "Epoch:  211 / 1000\n",
      "w1:  [11.65410867] w2:  [-0.30013504] bias:  [16.47136785] loss:  66.23756424765486\n",
      "Epoch:  212 / 1000\n",
      "w1:  [11.66771098] w2:  [-0.32237695] bias:  [16.47276753] loss:  66.16928859868744\n",
      "Epoch:  213 / 1000\n",
      "w1:  [11.68128242] w2:  [-0.34460802] bias:  [16.47413131] loss:  66.10115571533613\n",
      "Epoch:  214 / 1000\n",
      "w1:  [11.6948235] w2:  [-0.36682797] bias:  [16.47546019] loss:  66.03316464397535\n",
      "Epoch:  215 / 1000\n",
      "w1:  [11.70833473] w2:  [-0.38903653] bias:  [16.47675509] loss:  65.96531446951785\n",
      "Epoch:  216 / 1000\n",
      "w1:  [11.72181661] w2:  [-0.41123345] bias:  [16.47801696] loss:  65.89760431336252\n",
      "Epoch:  217 / 1000\n",
      "w1:  [11.73526963] w2:  [-0.43341847] bias:  [16.47924668] loss:  65.83003333145311\n",
      "Epoch:  218 / 1000\n",
      "w1:  [11.74869425] w2:  [-0.45559136] bias:  [16.48044512] loss:  65.76260071244121\n",
      "Epoch:  219 / 1000\n",
      "w1:  [11.76209092] w2:  [-0.47775186] bias:  [16.48161314] loss:  65.69530567594839\n",
      "Epoch:  220 / 1000\n",
      "w1:  [11.7754601] w2:  [-0.49989976] bias:  [16.48275157] loss:  65.62814747092177\n",
      "Epoch:  221 / 1000\n",
      "w1:  [11.78880222] w2:  [-0.52203482] bias:  [16.48386119] loss:  65.56112537407823\n",
      "Epoch:  222 / 1000\n",
      "w1:  [11.8021177] w2:  [-0.54415684] bias:  [16.4849428] loss:  65.49423868843232\n",
      "Epoch:  223 / 1000\n",
      "w1:  [11.81540694] w2:  [-0.5662656] bias:  [16.48599716] loss:  65.42748674190352\n",
      "Epoch:  224 / 1000\n",
      "w1:  [11.82867036] w2:  [-0.5883609] bias:  [16.487025] loss:  65.36086888599856\n",
      "Epoch:  225 / 1000\n",
      "w1:  [11.84190833] w2:  [-0.61044254] bias:  [16.48802704] loss:  65.29438449456438\n",
      "Epoch:  226 / 1000\n",
      "w1:  [11.85512124] w2:  [-0.63251033] bias:  [16.48900398] loss:  65.2280329626087\n",
      "Epoch:  227 / 1000\n",
      "w1:  [11.86830945] w2:  [-0.65456407] bias:  [16.48995651] loss:  65.16181370518369\n",
      "Epoch:  228 / 1000\n",
      "w1:  [11.88147332] w2:  [-0.67660361] bias:  [16.49088527] loss:  65.09572615632992\n",
      "Epoch:  229 / 1000\n",
      "w1:  [11.89461321] w2:  [-0.69862874] bias:  [16.49179093] loss:  65.02976976807719\n",
      "Epoch:  230 / 1000\n",
      "w1:  [11.90772945] w2:  [-0.72063932] bias:  [16.4926741] loss:  64.96394400949906\n",
      "Epoch:  231 / 1000\n",
      "w1:  [11.92082237] w2:  [-0.74263516] bias:  [16.49353538] loss:  64.8982483658183\n",
      "Epoch:  232 / 1000\n",
      "w1:  [11.9338923] w2:  [-0.76461612] bias:  [16.49437538] loss:  64.8326823375606\n",
      "Epoch:  233 / 1000\n",
      "w1:  [11.94693954] w2:  [-0.78658204] bias:  [16.49519467] loss:  64.76724543975362\n",
      "Epoch:  234 / 1000\n",
      "w1:  [11.95996442] w2:  [-0.80853277] bias:  [16.49599381] loss:  64.70193720116943\n",
      "Epoch:  235 / 1000\n",
      "w1:  [11.97296721] w2:  [-0.83046816] bias:  [16.49677335] loss:  64.63675716360736\n",
      "Epoch:  236 / 1000\n",
      "w1:  [11.98594821] w2:  [-0.85238807] bias:  [16.49753381] loss:  64.57170488121584\n",
      "Epoch:  237 / 1000\n",
      "w1:  [11.99890771] w2:  [-0.87429237] bias:  [16.49827571] loss:  64.50677991985049\n",
      "Epoch:  238 / 1000\n",
      "w1:  [12.01184598] w2:  [-0.89618093] bias:  [16.49899955] loss:  64.44198185646673\n",
      "Epoch:  239 / 1000\n",
      "w1:  [12.02476328] w2:  [-0.91805361] bias:  [16.49970582] loss:  64.37731027854527\n",
      "Epoch:  240 / 1000\n",
      "w1:  [12.03765988] w2:  [-0.93991029] bias:  [16.500395] loss:  64.31276478354827\n",
      "Epoch:  241 / 1000\n",
      "w1:  [12.05053603] w2:  [-0.96175085] bias:  [16.50106754] loss:  64.24834497840502\n",
      "Epoch:  242 / 1000\n",
      "w1:  [12.06339198] w2:  [-0.98357518] bias:  [16.5017239] loss:  64.18405047902498\n",
      "Epoch:  243 / 1000\n",
      "w1:  [12.07622796] w2:  [-1.00538317] bias:  [16.5023645] loss:  64.11988090983729\n",
      "Epoch:  244 / 1000\n",
      "w1:  [12.08904421] w2:  [-1.0271747] bias:  [16.50298979] loss:  64.05583590335493\n",
      "Epoch:  245 / 1000\n",
      "w1:  [12.10184097] w2:  [-1.04894967] bias:  [16.50360016] loss:  63.991915099762245\n",
      "Epoch:  246 / 1000\n",
      "w1:  [12.11461844] w2:  [-1.07070797] bias:  [16.50419603] loss:  63.92811814652481\n",
      "Epoch:  247 / 1000\n",
      "w1:  [12.12737685] w2:  [-1.09244952] bias:  [16.50477777] loss:  63.86444469802013\n",
      "Epoch:  248 / 1000\n",
      "w1:  [12.14011642] w2:  [-1.11417421] bias:  [16.50534578] loss:  63.80089441518833\n",
      "Epoch:  249 / 1000\n",
      "w1:  [12.15283733] w2:  [-1.13588195] bias:  [16.50590043] loss:  63.73746696520143\n",
      "Epoch:  250 / 1000\n",
      "w1:  [12.1655398] w2:  [-1.15757265] bias:  [16.50644206] loss:  63.67416202115062\n",
      "Epoch:  251 / 1000\n",
      "w1:  [12.17822402] w2:  [-1.17924623] bias:  [16.50697104] loss:  63.61097926175019\n",
      "Epoch:  252 / 1000\n",
      "w1:  [12.19089018] w2:  [-1.2009026] bias:  [16.5074877] loss:  63.54791837105738\n",
      "Epoch:  253 / 1000\n",
      "w1:  [12.20353846] w2:  [-1.22254168] bias:  [16.50799237] loss:  63.48497903820736\n",
      "Epoch:  254 / 1000\n",
      "w1:  [12.21616905] w2:  [-1.24416339] bias:  [16.50848538] loss:  63.42216095716239\n",
      "Epoch:  255 / 1000\n",
      "w1:  [12.22878211] w2:  [-1.26576767] bias:  [16.50896704] loss:  63.359463826474396\n",
      "Epoch:  256 / 1000\n",
      "w1:  [12.24137783] w2:  [-1.28735443] bias:  [16.50943765] loss:  63.296887349060476\n",
      "Epoch:  257 / 1000\n",
      "w1:  [12.25395636] w2:  [-1.3089236] bias:  [16.50989751] loss:  63.234431231990236\n",
      "Epoch:  258 / 1000\n",
      "w1:  [12.26651787] w2:  [-1.33047512] bias:  [16.51034691] loss:  63.17209518628466\n",
      "Epoch:  259 / 1000\n",
      "w1:  [12.27906252] w2:  [-1.35200893] bias:  [16.51078613] loss:  63.10987892672585\n",
      "Epoch:  260 / 1000\n",
      "w1:  [12.29159047] w2:  [-1.37352495] bias:  [16.51121545] loss:  63.04778217167676\n",
      "Epoch:  261 / 1000\n",
      "w1:  [12.30410185] w2:  [-1.39502314] bias:  [16.51163512] loss:  62.9858046429108\n",
      "Epoch:  262 / 1000\n",
      "w1:  [12.31659682] w2:  [-1.41650342] bias:  [16.5120454] loss:  62.9239460654505\n",
      "Epoch:  263 / 1000\n",
      "w1:  [12.32907553] w2:  [-1.43796575] bias:  [16.51244655] loss:  62.8622061674148\n",
      "Epoch:  264 / 1000\n",
      "w1:  [12.34153811] w2:  [-1.45941007] bias:  [16.51283882] loss:  62.80058467987453\n",
      "Epoch:  265 / 1000\n",
      "w1:  [12.35398469] w2:  [-1.48083633] bias:  [16.51322243] loss:  62.73908133671575\n",
      "Epoch:  266 / 1000\n",
      "w1:  [12.36641541] w2:  [-1.50224447] bias:  [16.51359762] loss:  62.67769587451019\n",
      "Epoch:  267 / 1000\n",
      "w1:  [12.3788304] w2:  [-1.52363445] bias:  [16.51396461] loss:  62.616428032392875\n",
      "Epoch:  268 / 1000\n",
      "w1:  [12.39122978] w2:  [-1.54500622] bias:  [16.51432363] loss:  62.55527755194609\n",
      "Epoch:  269 / 1000\n",
      "w1:  [12.40361368] w2:  [-1.56635974] bias:  [16.51467488] loss:  62.4942441770897\n",
      "Epoch:  270 / 1000\n",
      "w1:  [12.41598222] w2:  [-1.58769496] bias:  [16.51501858] loss:  62.43332765397722\n",
      "Epoch:  271 / 1000\n",
      "w1:  [12.4283355] w2:  [-1.60901184] bias:  [16.51535492] loss:  62.37252773089763\n",
      "Epoch:  272 / 1000\n",
      "w1:  [12.44067365] w2:  [-1.63031035] bias:  [16.5156841] loss:  62.311844158182176\n",
      "Epoch:  273 / 1000\n",
      "w1:  [12.45299678] w2:  [-1.65159043] bias:  [16.5160063] loss:  62.251276688116356\n",
      "Epoch:  274 / 1000\n",
      "w1:  [12.46530499] w2:  [-1.67285207] bias:  [16.51632173] loss:  62.190825074856534\n",
      "Epoch:  275 / 1000\n",
      "w1:  [12.4775984] w2:  [-1.69409522] bias:  [16.51663054] loss:  62.13048907435101\n",
      "Epoch:  276 / 1000\n",
      "w1:  [12.48987709] w2:  [-1.71531984] bias:  [16.51693293] loss:  62.070268444265295\n",
      "Epoch:  277 / 1000\n",
      "w1:  [12.50214118] w2:  [-1.73652591] bias:  [16.51722906] loss:  62.010162943911375\n",
      "Epoch:  278 / 1000\n",
      "w1:  [12.51439076] w2:  [-1.7577134] bias:  [16.5175191] loss:  61.95017233418076\n",
      "Epoch:  279 / 1000\n",
      "w1:  [12.52662592] w2:  [-1.77888227] bias:  [16.5178032] loss:  61.89029637748108\n",
      "Epoch:  280 / 1000\n",
      "w1:  [12.53884677] w2:  [-1.8000325] bias:  [16.51808153] loss:  61.83053483767603\n",
      "Epoch:  281 / 1000\n",
      "w1:  [12.55105338] w2:  [-1.82116406] bias:  [16.51835423] loss:  61.77088748002861\n",
      "Epoch:  282 / 1000\n",
      "w1:  [12.56324586] w2:  [-1.84227693] bias:  [16.51862146] loss:  61.71135407114722\n",
      "Epoch:  283 / 1000\n",
      "w1:  [12.57542428] w2:  [-1.86337108] bias:  [16.51888336] loss:  61.65193437893482\n",
      "Epoch:  284 / 1000\n",
      "w1:  [12.58758873] w2:  [-1.88444648] bias:  [16.51914007] loss:  61.59262817254059\n",
      "Epoch:  285 / 1000\n",
      "w1:  [12.59973929] w2:  [-1.90550312] bias:  [16.51939173] loss:  61.53343522231427\n",
      "Epoch:  286 / 1000\n",
      "w1:  [12.61187604] w2:  [-1.92654097] bias:  [16.51963847] loss:  61.47435529976291\n",
      "Epoch:  287 / 1000\n",
      "w1:  [12.62399907] w2:  [-1.94756002] bias:  [16.51988042] loss:  61.41538817750986\n",
      "Epoch:  288 / 1000\n",
      "w1:  [12.63610844] w2:  [-1.96856024] bias:  [16.5201177] loss:  61.35653362925601\n",
      "Epoch:  289 / 1000\n",
      "w1:  [12.64820424] w2:  [-1.98954162] bias:  [16.52035044] loss:  61.297791429742986\n",
      "Epoch:  290 / 1000\n",
      "w1:  [12.66028653] w2:  [-2.01050414] bias:  [16.52057876] loss:  61.23916135471831\n",
      "Epoch:  291 / 1000\n",
      "w1:  [12.67235539] w2:  [-2.03144779] bias:  [16.52080276] loss:  61.180643180902486\n",
      "Epoch:  292 / 1000\n",
      "w1:  [12.68441089] w2:  [-2.05237254] bias:  [16.52102258] loss:  61.122236685957716\n",
      "Epoch:  293 / 1000\n",
      "w1:  [12.6964531] w2:  [-2.07327839] bias:  [16.5212383] loss:  61.063941648458275\n",
      "Epoch:  294 / 1000\n",
      "w1:  [12.70848207] w2:  [-2.09416533] bias:  [16.52145005] loss:  61.00575784786246\n",
      "Epoch:  295 / 1000\n",
      "w1:  [12.72049788] w2:  [-2.11503333] bias:  [16.52165792] loss:  60.947685064486066\n",
      "Epoch:  296 / 1000\n",
      "w1:  [12.7325006] w2:  [-2.13588239] bias:  [16.52186202] loss:  60.88972307947717\n",
      "Epoch:  297 / 1000\n",
      "w1:  [12.74449027] w2:  [-2.15671251] bias:  [16.52206244] loss:  60.83187167479225\n",
      "Epoch:  298 / 1000\n",
      "w1:  [12.75646697] w2:  [-2.17752366] bias:  [16.52225928] loss:  60.774130633173534\n",
      "Epoch:  299 / 1000\n",
      "w1:  [12.76843075] w2:  [-2.19831584] bias:  [16.52245263] loss:  60.71649973812762\n",
      "Epoch:  300 / 1000\n",
      "w1:  [12.78038167] w2:  [-2.21908904] bias:  [16.52264258] loss:  60.65897877390512\n",
      "Epoch:  301 / 1000\n",
      "w1:  [12.79231979] w2:  [-2.23984325] bias:  [16.52282922] loss:  60.60156752548139\n",
      "Epoch:  302 / 1000\n",
      "w1:  [12.80424516] w2:  [-2.26057848] bias:  [16.52301264] loss:  60.54426577853821\n",
      "Epoch:  303 / 1000\n",
      "w1:  [12.81615784] w2:  [-2.2812947] bias:  [16.52319291] loss:  60.48707331944654\n",
      "Epoch:  304 / 1000\n",
      "w1:  [12.82805788] w2:  [-2.30199192] bias:  [16.52337012] loss:  60.42998993525001\n",
      "Epoch:  305 / 1000\n",
      "w1:  [12.83994533] w2:  [-2.32267012] bias:  [16.52354435] loss:  60.37301541364938\n",
      "Epoch:  306 / 1000\n",
      "w1:  [12.85182024] w2:  [-2.34332932] bias:  [16.52371567] loss:  60.316149542987695\n",
      "Epoch:  307 / 1000\n",
      "w1:  [12.86368266] w2:  [-2.36396949] bias:  [16.52388416] loss:  60.25939211223634\n",
      "Epoch:  308 / 1000\n",
      "w1:  [12.87553264] w2:  [-2.38459065] bias:  [16.52404989] loss:  60.20274291098164\n",
      "Epoch:  309 / 1000\n",
      "w1:  [12.88737023] w2:  [-2.40519278] bias:  [16.52421293] loss:  60.14620172941229\n",
      "Epoch:  310 / 1000\n",
      "w1:  [12.89919547] w2:  [-2.42577589] bias:  [16.52437335] loss:  60.08976835830727\n",
      "Epoch:  311 / 1000\n",
      "w1:  [12.91100841] w2:  [-2.44633997] bias:  [16.52453122] loss:  60.0334425890246\n",
      "Epoch:  312 / 1000\n",
      "w1:  [12.9228091] w2:  [-2.46688503] bias:  [16.5246866] loss:  59.977224213490395\n",
      "Epoch:  313 / 1000\n",
      "w1:  [12.93459757] w2:  [-2.48741106] bias:  [16.52483955] loss:  59.921113024188664\n",
      "Epoch:  314 / 1000\n",
      "w1:  [12.94637387] w2:  [-2.50791806] bias:  [16.52499013] loss:  59.865108814151505\n",
      "Epoch:  315 / 1000\n",
      "w1:  [12.95813804] w2:  [-2.52840603] bias:  [16.52513841] loss:  59.80921137694996\n",
      "Epoch:  316 / 1000\n",
      "w1:  [12.96989013] w2:  [-2.54887498] bias:  [16.52528444] loss:  59.75342050668502\n",
      "Epoch:  317 / 1000\n",
      "w1:  [12.98163017] w2:  [-2.56932491] bias:  [16.52542828] loss:  59.69773599797939\n",
      "Epoch:  318 / 1000\n",
      "w1:  [12.9933582] w2:  [-2.58975581] bias:  [16.52556999] loss:  59.642157645969526\n",
      "Epoch:  319 / 1000\n",
      "w1:  [13.00507425] w2:  [-2.6101677] bias:  [16.52570961] loss:  59.58668524629801\n",
      "Epoch:  320 / 1000\n",
      "w1:  [13.01677838] w2:  [-2.63056057] bias:  [16.5258472] loss:  59.531318595106384\n",
      "Epoch:  321 / 1000\n",
      "w1:  [13.02847061] w2:  [-2.65093443] bias:  [16.52598281] loss:  59.476057489028285\n",
      "Epoch:  322 / 1000\n",
      "w1:  [13.04015098] w2:  [-2.67128928] bias:  [16.52611649] loss:  59.42090172518296\n",
      "Epoch:  323 / 1000\n",
      "w1:  [13.05181953] w2:  [-2.69162513] bias:  [16.52624829] loss:  59.36585110116903\n",
      "Epoch:  324 / 1000\n",
      "w1:  [13.06347628] w2:  [-2.71194197] bias:  [16.52637824] loss:  59.31090541505856\n",
      "Epoch:  325 / 1000\n",
      "w1:  [13.07512128] w2:  [-2.73223982] bias:  [16.52650641] loss:  59.256064465391525\n",
      "Epoch:  326 / 1000\n",
      "w1:  [13.08675456] w2:  [-2.75251868] bias:  [16.52663283] loss:  59.20132805117033\n",
      "Epoch:  327 / 1000\n",
      "w1:  [13.09837615] w2:  [-2.77277856] bias:  [16.52675755] loss:  59.14669597185476\n",
      "Epoch:  328 / 1000\n",
      "w1:  [13.10998609] w2:  [-2.79301946] bias:  [16.5268806] loss:  59.09216802735714\n",
      "Epoch:  329 / 1000\n",
      "w1:  [13.12158439] w2:  [-2.81324139] bias:  [16.52700203] loss:  59.03774401803757\n",
      "Epoch:  330 / 1000\n",
      "w1:  [13.13317111] w2:  [-2.83344435] bias:  [16.52712188] loss:  58.983423744699635\n",
      "Epoch:  331 / 1000\n",
      "w1:  [13.14474625] w2:  [-2.85362835] bias:  [16.52724018] loss:  58.92920700858606\n",
      "Epoch:  332 / 1000\n",
      "w1:  [13.15630987] w2:  [-2.87379341] bias:  [16.52735697] loss:  58.8750936113747\n",
      "Epoch:  333 / 1000\n",
      "w1:  [13.16786198] w2:  [-2.89393952] bias:  [16.5274723] loss:  58.8210833551747\n",
      "Epoch:  334 / 1000\n",
      "w1:  [13.17940261] w2:  [-2.91406669] bias:  [16.52758618] loss:  58.76717604252277\n",
      "Epoch:  335 / 1000\n",
      "w1:  [13.19093179] w2:  [-2.93417494] bias:  [16.52769867] loss:  58.71337147637968\n",
      "Epoch:  336 / 1000\n",
      "w1:  [13.20244956] w2:  [-2.95426426] bias:  [16.52780979] loss:  58.65966946012686\n",
      "Epoch:  337 / 1000\n",
      "w1:  [13.21395593] w2:  [-2.97433468] bias:  [16.52791957] loss:  58.60606979756316\n",
      "Epoch:  338 / 1000\n",
      "w1:  [13.22545093] w2:  [-2.99438619] bias:  [16.52802805] loss:  58.5525722929018\n",
      "Epoch:  339 / 1000\n",
      "w1:  [13.23693459] w2:  [-3.01441881] bias:  [16.52813525] loss:  58.49917675076734\n",
      "Epoch:  340 / 1000\n",
      "w1:  [13.24840694] w2:  [-3.03443255] bias:  [16.52824122] loss:  58.44588297619291\n",
      "Epoch:  341 / 1000\n",
      "w1:  [13.25986801] w2:  [-3.05442741] bias:  [16.52834596] loss:  58.39269077461742\n",
      "Epoch:  342 / 1000\n",
      "w1:  [13.2713178] w2:  [-3.07440341] bias:  [16.52844953] loss:  58.33959995188297\n",
      "Epoch:  343 / 1000\n",
      "w1:  [13.28275636] w2:  [-3.09436055] bias:  [16.52855193] loss:  58.28661031423232\n",
      "Epoch:  344 / 1000\n",
      "w1:  [13.2941837] w2:  [-3.11429886] bias:  [16.5286532] loss:  58.233721668306536\n",
      "Epoch:  345 / 1000\n",
      "w1:  [13.30559985] w2:  [-3.13421832] bias:  [16.52875337] loss:  58.180933821142595\n",
      "Epoch:  346 / 1000\n",
      "w1:  [13.31700484] w2:  [-3.15411896] bias:  [16.52885246] loss:  58.12824658017118\n",
      "Epoch:  347 / 1000\n",
      "w1:  [13.32839868] w2:  [-3.17400079] bias:  [16.52895049] loss:  58.07565975321453\n",
      "Epoch:  348 / 1000\n",
      "w1:  [13.33978139] w2:  [-3.19386382] bias:  [16.52904749] loss:  58.02317314848442\n",
      "Epoch:  349 / 1000\n",
      "w1:  [13.35115301] w2:  [-3.21370806] bias:  [16.52914348] loss:  57.97078657458009\n",
      "Epoch:  350 / 1000\n",
      "w1:  [13.36251355] w2:  [-3.23353352] bias:  [16.52923849] loss:  57.918499840486355\n",
      "Epoch:  351 / 1000\n",
      "w1:  [13.37386303] w2:  [-3.25334021] bias:  [16.52933254] loss:  57.866312755571784\n",
      "Epoch:  352 / 1000\n",
      "w1:  [13.38520148] w2:  [-3.27312815] bias:  [16.52942564] loss:  57.81422512958685\n",
      "Epoch:  353 / 1000\n",
      "w1:  [13.39652892] w2:  [-3.29289734] bias:  [16.52951782] loss:  57.76223677266225\n",
      "Epoch:  354 / 1000\n",
      "w1:  [13.40784536] w2:  [-3.3126478] bias:  [16.52960911] loss:  57.710347495307204\n",
      "Epoch:  355 / 1000\n",
      "w1:  [13.41915083] w2:  [-3.33237954] bias:  [16.52969951] loss:  57.65855710840784\n",
      "Epoch:  356 / 1000\n",
      "w1:  [13.43044534] w2:  [-3.35209258] bias:  [16.52978905] loss:  57.60686542322565\n",
      "Epoch:  357 / 1000\n",
      "w1:  [13.44172893] w2:  [-3.37178691] bias:  [16.52987775] loss:  57.55527225139593\n",
      "Epoch:  358 / 1000\n",
      "w1:  [13.4530016] w2:  [-3.39146257] bias:  [16.52996563] loss:  57.50377740492633\n",
      "Epoch:  359 / 1000\n",
      "w1:  [13.46426337] w2:  [-3.41111955] bias:  [16.5300527] loss:  57.45238069619546\n",
      "Epoch:  360 / 1000\n",
      "w1:  [13.47551428] w2:  [-3.43075788] bias:  [16.53013898] loss:  57.40108193795143\n",
      "Epoch:  361 / 1000\n",
      "w1:  [13.48675432] w2:  [-3.45037756] bias:  [16.53022448] loss:  57.349880943310566\n",
      "Epoch:  362 / 1000\n",
      "w1:  [13.49798353] w2:  [-3.46997861] bias:  [16.53030924] loss:  57.29877752575603\n",
      "Epoch:  363 / 1000\n",
      "w1:  [13.50920192] w2:  [-3.48956105] bias:  [16.53039325] loss:  57.24777149913667\n",
      "Epoch:  364 / 1000\n",
      "w1:  [13.52040951] w2:  [-3.50912487] bias:  [16.53047654] loss:  57.19686267766562\n",
      "Epoch:  365 / 1000\n",
      "w1:  [13.53160631] w2:  [-3.52867011] bias:  [16.53055911] loss:  57.14605087591921\n",
      "Epoch:  366 / 1000\n",
      "w1:  [13.54279235] w2:  [-3.54819677] bias:  [16.530641] loss:  57.095335908835736\n",
      "Epoch:  367 / 1000\n",
      "w1:  [13.55396764] w2:  [-3.56770486] bias:  [16.5307222] loss:  57.044717591714296\n",
      "Epoch:  368 / 1000\n",
      "w1:  [13.5651322] w2:  [-3.58719441] bias:  [16.53080274] loss:  56.99419574021371\n",
      "Epoch:  369 / 1000\n",
      "w1:  [13.57628604] w2:  [-3.60666541] bias:  [16.53088262] loss:  56.94377017035138\n",
      "Epoch:  370 / 1000\n",
      "w1:  [13.58742919] w2:  [-3.6261179] bias:  [16.53096187] loss:  56.89344069850224\n",
      "Epoch:  371 / 1000\n",
      "w1:  [13.59856166] w2:  [-3.64555187] bias:  [16.53104048] loss:  56.84320714139772\n",
      "Epoch:  372 / 1000\n",
      "w1:  [13.60968346] w2:  [-3.66496735] bias:  [16.53111849] loss:  56.79306931612464\n",
      "Epoch:  373 / 1000\n",
      "w1:  [13.62079461] w2:  [-3.68436435] bias:  [16.53119589] loss:  56.7430270401243\n",
      "Epoch:  374 / 1000\n",
      "w1:  [13.63189513] w2:  [-3.70374288] bias:  [16.53127269] loss:  56.69308013119144\n",
      "Epoch:  375 / 1000\n",
      "w1:  [13.64298504] w2:  [-3.72310296] bias:  [16.53134892] loss:  56.643228407473266\n",
      "Epoch:  376 / 1000\n",
      "w1:  [13.65406434] w2:  [-3.74244461] bias:  [16.53142459] loss:  56.5934716874685\n",
      "Epoch:  377 / 1000\n",
      "w1:  [13.66513306] w2:  [-3.76176782] bias:  [16.53149969] loss:  56.54380979002649\n",
      "Epoch:  378 / 1000\n",
      "w1:  [13.6761912] w2:  [-3.78107263] bias:  [16.53157425] loss:  56.494242534346206\n",
      "Epoch:  379 / 1000\n",
      "w1:  [13.6872388] w2:  [-3.80035905] bias:  [16.53164827] loss:  56.444769739975406\n",
      "Epoch:  380 / 1000\n",
      "w1:  [13.69827585] w2:  [-3.81962709] bias:  [16.53172177] loss:  56.39539122680974\n",
      "Epoch:  381 / 1000\n",
      "w1:  [13.70930238] w2:  [-3.83887676] bias:  [16.53179474] loss:  56.346106815091844\n",
      "Epoch:  382 / 1000\n",
      "w1:  [13.7203184] w2:  [-3.85810808] bias:  [16.53186722] loss:  56.2969163254105\n",
      "Epoch:  383 / 1000\n",
      "w1:  [13.73132392] w2:  [-3.87732106] bias:  [16.53193919] loss:  56.247819578699755\n",
      "Epoch:  384 / 1000\n",
      "w1:  [13.74231896] w2:  [-3.89651573] bias:  [16.53201067] loss:  56.19881639623815\n",
      "Epoch:  385 / 1000\n",
      "w1:  [13.75330353] w2:  [-3.91569209] bias:  [16.53208168] loss:  56.14990659964779\n",
      "Epoch:  386 / 1000\n",
      "w1:  [13.76427766] w2:  [-3.93485016] bias:  [16.53215221] loss:  56.10109001089366\n",
      "Epoch:  387 / 1000\n",
      "w1:  [13.77524134] w2:  [-3.95398995] bias:  [16.53222228] loss:  56.0523664522827\n",
      "Epoch:  388 / 1000\n",
      "w1:  [13.7861946] w2:  [-3.97311148] bias:  [16.53229189] loss:  56.00373574646305\n",
      "Epoch:  389 / 1000\n",
      "w1:  [13.79713744] w2:  [-3.99221477] bias:  [16.53236106] loss:  55.95519771642328\n",
      "Epoch:  390 / 1000\n",
      "w1:  [13.80806989] w2:  [-4.01129983] bias:  [16.53242979] loss:  55.90675218549162\n",
      "Epoch:  391 / 1000\n",
      "w1:  [13.81899196] w2:  [-4.03036668] bias:  [16.53249808] loss:  55.85839897733516\n",
      "Epoch:  392 / 1000\n",
      "w1:  [13.82990365] w2:  [-4.04941532] bias:  [16.53256595] loss:  55.810137915959096\n",
      "Epoch:  393 / 1000\n",
      "w1:  [13.84080499] w2:  [-4.06844579] bias:  [16.5326334] loss:  55.76196882570598\n",
      "Epoch:  394 / 1000\n",
      "w1:  [13.85169599] w2:  [-4.08745808] bias:  [16.53270044] loss:  55.71389153125496\n",
      "Epoch:  395 / 1000\n",
      "w1:  [13.86257665] w2:  [-4.10645222] bias:  [16.53276707] loss:  55.66590585762109\n",
      "Epoch:  396 / 1000\n",
      "w1:  [13.873447] w2:  [-4.12542822] bias:  [16.53283331] loss:  55.61801163015455\n",
      "Epoch:  397 / 1000\n",
      "w1:  [13.88430704] w2:  [-4.14438611] bias:  [16.53289916] loss:  55.57020867453988\n",
      "Epoch:  398 / 1000\n",
      "w1:  [13.89515679] w2:  [-4.16332588] bias:  [16.53296461] loss:  55.52249681679541\n",
      "Epoch:  399 / 1000\n",
      "w1:  [13.90599626] w2:  [-4.18224756] bias:  [16.53302969] loss:  55.47487588327236\n",
      "Epoch:  400 / 1000\n",
      "w1:  [13.91682547] w2:  [-4.20115117] bias:  [16.5330944] loss:  55.42734570065424\n",
      "Epoch:  401 / 1000\n",
      "w1:  [13.92764442] w2:  [-4.22003672] bias:  [16.53315873] loss:  55.37990609595616\n",
      "Epoch:  402 / 1000\n",
      "w1:  [13.93845312] w2:  [-4.23890423] bias:  [16.53322271] loss:  55.33255689652407\n",
      "Epoch:  403 / 1000\n",
      "w1:  [13.9492516] w2:  [-4.2577537] bias:  [16.53328632] loss:  55.285297930034055\n",
      "Epoch:  404 / 1000\n",
      "w1:  [13.96003987] w2:  [-4.27658517] bias:  [16.53334959] loss:  55.23812902449176\n",
      "Epoch:  405 / 1000\n",
      "w1:  [13.97081793] w2:  [-4.29539864] bias:  [16.53341251] loss:  55.19105000823158\n",
      "Epoch:  406 / 1000\n",
      "w1:  [13.98158579] w2:  [-4.31419412] bias:  [16.53347508] loss:  55.14406070991603\n",
      "Epoch:  407 / 1000\n",
      "w1:  [13.99234348] w2:  [-4.33297164] bias:  [16.53353732] loss:  55.09716095853509\n",
      "Epoch:  408 / 1000\n",
      "w1:  [14.003091] w2:  [-4.35173121] bias:  [16.53359923] loss:  55.050350583405496\n",
      "Epoch:  409 / 1000\n",
      "w1:  [14.01382836] w2:  [-4.37047285] bias:  [16.5336608] loss:  55.0036294141701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  410 / 1000\n",
      "w1:  [14.02455557] w2:  [-4.38919657] bias:  [16.53372206] loss:  54.95699728079718\n",
      "Epoch:  411 / 1000\n",
      "w1:  [14.03527266] w2:  [-4.40790239] bias:  [16.53378299] loss:  54.9104540135798\n",
      "Epoch:  412 / 1000\n",
      "w1:  [14.04597962] w2:  [-4.42659032] bias:  [16.53384361] loss:  54.863999443135164\n",
      "Epoch:  413 / 1000\n",
      "w1:  [14.05667647] w2:  [-4.44526039] bias:  [16.53390392] loss:  54.8176334004039\n",
      "Epoch:  414 / 1000\n",
      "w1:  [14.06736322] w2:  [-4.4639126] bias:  [16.53396392] loss:  54.771355716649516\n",
      "Epoch:  415 / 1000\n",
      "w1:  [14.07803989] w2:  [-4.48254697] bias:  [16.53402362] loss:  54.72516622345764\n",
      "Epoch:  416 / 1000\n",
      "w1:  [14.08870649] w2:  [-4.50116351] bias:  [16.53408302] loss:  54.679064752735414\n",
      "Epoch:  417 / 1000\n",
      "w1:  [14.09936301] w2:  [-4.51976226] bias:  [16.53414213] loss:  54.63305113671093\n",
      "Epoch:  418 / 1000\n",
      "w1:  [14.11000949] w2:  [-4.53834321] bias:  [16.53420094] loss:  54.587125207932466\n",
      "Epoch:  419 / 1000\n",
      "w1:  [14.12064593] w2:  [-4.55690638] bias:  [16.53425947] loss:  54.54128679926795\n",
      "Epoch:  420 / 1000\n",
      "w1:  [14.13127233] w2:  [-4.5754518] bias:  [16.53431771] loss:  54.49553574390424\n",
      "Epoch:  421 / 1000\n",
      "w1:  [14.14188872] w2:  [-4.59397948] bias:  [16.53437567] loss:  54.44987187534657\n",
      "Epoch:  422 / 1000\n",
      "w1:  [14.1524951] w2:  [-4.61248943] bias:  [16.53443335] loss:  54.404295027417874\n",
      "Epoch:  423 / 1000\n",
      "w1:  [14.16309148] w2:  [-4.63098167] bias:  [16.53449075] loss:  54.35880503425819\n",
      "Epoch:  424 / 1000\n",
      "w1:  [14.17367787] w2:  [-4.64945622] bias:  [16.53454789] loss:  54.31340173032401\n",
      "Epoch:  425 / 1000\n",
      "w1:  [14.1842543] w2:  [-4.66791308] bias:  [16.53460475] loss:  54.26808495038766\n",
      "Epoch:  426 / 1000\n",
      "w1:  [14.19482075] w2:  [-4.68635229] bias:  [16.53466135] loss:  54.22285452953672\n",
      "Epoch:  427 / 1000\n",
      "w1:  [14.20537726] w2:  [-4.70477385] bias:  [16.53471768] loss:  54.177710303173335\n",
      "Epoch:  428 / 1000\n",
      "w1:  [14.21592382] w2:  [-4.72317778] bias:  [16.53477376] loss:  54.13265210701367\n",
      "Epoch:  429 / 1000\n",
      "w1:  [14.22646045] w2:  [-4.7415641] bias:  [16.53482958] loss:  54.08767977708726\n",
      "Epoch:  430 / 1000\n",
      "w1:  [14.23698716] w2:  [-4.75993282] bias:  [16.53488514] loss:  54.04279314973641\n",
      "Epoch:  431 / 1000\n",
      "w1:  [14.24750396] w2:  [-4.77828395] bias:  [16.53494045] loss:  53.99799206161556\n",
      "Epoch:  432 / 1000\n",
      "w1:  [14.25801086] w2:  [-4.79661753] bias:  [16.53499551] loss:  53.953276349690725\n",
      "Epoch:  433 / 1000\n",
      "w1:  [14.26850787] w2:  [-4.81493355] bias:  [16.53505032] loss:  53.908645851238866\n",
      "Epoch:  434 / 1000\n",
      "w1:  [14.278995] w2:  [-4.83323204] bias:  [16.53510488] loss:  53.864100403847246\n",
      "Epoch:  435 / 1000\n",
      "w1:  [14.28947226] w2:  [-4.85151301] bias:  [16.53515921] loss:  53.81963984541291\n",
      "Epoch:  436 / 1000\n",
      "w1:  [14.29993967] w2:  [-4.86977648] bias:  [16.53521329] loss:  53.775264014141996\n",
      "Epoch:  437 / 1000\n",
      "w1:  [14.31039723] w2:  [-4.88802246] bias:  [16.53526713] loss:  53.73097274854922\n",
      "Epoch:  438 / 1000\n",
      "w1:  [14.32084495] w2:  [-4.90625098] bias:  [16.53532074] loss:  53.68676588745722\n",
      "Epoch:  439 / 1000\n",
      "w1:  [14.33128285] w2:  [-4.92446204] bias:  [16.53537412] loss:  53.64264326999598\n",
      "Epoch:  440 / 1000\n",
      "w1:  [14.34171092] w2:  [-4.94265567] bias:  [16.53542726] loss:  53.59860473560223\n",
      "Epoch:  441 / 1000\n",
      "w1:  [14.3521292] w2:  [-4.96083188] bias:  [16.53548017] loss:  53.55465012401886\n",
      "Epoch:  442 / 1000\n",
      "w1:  [14.36253768] w2:  [-4.97899068] bias:  [16.53553285] loss:  53.51077927529438\n",
      "Epoch:  443 / 1000\n",
      "w1:  [14.37293637] w2:  [-4.99713209] bias:  [16.53558531] loss:  53.466992029782176\n",
      "Epoch:  444 / 1000\n",
      "w1:  [14.38332528] w2:  [-5.01525613] bias:  [16.53563754] loss:  53.4232882281401\n",
      "Epoch:  445 / 1000\n",
      "w1:  [14.39370443] w2:  [-5.03336282] bias:  [16.53568955] loss:  53.379667711329795\n",
      "Epoch:  446 / 1000\n",
      "w1:  [14.40407383] w2:  [-5.05145216] bias:  [16.53574134] loss:  53.336130320616135\n",
      "Epoch:  447 / 1000\n",
      "w1:  [14.41443348] w2:  [-5.06952418] bias:  [16.53579291] loss:  53.29267589756659\n",
      "Epoch:  448 / 1000\n",
      "w1:  [14.4247834] w2:  [-5.0875789] bias:  [16.53584426] loss:  53.24930428405072\n",
      "Epoch:  449 / 1000\n",
      "w1:  [14.43512359] w2:  [-5.10561632] bias:  [16.5358954] loss:  53.206015322239566\n",
      "Epoch:  450 / 1000\n",
      "w1:  [14.44545406] w2:  [-5.12363646] bias:  [16.53594632] loss:  53.162808854605025\n",
      "Epoch:  451 / 1000\n",
      "w1:  [14.45577483] w2:  [-5.14163935] bias:  [16.53599703] loss:  53.119684723919356\n",
      "Epoch:  452 / 1000\n",
      "w1:  [14.46608591] w2:  [-5.15962499] bias:  [16.53604752] loss:  53.0766427732545\n",
      "Epoch:  453 / 1000\n",
      "w1:  [14.4763873] w2:  [-5.17759341] bias:  [16.53609781] loss:  53.03368284598164\n",
      "Epoch:  454 / 1000\n",
      "w1:  [14.48667901] w2:  [-5.19554461] bias:  [16.53614789] loss:  52.990804785770486\n",
      "Epoch:  455 / 1000\n",
      "w1:  [14.49696106] w2:  [-5.21347862] bias:  [16.53619776] loss:  52.9480084365888\n",
      "Epoch:  456 / 1000\n",
      "w1:  [14.50723345] w2:  [-5.23139545] bias:  [16.53624743] loss:  52.90529364270178\n",
      "Epoch:  457 / 1000\n",
      "w1:  [14.5174962] w2:  [-5.24929511] bias:  [16.53629689] loss:  52.8626602486715\n",
      "Epoch:  458 / 1000\n",
      "w1:  [14.52774931] w2:  [-5.26717763] bias:  [16.53634615] loss:  52.82010809935634\n",
      "Epoch:  459 / 1000\n",
      "w1:  [14.53799279] w2:  [-5.28504302] bias:  [16.53639521] loss:  52.77763703991044\n",
      "Epoch:  460 / 1000\n",
      "w1:  [14.54822665] w2:  [-5.30289129] bias:  [16.53644406] loss:  52.7352469157831\n",
      "Epoch:  461 / 1000\n",
      "w1:  [14.55845091] w2:  [-5.32072246] bias:  [16.53649272] loss:  52.69293757271822\n",
      "Epoch:  462 / 1000\n",
      "w1:  [14.56866557] w2:  [-5.33853655] bias:  [16.53654118] loss:  52.65070885675375\n",
      "Epoch:  463 / 1000\n",
      "w1:  [14.57887064] w2:  [-5.35633357] bias:  [16.53658944] loss:  52.60856061422116\n",
      "Epoch:  464 / 1000\n",
      "w1:  [14.58906614] w2:  [-5.37411354] bias:  [16.53663751] loss:  52.56649269174476\n",
      "Epoch:  465 / 1000\n",
      "w1:  [14.59925206] w2:  [-5.39187648] bias:  [16.53668538] loss:  52.524504936241335\n",
      "Epoch:  466 / 1000\n",
      "w1:  [14.60942843] w2:  [-5.4096224] bias:  [16.53673306] loss:  52.48259719491934\n",
      "Epoch:  467 / 1000\n",
      "w1:  [14.61959525] w2:  [-5.42735131] bias:  [16.53678054] loss:  52.44076931527857\n",
      "Epoch:  468 / 1000\n",
      "w1:  [14.62975252] w2:  [-5.44506324] bias:  [16.53682784] loss:  52.39902114510951\n",
      "Epoch:  469 / 1000\n",
      "w1:  [14.63990027] w2:  [-5.46275819] bias:  [16.53687494] loss:  52.35735253249268\n",
      "Epoch:  470 / 1000\n",
      "w1:  [14.65003849] w2:  [-5.48043619] bias:  [16.53692186] loss:  52.3157633257983\n",
      "Epoch:  471 / 1000\n",
      "w1:  [14.6601672] w2:  [-5.49809725] bias:  [16.53696858] loss:  52.27425337368552\n",
      "Epoch:  472 / 1000\n",
      "w1:  [14.67028641] w2:  [-5.51574139] bias:  [16.53701512] loss:  52.232822525102\n",
      "Epoch:  473 / 1000\n",
      "w1:  [14.68039613] w2:  [-5.53336862] bias:  [16.53706147] loss:  52.19147062928334\n",
      "Epoch:  474 / 1000\n",
      "w1:  [14.69049636] w2:  [-5.55097896] bias:  [16.53710763] loss:  52.15019753575246\n",
      "Epoch:  475 / 1000\n",
      "w1:  [14.70058712] w2:  [-5.56857242] bias:  [16.53715362] loss:  52.10900309431914\n",
      "Epoch:  476 / 1000\n",
      "w1:  [14.71066841] w2:  [-5.58614902] bias:  [16.53719941] loss:  52.06788715507942\n",
      "Epoch:  477 / 1000\n",
      "w1:  [14.72074025] w2:  [-5.60370878] bias:  [16.53724502] loss:  52.02684956841507\n",
      "Epoch:  478 / 1000\n",
      "w1:  [14.73080264] w2:  [-5.62125172] bias:  [16.53729045] loss:  51.98589018499302\n",
      "Epoch:  479 / 1000\n",
      "w1:  [14.7408556] w2:  [-5.63877783] bias:  [16.5373357] loss:  51.945008855764875\n",
      "Epoch:  480 / 1000\n",
      "w1:  [14.75089913] w2:  [-5.65628716] bias:  [16.53738077] loss:  51.90420543196632\n",
      "Epoch:  481 / 1000\n",
      "w1:  [14.76093323] w2:  [-5.6737797] bias:  [16.53742566] loss:  51.863479765116566\n",
      "Epoch:  482 / 1000\n",
      "w1:  [14.77095794] w2:  [-5.69125548] bias:  [16.53747037] loss:  51.82283170701787\n",
      "Epoch:  483 / 1000\n",
      "w1:  [14.78097324] w2:  [-5.70871451] bias:  [16.5375149] loss:  51.782261109754934\n",
      "Epoch:  484 / 1000\n",
      "w1:  [14.79097915] w2:  [-5.72615681] bias:  [16.53755925] loss:  51.741767825694396\n",
      "Epoch:  485 / 1000\n",
      "w1:  [14.80097567] w2:  [-5.74358238] bias:  [16.53760342] loss:  51.701351707484285\n",
      "Epoch:  486 / 1000\n",
      "w1:  [14.81096283] w2:  [-5.76099126] bias:  [16.53764742] loss:  51.66101260805351\n",
      "Epoch:  487 / 1000\n",
      "w1:  [14.82094062] w2:  [-5.77838346] bias:  [16.53769124] loss:  51.62075038061126\n",
      "Epoch:  488 / 1000\n",
      "w1:  [14.83090906] w2:  [-5.79575898] bias:  [16.53773489] loss:  51.58056487864654\n",
      "Epoch:  489 / 1000\n",
      "w1:  [14.84086816] w2:  [-5.81311785] bias:  [16.53777836] loss:  51.540455955927584\n",
      "Epoch:  490 / 1000\n",
      "w1:  [14.85081791] w2:  [-5.83046008] bias:  [16.53782166] loss:  51.50042346650137\n",
      "Epoch:  491 / 1000\n",
      "w1:  [14.86075835] w2:  [-5.84778569] bias:  [16.53786479] loss:  51.46046726469302\n",
      "Epoch:  492 / 1000\n",
      "w1:  [14.87068946] w2:  [-5.86509469] bias:  [16.53790774] loss:  51.420587205105384\n",
      "Epoch:  493 / 1000\n",
      "w1:  [14.88061127] w2:  [-5.8823871] bias:  [16.53795052] loss:  51.38078314261835\n",
      "Epoch:  494 / 1000\n",
      "w1:  [14.89052378] w2:  [-5.89966294] bias:  [16.53799313] loss:  51.34105493238847\n",
      "Epoch:  495 / 1000\n",
      "w1:  [14.90042699] w2:  [-5.91692221] bias:  [16.53803557] loss:  51.30140242984834\n",
      "Epoch:  496 / 1000\n",
      "w1:  [14.91032093] w2:  [-5.93416495] bias:  [16.53807784] loss:  51.26182549070611\n",
      "Epoch:  497 / 1000\n",
      "w1:  [14.92020559] w2:  [-5.95139115] bias:  [16.53811993] loss:  51.222323970944935\n",
      "Epoch:  498 / 1000\n",
      "w1:  [14.93008099] w2:  [-5.96860084] bias:  [16.53816186] loss:  51.182897726822475\n",
      "Epoch:  499 / 1000\n",
      "w1:  [14.93994714] w2:  [-5.98579404] bias:  [16.53820362] loss:  51.14354661487034\n",
      "Epoch:  500 / 1000\n",
      "w1:  [14.94980404] w2:  [-6.00297075] bias:  [16.53824521] loss:  51.104270491893615\n",
      "Epoch:  501 / 1000\n",
      "w1:  [14.9596517] w2:  [-6.020131] bias:  [16.53828664] loss:  51.065069214970315\n",
      "Epoch:  502 / 1000\n",
      "w1:  [14.96949014] w2:  [-6.0372748] bias:  [16.53832789] loss:  51.025942641450825\n",
      "Epoch:  503 / 1000\n",
      "w1:  [14.97931936] w2:  [-6.05440216] bias:  [16.53836898] loss:  50.98689062895745\n",
      "Epoch:  504 / 1000\n",
      "w1:  [14.98913937] w2:  [-6.0715131] bias:  [16.53840991] loss:  50.94791303538382\n",
      "Epoch:  505 / 1000\n",
      "w1:  [14.99895018] w2:  [-6.08860764] bias:  [16.53845067] loss:  50.90900971889449\n",
      "Epoch:  506 / 1000\n",
      "w1:  [15.0087518] w2:  [-6.1056858] bias:  [16.53849126] loss:  50.87018053792427\n",
      "Epoch:  507 / 1000\n",
      "w1:  [15.01854423] w2:  [-6.12274758] bias:  [16.53853169] loss:  50.831425351177856\n",
      "Epoch:  508 / 1000\n",
      "w1:  [15.02832749] w2:  [-6.139793] bias:  [16.53857195] loss:  50.79274401762918\n",
      "Epoch:  509 / 1000\n",
      "w1:  [15.03810159] w2:  [-6.15682209] bias:  [16.53861205] loss:  50.75413639652102\n",
      "Epoch:  510 / 1000\n",
      "w1:  [15.04786653] w2:  [-6.17383484] bias:  [16.53865198] loss:  50.7156023473644\n",
      "Epoch:  511 / 1000\n",
      "w1:  [15.05762232] w2:  [-6.19083129] bias:  [16.53869176] loss:  50.67714172993815\n",
      "Epoch:  512 / 1000\n",
      "w1:  [15.06736897] w2:  [-6.20781145] bias:  [16.53873137] loss:  50.638754404288306\n",
      "Epoch:  513 / 1000\n",
      "w1:  [15.0771065] w2:  [-6.22477532] bias:  [16.53877082] loss:  50.60044023072767\n",
      "Epoch:  514 / 1000\n",
      "w1:  [15.0868349] w2:  [-6.24172293] bias:  [16.5388101] loss:  50.56219906983531\n",
      "Epoch:  515 / 1000\n",
      "w1:  [15.09655419] w2:  [-6.25865429] bias:  [16.53884923] loss:  50.524030782455974\n",
      "Epoch:  516 / 1000\n",
      "w1:  [15.10626438] w2:  [-6.27556942] bias:  [16.53888819] loss:  50.485935229699685\n",
      "Epoch:  517 / 1000\n",
      "w1:  [15.11596547] w2:  [-6.29246834] bias:  [16.53892699] loss:  50.44791227294115\n",
      "Epoch:  518 / 1000\n",
      "w1:  [15.12565748] w2:  [-6.30935105] bias:  [16.53896563] loss:  50.4099617738193\n",
      "Epoch:  519 / 1000\n",
      "w1:  [15.13534041] w2:  [-6.32621757] bias:  [16.53900411] loss:  50.37208359423677\n",
      "Epoch:  520 / 1000\n",
      "w1:  [15.14501428] w2:  [-6.34306792] bias:  [16.53904244] loss:  50.33427759635942\n",
      "Epoch:  521 / 1000\n",
      "w1:  [15.15467908] w2:  [-6.35990212] bias:  [16.5390806] loss:  50.29654364261581\n",
      "Epoch:  522 / 1000\n",
      "w1:  [15.16433483] w2:  [-6.37672018] bias:  [16.5391186] loss:  50.258881595696685\n",
      "Epoch:  523 / 1000\n",
      "w1:  [15.17398154] w2:  [-6.39352211] bias:  [16.53915645] loss:  50.22129131855451\n",
      "Epoch:  524 / 1000\n",
      "w1:  [15.18361922] w2:  [-6.41030793] bias:  [16.53919414] loss:  50.18377267440296\n",
      "Epoch:  525 / 1000\n",
      "w1:  [15.19324787] w2:  [-6.42707766] bias:  [16.53923167] loss:  50.146325526716424\n",
      "Epoch:  526 / 1000\n",
      "w1:  [15.20286751] w2:  [-6.4438313] bias:  [16.53926904] loss:  50.10894973922948\n",
      "Epoch:  527 / 1000\n",
      "w1:  [15.21247814] w2:  [-6.46056889] bias:  [16.53930625] loss:  50.07164517593644\n",
      "Epoch:  528 / 1000\n",
      "w1:  [15.22207977] w2:  [-6.47729042] bias:  [16.53934331] loss:  50.03441170109082\n",
      "Epoch:  529 / 1000\n",
      "w1:  [15.23167241] w2:  [-6.49399593] bias:  [16.53938021] loss:  49.99724917920488\n",
      "Epoch:  530 / 1000\n",
      "w1:  [15.24125606] w2:  [-6.51068541] bias:  [16.53941696] loss:  49.96015747504911\n",
      "Epoch:  531 / 1000\n",
      "w1:  [15.25083075] w2:  [-6.52735889] bias:  [16.53945355] loss:  49.92313645365172\n",
      "Epoch:  532 / 1000\n",
      "w1:  [15.26039647] w2:  [-6.54401639] bias:  [16.53948998] loss:  49.8861859802982\n",
      "Epoch:  533 / 1000\n",
      "w1:  [15.26995324] w2:  [-6.56065791] bias:  [16.53952626] loss:  49.84930592053078\n",
      "Epoch:  534 / 1000\n",
      "w1:  [15.27950105] w2:  [-6.57728348] bias:  [16.53956238] loss:  49.81249614014796\n",
      "Epoch:  535 / 1000\n",
      "w1:  [15.28903993] w2:  [-6.5938931] bias:  [16.53959835] loss:  49.77575650520403\n",
      "Epoch:  536 / 1000\n",
      "w1:  [15.29856988] w2:  [-6.61048679] bias:  [16.53963416] loss:  49.73908688200856\n",
      "Epoch:  537 / 1000\n",
      "w1:  [15.30809091] w2:  [-6.62706458] bias:  [16.53966982] loss:  49.702487137125935\n",
      "Epoch:  538 / 1000\n",
      "w1:  [15.31760303] w2:  [-6.64362647] bias:  [16.53970533] loss:  49.665957137374875\n",
      "Epoch:  539 / 1000\n",
      "w1:  [15.32710624] w2:  [-6.66017247] bias:  [16.53974068] loss:  49.62949674982791\n",
      "Epoch:  540 / 1000\n",
      "w1:  [15.33660055] w2:  [-6.67670261] bias:  [16.53977588] loss:  49.59310584181093\n",
      "Epoch:  541 / 1000\n",
      "w1:  [15.34608598] w2:  [-6.6932169] bias:  [16.53981093] loss:  49.556784280902725\n",
      "Epoch:  542 / 1000\n",
      "w1:  [15.35556253] w2:  [-6.70971536] bias:  [16.53984582] loss:  49.52053193493444\n",
      "Epoch:  543 / 1000\n",
      "w1:  [15.36503021] w2:  [-6.72619799] bias:  [16.53988056] loss:  49.48434867198912\n",
      "Epoch:  544 / 1000\n",
      "w1:  [15.37448903] w2:  [-6.74266482] bias:  [16.53991515] loss:  49.448234360401266\n",
      "Epoch:  545 / 1000\n",
      "w1:  [15.38393899] w2:  [-6.75911585] bias:  [16.53994958] loss:  49.4121888687563\n",
      "Epoch:  546 / 1000\n",
      "w1:  [15.39338011] w2:  [-6.77555111] bias:  [16.53998387] loss:  49.376212065890144\n",
      "Epoch:  547 / 1000\n",
      "w1:  [15.40281239] w2:  [-6.79197061] bias:  [16.540018] loss:  49.34030382088867\n",
      "Epoch:  548 / 1000\n",
      "w1:  [15.41223585] w2:  [-6.80837437] bias:  [16.54005198] loss:  49.30446400308731\n",
      "Epoch:  549 / 1000\n",
      "w1:  [15.42165048] w2:  [-6.82476239] bias:  [16.54008581] loss:  49.268692482070485\n",
      "Epoch:  550 / 1000\n",
      "w1:  [15.43105631] w2:  [-6.8411347] bias:  [16.54011949] loss:  49.23298912767125\n",
      "Epoch:  551 / 1000\n",
      "w1:  [15.44045333] w2:  [-6.8574913] bias:  [16.54015302] loss:  49.197353809970686\n",
      "Epoch:  552 / 1000\n",
      "w1:  [15.44984156] w2:  [-6.87383222] bias:  [16.5401864] loss:  49.16178639929751\n",
      "Epoch:  553 / 1000\n",
      "w1:  [15.459221] w2:  [-6.89015747] bias:  [16.54021963] loss:  49.12628676622761\n",
      "Epoch:  554 / 1000\n",
      "w1:  [15.46859166] w2:  [-6.90646707] bias:  [16.54025271] loss:  49.09085478158352\n",
      "Epoch:  555 / 1000\n",
      "w1:  [15.47795356] w2:  [-6.92276102] bias:  [16.54028564] loss:  49.055490316434\n",
      "Epoch:  556 / 1000\n",
      "w1:  [15.48730669] w2:  [-6.93903935] bias:  [16.54031842] loss:  49.02019324209354\n",
      "Epoch:  557 / 1000\n",
      "w1:  [15.49665108] w2:  [-6.95530206] bias:  [16.54035105] loss:  48.984963430121866\n",
      "Epoch:  558 / 1000\n",
      "w1:  [15.50598671] w2:  [-6.97154918] bias:  [16.54038353] loss:  48.94980075232356\n",
      "Epoch:  559 / 1000\n",
      "w1:  [15.51531362] w2:  [-6.98778072] bias:  [16.54041586] loss:  48.91470508074751\n",
      "Epoch:  560 / 1000\n",
      "w1:  [15.52463179] w2:  [-7.00399669] bias:  [16.54044805] loss:  48.87967628768646\n",
      "Epoch:  561 / 1000\n",
      "w1:  [15.53394125] w2:  [-7.02019711] bias:  [16.54048008] loss:  48.844714245676556\n",
      "Epoch:  562 / 1000\n",
      "w1:  [15.54324199] w2:  [-7.03638199] bias:  [16.54051197] loss:  48.80981882749691\n",
      "Epoch:  563 / 1000\n",
      "w1:  [15.55253404] w2:  [-7.05255135] bias:  [16.54054371] loss:  48.774989906169104\n",
      "Epoch:  564 / 1000\n",
      "w1:  [15.56181739] w2:  [-7.0687052] bias:  [16.54057531] loss:  48.74022735495671\n",
      "Epoch:  565 / 1000\n",
      "w1:  [15.57109205] w2:  [-7.08484356] bias:  [16.54060675] loss:  48.705531047364865\n",
      "Epoch:  566 / 1000\n",
      "w1:  [15.58035804] w2:  [-7.10096644] bias:  [16.54063805] loss:  48.670900857139806\n",
      "Epoch:  567 / 1000\n",
      "w1:  [15.58961536] w2:  [-7.11707386] bias:  [16.5406692] loss:  48.6363366582684\n",
      "Epoch:  568 / 1000\n",
      "w1:  [15.59886401] w2:  [-7.13316583] bias:  [16.54070021] loss:  48.60183832497767\n",
      "Epoch:  569 / 1000\n",
      "w1:  [15.60810402] w2:  [-7.14924237] bias:  [16.54073107] loss:  48.567405731734404\n",
      "Epoch:  570 / 1000\n",
      "w1:  [15.61733538] w2:  [-7.16530349] bias:  [16.54076178] loss:  48.53303875324457\n",
      "Epoch:  571 / 1000\n",
      "w1:  [15.6265581] w2:  [-7.1813492] bias:  [16.54079234] loss:  48.49873726445302\n",
      "Epoch:  572 / 1000\n",
      "w1:  [15.6357722] w2:  [-7.19737952] bias:  [16.54082276] loss:  48.4645011405429\n",
      "Epoch:  573 / 1000\n",
      "w1:  [15.64497767] w2:  [-7.21339447] bias:  [16.54085304] loss:  48.430330256935264\n",
      "Epoch:  574 / 1000\n",
      "w1:  [15.65417454] w2:  [-7.22939406] bias:  [16.54088317] loss:  48.39622448928863\n",
      "Epoch:  575 / 1000\n",
      "w1:  [15.6633628] w2:  [-7.24537831] bias:  [16.54091315] loss:  48.36218371349847\n",
      "Epoch:  576 / 1000\n",
      "w1:  [15.67254246] w2:  [-7.26134722] bias:  [16.54094299] loss:  48.328207805696806\n",
      "Epoch:  577 / 1000\n",
      "w1:  [15.68171354] w2:  [-7.27730082] bias:  [16.54097268] loss:  48.29429664225176\n",
      "Epoch:  578 / 1000\n",
      "w1:  [15.69087605] w2:  [-7.29323911] bias:  [16.54100223] loss:  48.260450099767056\n",
      "Epoch:  579 / 1000\n",
      "w1:  [15.70002998] w2:  [-7.30916212] bias:  [16.54103163] loss:  48.22666805508164\n",
      "Epoch:  580 / 1000\n",
      "w1:  [15.70917535] w2:  [-7.32506985] bias:  [16.54106089] loss:  48.192950385269164\n",
      "Epoch:  581 / 1000\n",
      "w1:  [15.71831216] w2:  [-7.34096233] bias:  [16.54109001] loss:  48.15929696763759\n",
      "Epoch:  582 / 1000\n",
      "w1:  [15.72744043] w2:  [-7.35683956] bias:  [16.54111898] loss:  48.125707679728755\n",
      "Epoch:  583 / 1000\n",
      "w1:  [15.73656016] w2:  [-7.37270157] bias:  [16.54114781] loss:  48.09218239931779\n",
      "Epoch:  584 / 1000\n",
      "w1:  [15.74567136] w2:  [-7.38854836] bias:  [16.54117649] loss:  48.05872100441292\n",
      "Epoch:  585 / 1000\n",
      "w1:  [15.75477404] w2:  [-7.40437995] bias:  [16.54120503] loss:  48.02532337325475\n",
      "Epoch:  586 / 1000\n",
      "w1:  [15.76386821] w2:  [-7.42019635] bias:  [16.54123343] loss:  47.99198938431606\n",
      "Epoch:  587 / 1000\n",
      "w1:  [15.77295387] w2:  [-7.43599759] bias:  [16.54126168] loss:  47.958718916301166\n",
      "Epoch:  588 / 1000\n",
      "w1:  [15.78203103] w2:  [-7.45178367] bias:  [16.5412898] loss:  47.925511848145625\n",
      "Epoch:  589 / 1000\n",
      "w1:  [15.7910997] w2:  [-7.4675546] bias:  [16.54131776] loss:  47.89236805901569\n",
      "Epoch:  590 / 1000\n",
      "w1:  [15.8001599] w2:  [-7.48331041] bias:  [16.54134559] loss:  47.859287428307994\n",
      "Epoch:  591 / 1000\n",
      "w1:  [15.80921162] w2:  [-7.4990511] bias:  [16.54137327] loss:  47.82626983564892\n",
      "Epoch:  592 / 1000\n",
      "w1:  [15.81825487] w2:  [-7.5147767] bias:  [16.54140082] loss:  47.79331516089437\n",
      "Epoch:  593 / 1000\n",
      "w1:  [15.82728967] w2:  [-7.53048721] bias:  [16.54142821] loss:  47.76042328412919\n",
      "Epoch:  594 / 1000\n",
      "w1:  [15.83631602] w2:  [-7.54618266] bias:  [16.54145547] loss:  47.72759408566681\n",
      "Epoch:  595 / 1000\n",
      "w1:  [15.84533393] w2:  [-7.56186304] bias:  [16.54148259] loss:  47.69482744604873\n",
      "Epoch:  596 / 1000\n",
      "w1:  [15.85434341] w2:  [-7.57752839] bias:  [16.54150956] loss:  47.662123246044146\n",
      "Epoch:  597 / 1000\n",
      "w1:  [15.86334446] w2:  [-7.59317871] bias:  [16.5415364] loss:  47.629481366649536\n",
      "Epoch:  598 / 1000\n",
      "w1:  [15.8723371] w2:  [-7.60881401] bias:  [16.54156309] loss:  47.59690168908815\n",
      "Epoch:  599 / 1000\n",
      "w1:  [15.88132132] w2:  [-7.62443432] bias:  [16.54158964] loss:  47.56438409480965\n",
      "Epoch:  600 / 1000\n",
      "w1:  [15.89029715] w2:  [-7.64003964] bias:  [16.54161605] loss:  47.5319284654896\n",
      "Epoch:  601 / 1000\n",
      "w1:  [15.89926458] w2:  [-7.65563] bias:  [16.54164232] loss:  47.49953468302917\n",
      "Epoch:  602 / 1000\n",
      "w1:  [15.90822363] w2:  [-7.6712054] bias:  [16.54166845] loss:  47.46720262955452\n",
      "Epoch:  603 / 1000\n",
      "w1:  [15.9171743] w2:  [-7.68676586] bias:  [16.54169444] loss:  47.434932187416535\n",
      "Epoch:  604 / 1000\n",
      "w1:  [15.92611661] w2:  [-7.70231139] bias:  [16.54172029] loss:  47.40272323919032\n",
      "Epoch:  605 / 1000\n",
      "w1:  [15.93505055] w2:  [-7.71784201] bias:  [16.541746] loss:  47.37057566767477\n",
      "Epoch:  606 / 1000\n",
      "w1:  [15.94397614] w2:  [-7.73335773] bias:  [16.54177157] loss:  47.33848935589217\n",
      "Epoch:  607 / 1000\n",
      "w1:  [15.95289339] w2:  [-7.74885856] bias:  [16.541797] loss:  47.30646418708777\n",
      "Epoch:  608 / 1000\n",
      "w1:  [15.96180229] w2:  [-7.76434453] bias:  [16.54182229] loss:  47.27450004472931\n",
      "Epoch:  609 / 1000\n",
      "w1:  [15.97070287] w2:  [-7.77981564] bias:  [16.54184744] loss:  47.242596812506676\n",
      "Epoch:  610 / 1000\n",
      "w1:  [15.97959513] w2:  [-7.79527191] bias:  [16.54187245] loss:  47.2107543743314\n",
      "Epoch:  611 / 1000\n",
      "w1:  [15.98847908] w2:  [-7.81071335] bias:  [16.54189732] loss:  47.17897261433632\n",
      "Epoch:  612 / 1000\n",
      "w1:  [15.99735472] w2:  [-7.82613998] bias:  [16.54192206] loss:  47.147251416875044\n",
      "Epoch:  613 / 1000\n",
      "w1:  [16.00622206] w2:  [-7.84155181] bias:  [16.54194665] loss:  47.11559066652164\n",
      "Epoch:  614 / 1000\n",
      "w1:  [16.01508111] w2:  [-7.85694886] bias:  [16.54197111] loss:  47.083990248070165\n",
      "Epoch:  615 / 1000\n",
      "w1:  [16.02393189] w2:  [-7.87233113] bias:  [16.54199543] loss:  47.052450046534254\n",
      "Epoch:  616 / 1000\n",
      "w1:  [16.03277439] w2:  [-7.88769865] bias:  [16.54201961] loss:  47.02096994714667\n",
      "Epoch:  617 / 1000\n",
      "w1:  [16.04160862] w2:  [-7.90305142] bias:  [16.54204365] loss:  46.98954983535897\n",
      "Epoch:  618 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:  [16.05043459] w2:  [-7.91838947] bias:  [16.54206756] loss:  46.958189596840974\n",
      "Epoch:  619 / 1000\n",
      "w1:  [16.05925232] w2:  [-7.9337128] bias:  [16.54209133] loss:  46.92688911748046\n",
      "Epoch:  620 / 1000\n",
      "w1:  [16.0680618] w2:  [-7.94902143] bias:  [16.54211496] loss:  46.895648283382656\n",
      "Epoch:  621 / 1000\n",
      "w1:  [16.07686305] w2:  [-7.96431537] bias:  [16.54213845] loss:  46.8644669808699\n",
      "Epoch:  622 / 1000\n",
      "w1:  [16.08565607] w2:  [-7.97959464] bias:  [16.5421618] loss:  46.83334509648117\n",
      "Epoch:  623 / 1000\n",
      "w1:  [16.09444088] w2:  [-7.99485925] bias:  [16.54218502] loss:  46.8022825169717\n",
      "Epoch:  624 / 1000\n",
      "w1:  [16.10321747] w2:  [-8.01010922] bias:  [16.5422081] loss:  46.77127912931256\n",
      "Epoch:  625 / 1000\n",
      "w1:  [16.11198586] w2:  [-8.02534456] bias:  [16.54223105] loss:  46.740334820690265\n",
      "Epoch:  626 / 1000\n",
      "w1:  [16.12074606] w2:  [-8.04056528] bias:  [16.54225386] loss:  46.70944947850632\n",
      "Epoch:  627 / 1000\n",
      "w1:  [16.12949806] w2:  [-8.0557714] bias:  [16.54227653] loss:  46.67862299037686\n",
      "Epoch:  628 / 1000\n",
      "w1:  [16.13824189] w2:  [-8.07096293] bias:  [16.54229906] loss:  46.64785524413221\n",
      "Epoch:  629 / 1000\n",
      "w1:  [16.14697755] w2:  [-8.08613988] bias:  [16.54232146] loss:  46.617146127816454\n",
      "Epoch:  630 / 1000\n",
      "w1:  [16.15570504] w2:  [-8.10130228] bias:  [16.54234373] loss:  46.5864955296871\n",
      "Epoch:  631 / 1000\n",
      "w1:  [16.16442437] w2:  [-8.11645012] bias:  [16.54236585] loss:  46.55590333821462\n",
      "Epoch:  632 / 1000\n",
      "w1:  [16.17313556] w2:  [-8.13158344] bias:  [16.54238785] loss:  46.52536944208202\n",
      "Epoch:  633 / 1000\n",
      "w1:  [16.18183861] w2:  [-8.14670223] bias:  [16.5424097] loss:  46.49489373018453\n",
      "Epoch:  634 / 1000\n",
      "w1:  [16.19053352] w2:  [-8.16180652] bias:  [16.54243142] loss:  46.46447609162909\n",
      "Epoch:  635 / 1000\n",
      "w1:  [16.19922031] w2:  [-8.17689632] bias:  [16.54245301] loss:  46.43411641573402\n",
      "Epoch:  636 / 1000\n",
      "w1:  [16.20789898] w2:  [-8.19197164] bias:  [16.54247446] loss:  46.40381459202858\n",
      "Epoch:  637 / 1000\n",
      "w1:  [16.21656954] w2:  [-8.20703249] bias:  [16.54249578] loss:  46.37357051025257\n",
      "Epoch:  638 / 1000\n",
      "w1:  [16.225232] w2:  [-8.2220789] bias:  [16.54251696] loss:  46.343384060356\n",
      "Epoch:  639 / 1000\n",
      "w1:  [16.23388636] w2:  [-8.23711087] bias:  [16.54253801] loss:  46.313255132498554\n",
      "Epoch:  640 / 1000\n",
      "w1:  [16.24253264] w2:  [-8.25212841] bias:  [16.54255892] loss:  46.2831836170493\n",
      "Epoch:  641 / 1000\n",
      "w1:  [16.25117084] w2:  [-8.26713155] bias:  [16.5425797] loss:  46.25316940458626\n",
      "Epoch:  642 / 1000\n",
      "w1:  [16.25980096] w2:  [-8.28212029] bias:  [16.54260034] loss:  46.22321238589598\n",
      "Epoch:  643 / 1000\n",
      "w1:  [16.26842303] w2:  [-8.29709465] bias:  [16.54262085] loss:  46.19331245197321\n",
      "Epoch:  644 / 1000\n",
      "w1:  [16.27703703] w2:  [-8.31205465] bias:  [16.54264123] loss:  46.1634694940204\n",
      "Epoch:  645 / 1000\n",
      "w1:  [16.28564299] w2:  [-8.32700029] bias:  [16.54266147] loss:  46.133683403447414\n",
      "Epoch:  646 / 1000\n",
      "w1:  [16.29424091] w2:  [-8.34193159] bias:  [16.54268158] loss:  46.103954071871044\n",
      "Epoch:  647 / 1000\n",
      "w1:  [16.3028308] w2:  [-8.35684856] bias:  [16.54270156] loss:  46.074281391114674\n",
      "Epoch:  648 / 1000\n",
      "w1:  [16.31141266] w2:  [-8.37175122] bias:  [16.5427214] loss:  46.04466525320786\n",
      "Epoch:  649 / 1000\n",
      "w1:  [16.3199865] w2:  [-8.38663958] bias:  [16.54274111] loss:  46.015105550385954\n",
      "Epoch:  650 / 1000\n",
      "w1:  [16.32855233] w2:  [-8.40151365] bias:  [16.54276069] loss:  45.985602175089674\n",
      "Epoch:  651 / 1000\n",
      "w1:  [16.33711016] w2:  [-8.41637346] bias:  [16.54278013] loss:  45.95615501996476\n",
      "Epoch:  652 / 1000\n",
      "w1:  [16.34565999] w2:  [-8.431219] bias:  [16.54279944] loss:  45.92676397786158\n",
      "Epoch:  653 / 1000\n",
      "w1:  [16.35420184] w2:  [-8.4460503] bias:  [16.54281862] loss:  45.89742894183468\n",
      "Epoch:  654 / 1000\n",
      "w1:  [16.36273571] w2:  [-8.46086737] bias:  [16.54283767] loss:  45.86814980514248\n",
      "Epoch:  655 / 1000\n",
      "w1:  [16.3712616] w2:  [-8.47567022] bias:  [16.54285658] loss:  45.83892646124682\n",
      "Epoch:  656 / 1000\n",
      "w1:  [16.37977953] w2:  [-8.49045887] bias:  [16.54287536] loss:  45.80975880381258\n",
      "Epoch:  657 / 1000\n",
      "w1:  [16.38828951] w2:  [-8.50523333] bias:  [16.54289401] loss:  45.78064672670735\n",
      "Epoch:  658 / 1000\n",
      "w1:  [16.39679153] w2:  [-8.51999361] bias:  [16.54291253] loss:  45.75159012400098\n",
      "Epoch:  659 / 1000\n",
      "w1:  [16.40528561] w2:  [-8.53473972] bias:  [16.54293092] loss:  45.722588889965195\n",
      "Epoch:  660 / 1000\n",
      "w1:  [16.41377176] w2:  [-8.54947169] bias:  [16.54294918] loss:  45.69364291907327\n",
      "Epoch:  661 / 1000\n",
      "w1:  [16.42224998] w2:  [-8.56418952] bias:  [16.5429673] loss:  45.664752105999604\n",
      "Epoch:  662 / 1000\n",
      "w1:  [16.43072029] w2:  [-8.57889323] bias:  [16.54298529] loss:  45.63591634561932\n",
      "Epoch:  663 / 1000\n",
      "w1:  [16.43918268] w2:  [-8.59358283] bias:  [16.54300316] loss:  45.6071355330079\n",
      "Epoch:  664 / 1000\n",
      "w1:  [16.44763716] w2:  [-8.60825833] bias:  [16.54302089] loss:  45.57840956344082\n",
      "Epoch:  665 / 1000\n",
      "w1:  [16.45608375] w2:  [-8.62291975] bias:  [16.54303849] loss:  45.54973833239317\n",
      "Epoch:  666 / 1000\n",
      "w1:  [16.46452245] w2:  [-8.6375671] bias:  [16.54305596] loss:  45.52112173553921\n",
      "Epoch:  667 / 1000\n",
      "w1:  [16.47295327] w2:  [-8.6522004] bias:  [16.5430733] loss:  45.49255966875211\n",
      "Epoch:  668 / 1000\n",
      "w1:  [16.48137622] w2:  [-8.66681965] bias:  [16.54309051] loss:  45.46405202810342\n",
      "Epoch:  669 / 1000\n",
      "w1:  [16.48979129] w2:  [-8.68142488] bias:  [16.54310759] loss:  45.435598709862816\n",
      "Epoch:  670 / 1000\n",
      "w1:  [16.49819851] w2:  [-8.69601608] bias:  [16.54312454] loss:  45.4071996104977\n",
      "Epoch:  671 / 1000\n",
      "w1:  [16.50659788] w2:  [-8.71059329] bias:  [16.54314135] loss:  45.37885462667274\n",
      "Epoch:  672 / 1000\n",
      "w1:  [16.5149894] w2:  [-8.72515651] bias:  [16.54315804] loss:  45.35056365524961\n",
      "Epoch:  673 / 1000\n",
      "w1:  [16.52337309] w2:  [-8.73970575] bias:  [16.5431746] loss:  45.322326593286526\n",
      "Epoch:  674 / 1000\n",
      "w1:  [16.53174895] w2:  [-8.75424103] bias:  [16.54319103] loss:  45.29414333803793\n",
      "Epoch:  675 / 1000\n",
      "w1:  [16.54011698] w2:  [-8.76876237] bias:  [16.54320734] loss:  45.26601378695406\n",
      "Epoch:  676 / 1000\n",
      "w1:  [16.5484772] w2:  [-8.78326976] bias:  [16.54322351] loss:  45.237937837680654\n",
      "Epoch:  677 / 1000\n",
      "w1:  [16.55682962] w2:  [-8.79776324] bias:  [16.54323955] loss:  45.20991538805846\n",
      "Epoch:  678 / 1000\n",
      "w1:  [16.56517423] w2:  [-8.8122428] bias:  [16.54325546] loss:  45.18194633612302\n",
      "Epoch:  679 / 1000\n",
      "w1:  [16.57351105] w2:  [-8.82670847] bias:  [16.54327125] loss:  45.15403058010415\n",
      "Epoch:  680 / 1000\n",
      "w1:  [16.58184009] w2:  [-8.84116026] bias:  [16.54328691] loss:  45.126168018425666\n",
      "Epoch:  681 / 1000\n",
      "w1:  [16.59016135] w2:  [-8.85559818] bias:  [16.54330243] loss:  45.098358549704976\n",
      "Epoch:  682 / 1000\n",
      "w1:  [16.59847484] w2:  [-8.87002225] bias:  [16.54331783] loss:  45.0706020727527\n",
      "Epoch:  683 / 1000\n",
      "w1:  [16.60678057] w2:  [-8.88443247] bias:  [16.54333311] loss:  45.042898486572334\n",
      "Epoch:  684 / 1000\n",
      "w1:  [16.61507854] w2:  [-8.89882886] bias:  [16.54334825] loss:  45.01524769035989\n",
      "Epoch:  685 / 1000\n",
      "w1:  [16.62336876] w2:  [-8.91321143] bias:  [16.54336326] loss:  44.98764958350346\n",
      "Epoch:  686 / 1000\n",
      "w1:  [16.63165125] w2:  [-8.92758021] bias:  [16.54337815] loss:  44.96010406558293\n",
      "Epoch:  687 / 1000\n",
      "w1:  [16.639926] w2:  [-8.94193519] bias:  [16.54339291] loss:  44.93261103636958\n",
      "Epoch:  688 / 1000\n",
      "w1:  [16.64819302] w2:  [-8.9562764] bias:  [16.54340755] loss:  44.905170395825685\n",
      "Epoch:  689 / 1000\n",
      "w1:  [16.65645233] w2:  [-8.97060384] bias:  [16.54342205] loss:  44.87778204410423\n",
      "Epoch:  690 / 1000\n",
      "w1:  [16.66470392] w2:  [-8.98491753] bias:  [16.54343643] loss:  44.850445881548474\n",
      "Epoch:  691 / 1000\n",
      "w1:  [16.67294781] w2:  [-8.99921749] bias:  [16.54345068] loss:  44.82316180869164\n",
      "Epoch:  692 / 1000\n",
      "w1:  [16.68118401] w2:  [-9.01350372] bias:  [16.5434648] loss:  44.795929726256496\n",
      "Epoch:  693 / 1000\n",
      "w1:  [16.68941252] w2:  [-9.02777624] bias:  [16.5434788] loss:  44.768749535155074\n",
      "Epoch:  694 / 1000\n",
      "w1:  [16.69763334] w2:  [-9.04203506] bias:  [16.54349267] loss:  44.7416211364882\n",
      "Epoch:  695 / 1000\n",
      "w1:  [16.70584649] w2:  [-9.0562802] bias:  [16.54350642] loss:  44.71454443154525\n",
      "Epoch:  696 / 1000\n",
      "w1:  [16.71405197] w2:  [-9.07051167] bias:  [16.54352003] loss:  44.68751932180371\n",
      "Epoch:  697 / 1000\n",
      "w1:  [16.72224979] w2:  [-9.08472947] bias:  [16.54353353] loss:  44.660545708928844\n",
      "Epoch:  698 / 1000\n",
      "w1:  [16.73043996] w2:  [-9.09893363] bias:  [16.54354689] loss:  44.63362349477335\n",
      "Epoch:  699 / 1000\n",
      "w1:  [16.73862249] w2:  [-9.11312416] bias:  [16.54356013] loss:  44.60675258137699\n",
      "Epoch:  700 / 1000\n",
      "w1:  [16.74679738] w2:  [-9.12730107] bias:  [16.54357324] loss:  44.579932870966196\n",
      "Epoch:  701 / 1000\n",
      "w1:  [16.75496463] w2:  [-9.14146437] bias:  [16.54358623] loss:  44.553164265953804\n",
      "Epoch:  702 / 1000\n",
      "w1:  [16.76312426] w2:  [-9.15561408] bias:  [16.5435991] loss:  44.526446668938604\n",
      "Epoch:  703 / 1000\n",
      "w1:  [16.77127628] w2:  [-9.16975021] bias:  [16.54361183] loss:  44.49977998270506\n",
      "Epoch:  704 / 1000\n",
      "w1:  [16.77942069] w2:  [-9.18387277] bias:  [16.54362444] loss:  44.47316411022289\n",
      "Epoch:  705 / 1000\n",
      "w1:  [16.78755749] w2:  [-9.19798178] bias:  [16.54363693] loss:  44.44659895464676\n",
      "Epoch:  706 / 1000\n",
      "w1:  [16.7956867] w2:  [-9.21207724] bias:  [16.54364929] loss:  44.42008441931593\n",
      "Epoch:  707 / 1000\n",
      "w1:  [16.80380833] w2:  [-9.22615917] bias:  [16.54366153] loss:  44.393620407753865\n",
      "Epoch:  708 / 1000\n",
      "w1:  [16.81192237] w2:  [-9.24022759] bias:  [16.54367364] loss:  44.36720682366794\n",
      "Epoch:  709 / 1000\n",
      "w1:  [16.82002884] w2:  [-9.25428251] bias:  [16.54368563] loss:  44.34084357094904\n",
      "Epoch:  710 / 1000\n",
      "w1:  [16.82812774] w2:  [-9.26832393] bias:  [16.54369749] loss:  44.314530553671204\n",
      "Epoch:  711 / 1000\n",
      "w1:  [16.83621909] w2:  [-9.28235188] bias:  [16.54370923] loss:  44.28826767609136\n",
      "Epoch:  712 / 1000\n",
      "w1:  [16.84430288] w2:  [-9.29636636] bias:  [16.54372084] loss:  44.262054842648844\n",
      "Epoch:  713 / 1000\n",
      "w1:  [16.85237913] w2:  [-9.31036739] bias:  [16.54373233] loss:  44.235891957965194\n",
      "Epoch:  714 / 1000\n",
      "w1:  [16.86044785] w2:  [-9.32435499] bias:  [16.5437437] loss:  44.20977892684369\n",
      "Epoch:  715 / 1000\n",
      "w1:  [16.86850903] w2:  [-9.33832915] bias:  [16.54375494] loss:  44.18371565426905\n",
      "Epoch:  716 / 1000\n",
      "w1:  [16.87656269] w2:  [-9.35228991] bias:  [16.54376606] loss:  44.15770204540712\n",
      "Epoch:  717 / 1000\n",
      "w1:  [16.88460883] w2:  [-9.36623726] bias:  [16.54377705] loss:  44.13173800560446\n",
      "Epoch:  718 / 1000\n",
      "w1:  [16.89264747] w2:  [-9.38017122] bias:  [16.54378793] loss:  44.105823440388065\n",
      "Epoch:  719 / 1000\n",
      "w1:  [16.90067861] w2:  [-9.39409181] bias:  [16.54379867] loss:  44.079958255464945\n",
      "Epoch:  720 / 1000\n",
      "w1:  [16.90870225] w2:  [-9.40799904] bias:  [16.5438093] loss:  44.05414235672187\n",
      "Epoch:  721 / 1000\n",
      "w1:  [16.9167184] w2:  [-9.42189292] bias:  [16.5438198] loss:  44.02837565022497\n",
      "Epoch:  722 / 1000\n",
      "w1:  [16.92472707] w2:  [-9.43577346] bias:  [16.54383018] loss:  44.0026580422194\n",
      "Epoch:  723 / 1000\n",
      "w1:  [16.93272828] w2:  [-9.44964068] bias:  [16.54384044] loss:  43.97698943912902\n",
      "Epoch:  724 / 1000\n",
      "w1:  [16.94072201] w2:  [-9.46349459] bias:  [16.54385057] loss:  43.95136974755602\n",
      "Epoch:  725 / 1000\n",
      "w1:  [16.94870829] w2:  [-9.4773352] bias:  [16.54386058] loss:  43.92579887428062\n",
      "Epoch:  726 / 1000\n",
      "w1:  [16.95668711] w2:  [-9.49116252] bias:  [16.54387047] loss:  43.900276726260714\n",
      "Epoch:  727 / 1000\n",
      "w1:  [16.96465849] w2:  [-9.50497657] bias:  [16.54388024] loss:  43.8748032106315\n",
      "Epoch:  728 / 1000\n",
      "w1:  [16.97262244] w2:  [-9.51877736] bias:  [16.54388988] loss:  43.84937823470519\n",
      "Epoch:  729 / 1000\n",
      "w1:  [16.98057895] w2:  [-9.53256491] bias:  [16.54389941] loss:  43.82400170597068\n",
      "Epoch:  730 / 1000\n",
      "w1:  [16.98852804] w2:  [-9.54633921] bias:  [16.54390881] loss:  43.798673532093126\n",
      "Epoch:  731 / 1000\n",
      "w1:  [16.99646971] w2:  [-9.5601003] bias:  [16.54391809] loss:  43.77339362091374\n",
      "Epoch:  732 / 1000\n",
      "w1:  [17.00440398] w2:  [-9.57384817] bias:  [16.54392724] loss:  43.7481618804493\n",
      "Epoch:  733 / 1000\n",
      "w1:  [17.01233084] w2:  [-9.58758285] bias:  [16.54393628] loss:  43.72297821889198\n",
      "Epoch:  734 / 1000\n",
      "w1:  [17.02025031] w2:  [-9.60130434] bias:  [16.5439452] loss:  43.69784254460888\n",
      "Epoch:  735 / 1000\n",
      "w1:  [17.02816239] w2:  [-9.61501266] bias:  [16.54395399] loss:  43.672754766141786\n",
      "Epoch:  736 / 1000\n",
      "w1:  [17.03606709] w2:  [-9.62870782] bias:  [16.54396266] loss:  43.647714792206756\n",
      "Epoch:  737 / 1000\n",
      "w1:  [17.04396441] w2:  [-9.64238984] bias:  [16.54397121] loss:  43.62272253169386\n",
      "Epoch:  738 / 1000\n",
      "w1:  [17.05185437] w2:  [-9.65605872] bias:  [16.54397965] loss:  43.59777789366682\n",
      "Epoch:  739 / 1000\n",
      "w1:  [17.05973697] w2:  [-9.66971448] bias:  [16.54398796] loss:  43.572880787362635\n",
      "Epoch:  740 / 1000\n",
      "w1:  [17.06761221] w2:  [-9.68335713] bias:  [16.54399615] loss:  43.54803112219137\n",
      "Epoch:  741 / 1000\n",
      "w1:  [17.07548011] w2:  [-9.69698668] bias:  [16.54400422] loss:  43.523228807735656\n",
      "Epoch:  742 / 1000\n",
      "w1:  [17.08334067] w2:  [-9.71060314] bias:  [16.54401217] loss:  43.49847375375053\n",
      "Epoch:  743 / 1000\n",
      "w1:  [17.0911939] w2:  [-9.72420654] bias:  [16.54402] loss:  43.473765870163\n",
      "Epoch:  744 / 1000\n",
      "w1:  [17.0990398] w2:  [-9.73779688] bias:  [16.5440277] loss:  43.44910506707174\n",
      "Epoch:  745 / 1000\n",
      "w1:  [17.10687838] w2:  [-9.75137417] bias:  [16.54403529] loss:  43.42449125474679\n",
      "Epoch:  746 / 1000\n",
      "w1:  [17.11470966] w2:  [-9.76493842] bias:  [16.54404276] loss:  43.399924343629195\n",
      "Epoch:  747 / 1000\n",
      "w1:  [17.12253363] w2:  [-9.77848965] bias:  [16.54405011] loss:  43.3754042443307\n",
      "Epoch:  748 / 1000\n",
      "w1:  [17.1303503] w2:  [-9.79202788] bias:  [16.54405735] loss:  43.35093086763342\n",
      "Epoch:  749 / 1000\n",
      "w1:  [17.13815968] w2:  [-9.8055531] bias:  [16.54406446] loss:  43.3265041244895\n",
      "Epoch:  750 / 1000\n",
      "w1:  [17.14596178] w2:  [-9.81906535] bias:  [16.54407145] loss:  43.30212392602084\n",
      "Epoch:  751 / 1000\n",
      "w1:  [17.1537566] w2:  [-9.83256461] bias:  [16.54407832] loss:  43.2777901835187\n",
      "Epoch:  752 / 1000\n",
      "w1:  [17.16154415] w2:  [-9.84605092] bias:  [16.54408508] loss:  43.253502808443415\n",
      "Epoch:  753 / 1000\n",
      "w1:  [17.16932444] w2:  [-9.85952429] bias:  [16.54409171] loss:  43.229261712424105\n",
      "Epoch:  754 / 1000\n",
      "w1:  [17.17709747] w2:  [-9.87298471] bias:  [16.54409823] loss:  43.205066807258284\n",
      "Epoch:  755 / 1000\n",
      "w1:  [17.18486326] w2:  [-9.88643221] bias:  [16.54410463] loss:  43.180918004911604\n",
      "Epoch:  756 / 1000\n",
      "w1:  [17.1926218] w2:  [-9.89986681] bias:  [16.54411091] loss:  43.15681521751746\n",
      "Epoch:  757 / 1000\n",
      "w1:  [17.20037311] w2:  [-9.9132885] bias:  [16.54411707] loss:  43.132758357376765\n",
      "Epoch:  758 / 1000\n",
      "w1:  [17.20811719] w2:  [-9.92669731] bias:  [16.54412311] loss:  43.10874733695757\n",
      "Epoch:  759 / 1000\n",
      "w1:  [17.21585405] w2:  [-9.94009325] bias:  [16.54412904] loss:  43.08478206889473\n",
      "Epoch:  760 / 1000\n",
      "w1:  [17.22358369] w2:  [-9.95347632] bias:  [16.54413484] loss:  43.060862465989636\n",
      "Epoch:  761 / 1000\n",
      "w1:  [17.23130613] w2:  [-9.96684654] bias:  [16.54414053] loss:  43.03698844120988\n",
      "Epoch:  762 / 1000\n",
      "w1:  [17.23902136] w2:  [-9.98020393] bias:  [16.5441461] loss:  43.013159907688895\n",
      "Epoch:  763 / 1000\n",
      "w1:  [17.24672941] w2:  [-9.99354849] bias:  [16.54415156] loss:  42.989376778725735\n",
      "Epoch:  764 / 1000\n",
      "w1:  [17.25443026] w2:  [-10.00688024] bias:  [16.5441569] loss:  42.96563896778464\n",
      "Epoch:  765 / 1000\n",
      "w1:  [17.26212394] w2:  [-10.02019919] bias:  [16.54416211] loss:  42.941946388494834\n",
      "Epoch:  766 / 1000\n",
      "w1:  [17.26981044] w2:  [-10.03350536] bias:  [16.54416722] loss:  42.91829895465013\n",
      "Epoch:  767 / 1000\n",
      "w1:  [17.27748977] w2:  [-10.04679874] bias:  [16.5441722] loss:  42.89469658020864\n",
      "Epoch:  768 / 1000\n",
      "w1:  [17.28516195] w2:  [-10.06007937] bias:  [16.54417707] loss:  42.871139179292484\n",
      "Epoch:  769 / 1000\n",
      "w1:  [17.29282697] w2:  [-10.07334724] bias:  [16.54418182] loss:  42.847626666187445\n",
      "Epoch:  770 / 1000\n",
      "w1:  [17.30048484] w2:  [-10.08660237] bias:  [16.54418646] loss:  42.8241589553427\n",
      "Epoch:  771 / 1000\n",
      "w1:  [17.30813558] w2:  [-10.09984478] bias:  [16.54419098] loss:  42.800735961370435\n",
      "Epoch:  772 / 1000\n",
      "w1:  [17.31577918] w2:  [-10.11307447] bias:  [16.54419538] loss:  42.77735759904563\n",
      "Epoch:  773 / 1000\n",
      "w1:  [17.32341566] w2:  [-10.12629146] bias:  [16.54419966] loss:  42.75402378330564\n",
      "Epoch:  774 / 1000\n",
      "w1:  [17.33104502] w2:  [-10.13949575] bias:  [16.54420383] loss:  42.73073442925003\n",
      "Epoch:  775 / 1000\n",
      "w1:  [17.33866727] w2:  [-10.15268737] bias:  [16.54420789] loss:  42.70748945214008\n",
      "Epoch:  776 / 1000\n",
      "w1:  [17.34628241] w2:  [-10.16586633] bias:  [16.54421183] loss:  42.684288767398655\n",
      "Epoch:  777 / 1000\n",
      "w1:  [17.35389045] w2:  [-10.17903263] bias:  [16.54421565] loss:  42.66113229060978\n",
      "Epoch:  778 / 1000\n",
      "w1:  [17.3614914] w2:  [-10.19218628] bias:  [16.54421935] loss:  42.63801993751839\n",
      "Epoch:  779 / 1000\n",
      "w1:  [17.36908526] w2:  [-10.20532731] bias:  [16.54422294] loss:  42.61495162402998\n",
      "Epoch:  780 / 1000\n",
      "w1:  [17.37667205] w2:  [-10.21845572] bias:  [16.54422642] loss:  42.59192726621036\n",
      "Epoch:  781 / 1000\n",
      "w1:  [17.38425176] w2:  [-10.23157152] bias:  [16.54422978] loss:  42.56894678028528\n",
      "Epoch:  782 / 1000\n",
      "w1:  [17.39182441] w2:  [-10.24467473] bias:  [16.54423302] loss:  42.54601008264017\n",
      "Epoch:  783 / 1000\n",
      "w1:  [17.39939] w2:  [-10.25776535] bias:  [16.54423615] loss:  42.52311708981985\n",
      "Epoch:  784 / 1000\n",
      "w1:  [17.40694854] w2:  [-10.27084341] bias:  [16.54423917] loss:  42.50026771852815\n",
      "Epoch:  785 / 1000\n",
      "w1:  [17.41450004] w2:  [-10.28390891] bias:  [16.54424207] loss:  42.477461885627704\n",
      "Epoch:  786 / 1000\n",
      "w1:  [17.42204449] w2:  [-10.29696186] bias:  [16.54424486] loss:  42.454699508139576\n",
      "Epoch:  787 / 1000\n",
      "w1:  [17.42958192] w2:  [-10.31000228] bias:  [16.54424753] loss:  42.43198050324298\n",
      "Epoch:  788 / 1000\n",
      "w1:  [17.43711232] w2:  [-10.32303017] bias:  [16.54425008] loss:  42.409304788275016\n",
      "Epoch:  789 / 1000\n",
      "w1:  [17.4446357] w2:  [-10.33604556] bias:  [16.54425253] loss:  42.38667228073029\n",
      "Epoch:  790 / 1000\n",
      "w1:  [17.45215207] w2:  [-10.34904844] bias:  [16.54425485] loss:  42.364082898260676\n",
      "Epoch:  791 / 1000\n",
      "w1:  [17.45966143] w2:  [-10.36203885] bias:  [16.54425707] loss:  42.341536558674996\n",
      "Epoch:  792 / 1000\n",
      "w1:  [17.4671638] w2:  [-10.37501677] bias:  [16.54425917] loss:  42.31903317993875\n",
      "Epoch:  793 / 1000\n",
      "w1:  [17.47465917] w2:  [-10.38798224] bias:  [16.54426116] loss:  42.29657268017375\n",
      "Epoch:  794 / 1000\n",
      "w1:  [17.48214756] w2:  [-10.40093525] bias:  [16.54426303] loss:  42.274154977657865\n",
      "Epoch:  795 / 1000\n",
      "w1:  [17.48962898] w2:  [-10.41387583] bias:  [16.54426479] loss:  42.25177999082478\n",
      "Epoch:  796 / 1000\n",
      "w1:  [17.49710342] w2:  [-10.42680397] bias:  [16.54426643] loss:  42.229447638263565\n",
      "Epoch:  797 / 1000\n",
      "w1:  [17.50457089] w2:  [-10.43971971] bias:  [16.54426797] loss:  42.2071578387185\n",
      "Epoch:  798 / 1000\n",
      "w1:  [17.51203141] w2:  [-10.45262304] bias:  [16.54426939] loss:  42.1849105110887\n",
      "Epoch:  799 / 1000\n",
      "w1:  [17.51948497] w2:  [-10.46551398] bias:  [16.54427069] loss:  42.1627055744279\n",
      "Epoch:  800 / 1000\n",
      "w1:  [17.52693159] w2:  [-10.47839254] bias:  [16.54427189] loss:  42.1405429479441\n",
      "Epoch:  801 / 1000\n",
      "w1:  [17.53437127] w2:  [-10.49125873] bias:  [16.54427297] loss:  42.11842255099923\n",
      "Epoch:  802 / 1000\n",
      "w1:  [17.54180402] w2:  [-10.50411257] bias:  [16.54427394] loss:  42.096344303108964\n",
      "Epoch:  803 / 1000\n",
      "w1:  [17.54922984] w2:  [-10.51695406] bias:  [16.54427479] loss:  42.07430812394239\n",
      "Epoch:  804 / 1000\n",
      "w1:  [17.55664875] w2:  [-10.52978322] bias:  [16.54427554] loss:  42.052313933321656\n",
      "Epoch:  805 / 1000\n",
      "w1:  [17.56406074] w2:  [-10.54260006] bias:  [16.54427617] loss:  42.030361651221746\n",
      "Epoch:  806 / 1000\n",
      "w1:  [17.57146583] w2:  [-10.55540459] bias:  [16.54427669] loss:  42.00845119777017\n",
      "Epoch:  807 / 1000\n",
      "w1:  [17.57886401] w2:  [-10.56819682] bias:  [16.54427709] loss:  41.98658249324665\n",
      "Epoch:  808 / 1000\n",
      "w1:  [17.58625531] w2:  [-10.58097677] bias:  [16.54427739] loss:  41.9647554580829\n",
      "Epoch:  809 / 1000\n",
      "w1:  [17.59363972] w2:  [-10.59374445] bias:  [16.54427757] loss:  41.942970012862204\n",
      "Epoch:  810 / 1000\n",
      "w1:  [17.60101725] w2:  [-10.60649986] bias:  [16.54427764] loss:  41.92122607831929\n",
      "Epoch:  811 / 1000\n",
      "w1:  [17.6083879] w2:  [-10.61924302] bias:  [16.5442776] loss:  41.899523575339906\n",
      "Epoch:  812 / 1000\n",
      "w1:  [17.61575169] w2:  [-10.63197395] bias:  [16.54427745] loss:  41.87786242496064\n",
      "Epoch:  813 / 1000\n",
      "w1:  [17.62310862] w2:  [-10.64469265] bias:  [16.54427719] loss:  41.85624254836851\n",
      "Epoch:  814 / 1000\n",
      "w1:  [17.6304587] w2:  [-10.65739913] bias:  [16.54427681] loss:  41.83466386690081\n",
      "Epoch:  815 / 1000\n",
      "w1:  [17.63780193] w2:  [-10.67009341] bias:  [16.54427633] loss:  41.813126302044715\n",
      "Epoch:  816 / 1000\n",
      "w1:  [17.64513832] w2:  [-10.6827755] bias:  [16.54427573] loss:  41.79162977543709\n",
      "Epoch:  817 / 1000\n",
      "w1:  [17.65246787] w2:  [-10.69544541] bias:  [16.54427502] loss:  41.7701742088641\n",
      "Epoch:  818 / 1000\n",
      "w1:  [17.6597906] w2:  [-10.70810314] bias:  [16.54427421] loss:  41.74875952426101\n",
      "Epoch:  819 / 1000\n",
      "w1:  [17.66710651] w2:  [-10.72074873] bias:  [16.54427328] loss:  41.72738564371188\n",
      "Epoch:  820 / 1000\n",
      "w1:  [17.6744156] w2:  [-10.73338217] bias:  [16.54427224] loss:  41.70605248944924\n",
      "Epoch:  821 / 1000\n",
      "w1:  [17.68171789] w2:  [-10.74600347] bias:  [16.54427109] loss:  41.6847599838539\n",
      "Epoch:  822 / 1000\n",
      "w1:  [17.68901337] w2:  [-10.75861265] bias:  [16.54426983] loss:  41.66350804945453\n",
      "Epoch:  823 / 1000\n",
      "w1:  [17.69630206] w2:  [-10.77120972] bias:  [16.54426846] loss:  41.642296608927516\n",
      "Epoch:  824 / 1000\n",
      "w1:  [17.70358396] w2:  [-10.78379469] bias:  [16.54426698] loss:  41.621125585096586\n",
      "Epoch:  825 / 1000\n",
      "w1:  [17.71085908] w2:  [-10.79636758] bias:  [16.54426539] loss:  41.59999490093258\n",
      "Epoch:  826 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:  [17.71812742] w2:  [-10.80892839] bias:  [16.54426369] loss:  41.57890447955313\n",
      "Epoch:  827 / 1000\n",
      "w1:  [17.72538899] w2:  [-10.82147713] bias:  [16.54426188] loss:  41.55785424422244\n",
      "Epoch:  828 / 1000\n",
      "w1:  [17.7326438] w2:  [-10.83401382] bias:  [16.54425996] loss:  41.53684411835091\n",
      "Epoch:  829 / 1000\n",
      "w1:  [17.73989186] w2:  [-10.84653847] bias:  [16.54425794] loss:  41.51587402549497\n",
      "Epoch:  830 / 1000\n",
      "w1:  [17.74713316] w2:  [-10.8590511] bias:  [16.5442558] loss:  41.49494388935672\n",
      "Epoch:  831 / 1000\n",
      "w1:  [17.75436772] w2:  [-10.8715517] bias:  [16.54425355] loss:  41.47405363378367\n",
      "Epoch:  832 / 1000\n",
      "w1:  [17.76159554] w2:  [-10.88404029] bias:  [16.5442512] loss:  41.4532031827685\n",
      "Epoch:  833 / 1000\n",
      "w1:  [17.76881664] w2:  [-10.89651689] bias:  [16.54424873] loss:  41.43239246044873\n",
      "Epoch:  834 / 1000\n",
      "w1:  [17.776031] w2:  [-10.90898151] bias:  [16.54424616] loss:  41.41162139110648\n",
      "Epoch:  835 / 1000\n",
      "w1:  [17.78323865] w2:  [-10.92143415] bias:  [16.54424348] loss:  41.39088989916818\n",
      "Epoch:  836 / 1000\n",
      "w1:  [17.79043959] w2:  [-10.93387484] bias:  [16.54424069] loss:  41.370197909204315\n",
      "Epoch:  837 / 1000\n",
      "w1:  [17.79763383] w2:  [-10.94630357] bias:  [16.54423779] loss:  41.349545345929116\n",
      "Epoch:  838 / 1000\n",
      "w1:  [17.80482136] w2:  [-10.95872036] bias:  [16.54423478] loss:  41.3289321342003\n",
      "Epoch:  839 / 1000\n",
      "w1:  [17.8120022] w2:  [-10.97112523] bias:  [16.54423167] loss:  41.30835819901881\n",
      "Epoch:  840 / 1000\n",
      "w1:  [17.81917636] w2:  [-10.98351818] bias:  [16.54422844] loss:  41.28782346552854\n",
      "Epoch:  841 / 1000\n",
      "w1:  [17.82634384] w2:  [-10.99589923] bias:  [16.54422511] loss:  41.26732785901605\n",
      "Epoch:  842 / 1000\n",
      "w1:  [17.83350464] w2:  [-11.00826838] bias:  [16.54422167] loss:  41.24687130491029\n",
      "Epoch:  843 / 1000\n",
      "w1:  [17.84065878] w2:  [-11.02062566] bias:  [16.54421813] loss:  41.22645372878234\n",
      "Epoch:  844 / 1000\n",
      "w1:  [17.84780625] w2:  [-11.03297106] bias:  [16.54421447] loss:  41.206075056345135\n",
      "Epoch:  845 / 1000\n",
      "w1:  [17.85494707] w2:  [-11.04530461] bias:  [16.54421071] loss:  41.18573521345323\n",
      "Epoch:  846 / 1000\n",
      "w1:  [17.86208125] w2:  [-11.0576263] bias:  [16.54420684] loss:  41.16543412610245\n",
      "Epoch:  847 / 1000\n",
      "w1:  [17.86920878] w2:  [-11.06993617] bias:  [16.54420286] loss:  41.14517172042968\n",
      "Epoch:  848 / 1000\n",
      "w1:  [17.87632967] w2:  [-11.0822342] bias:  [16.54419878] loss:  41.1249479227126\n",
      "Epoch:  849 / 1000\n",
      "w1:  [17.88344394] w2:  [-11.09452042] bias:  [16.54419459] loss:  41.10476265936939\n",
      "Epoch:  850 / 1000\n",
      "w1:  [17.89055159] w2:  [-11.10679484] bias:  [16.54419029] loss:  41.08461585695848\n",
      "Epoch:  851 / 1000\n",
      "w1:  [17.89765261] w2:  [-11.11905747] bias:  [16.54418589] loss:  41.06450744217826\n",
      "Epoch:  852 / 1000\n",
      "w1:  [17.90474703] w2:  [-11.13130832] bias:  [16.54418137] loss:  41.04443734186683\n",
      "Epoch:  853 / 1000\n",
      "w1:  [17.91183484] w2:  [-11.14354741] bias:  [16.54417676] loss:  41.02440548300175\n",
      "Epoch:  854 / 1000\n",
      "w1:  [17.91891606] w2:  [-11.15577473] bias:  [16.54417203] loss:  41.00441179269974\n",
      "Epoch:  855 / 1000\n",
      "w1:  [17.92599069] w2:  [-11.16799031] bias:  [16.5441672] loss:  40.98445619821645\n",
      "Epoch:  856 / 1000\n",
      "w1:  [17.93305872] w2:  [-11.18019415] bias:  [16.54416226] loss:  40.96453862694614\n",
      "Epoch:  857 / 1000\n",
      "w1:  [17.94012019] w2:  [-11.19238627] bias:  [16.54415722] loss:  40.94465900642148\n",
      "Epoch:  858 / 1000\n",
      "w1:  [17.94717507] w2:  [-11.20456668] bias:  [16.54415207] loss:  40.924817264313255\n",
      "Epoch:  859 / 1000\n",
      "w1:  [17.95422339] w2:  [-11.21673538] bias:  [16.54414682] loss:  40.905013328430115\n",
      "Epoch:  860 / 1000\n",
      "w1:  [17.96126516] w2:  [-11.2288924] bias:  [16.54414146] loss:  40.88524712671826\n",
      "Epoch:  861 / 1000\n",
      "w1:  [17.96830036] w2:  [-11.24103773] bias:  [16.54413599] loss:  40.865518587261285\n",
      "Epoch:  862 / 1000\n",
      "w1:  [17.97532902] w2:  [-11.2531714] bias:  [16.54413042] loss:  40.8458276382798\n",
      "Epoch:  863 / 1000\n",
      "w1:  [17.98235114] w2:  [-11.26529342] bias:  [16.54412474] loss:  40.82617420813124\n",
      "Epoch:  864 / 1000\n",
      "w1:  [17.98936672] w2:  [-11.27740378] bias:  [16.54411896] loss:  40.806558225309594\n",
      "Epoch:  865 / 1000\n",
      "w1:  [17.99637578] w2:  [-11.28950251] bias:  [16.54411307] loss:  40.78697961844512\n",
      "Epoch:  866 / 1000\n",
      "w1:  [18.00337831] w2:  [-11.30158962] bias:  [16.54410708] loss:  40.767438316304116\n",
      "Epoch:  867 / 1000\n",
      "w1:  [18.01037432] w2:  [-11.31366512] bias:  [16.54410098] loss:  40.74793424778864\n",
      "Epoch:  868 / 1000\n",
      "w1:  [18.01736383] w2:  [-11.32572902] bias:  [16.54409478] loss:  40.72846734193626\n",
      "Epoch:  869 / 1000\n",
      "w1:  [18.02434683] w2:  [-11.33778132] bias:  [16.54408847] loss:  40.70903752791981\n",
      "Epoch:  870 / 1000\n",
      "w1:  [18.03132333] w2:  [-11.34982205] bias:  [16.54408206] loss:  40.68964473504709\n",
      "Epoch:  871 / 1000\n",
      "w1:  [18.03829334] w2:  [-11.36185121] bias:  [16.54407554] loss:  40.670288892760645\n",
      "Epoch:  872 / 1000\n",
      "w1:  [18.04525686] w2:  [-11.37386881] bias:  [16.54406892] loss:  40.650969930637515\n",
      "Epoch:  873 / 1000\n",
      "w1:  [18.05221391] w2:  [-11.38587486] bias:  [16.5440622] loss:  40.63168777838892\n",
      "Epoch:  874 / 1000\n",
      "w1:  [18.05916448] w2:  [-11.39786938] bias:  [16.54405537] loss:  40.6124423658601\n",
      "Epoch:  875 / 1000\n",
      "w1:  [18.06610858] w2:  [-11.40985238] bias:  [16.54404843] loss:  40.593233623029946\n",
      "Epoch:  876 / 1000\n",
      "w1:  [18.07304623] w2:  [-11.42182386] bias:  [16.5440414] loss:  40.574061480010876\n",
      "Epoch:  877 / 1000\n",
      "w1:  [18.07997742] w2:  [-11.43378385] bias:  [16.54403426] loss:  40.55492586704844\n",
      "Epoch:  878 / 1000\n",
      "w1:  [18.08690215] w2:  [-11.44573234] bias:  [16.54402701] loss:  40.535826714521185\n",
      "Epoch:  879 / 1000\n",
      "w1:  [18.09382045] w2:  [-11.45766935] bias:  [16.54401966] loss:  40.516763952940316\n",
      "Epoch:  880 / 1000\n",
      "w1:  [18.10073231] w2:  [-11.46959489] bias:  [16.54401221] loss:  40.497737512949506\n",
      "Epoch:  881 / 1000\n",
      "w1:  [18.10763774] w2:  [-11.48150898] bias:  [16.54400466] loss:  40.47874732532462\n",
      "Epoch:  882 / 1000\n",
      "w1:  [18.11453674] w2:  [-11.49341161] bias:  [16.543997] loss:  40.459793320973425\n",
      "Epoch:  883 / 1000\n",
      "w1:  [18.12142933] w2:  [-11.50530281] bias:  [16.54398924] loss:  40.440875430935414\n",
      "Epoch:  884 / 1000\n",
      "w1:  [18.12831551] w2:  [-11.51718259] bias:  [16.54398137] loss:  40.421993586381475\n",
      "Epoch:  885 / 1000\n",
      "w1:  [18.13519527] w2:  [-11.52905095] bias:  [16.5439734] loss:  40.40314771861373\n",
      "Epoch:  886 / 1000\n",
      "w1:  [18.14206864] w2:  [-11.54090791] bias:  [16.54396533] loss:  40.384337759065176\n",
      "Epoch:  887 / 1000\n",
      "w1:  [18.14893562] w2:  [-11.55275348] bias:  [16.54395716] loss:  40.36556363929955\n",
      "Epoch:  888 / 1000\n",
      "w1:  [18.1557962] w2:  [-11.56458766] bias:  [16.54394889] loss:  40.346825291010994\n",
      "Epoch:  889 / 1000\n",
      "w1:  [18.16265041] w2:  [-11.57641047] bias:  [16.54394051] loss:  40.328122646023836\n",
      "Epoch:  890 / 1000\n",
      "w1:  [18.16949824] w2:  [-11.58822192] bias:  [16.54393203] loss:  40.30945563629234\n",
      "Epoch:  891 / 1000\n",
      "w1:  [18.1763397] w2:  [-11.60002203] bias:  [16.54392345] loss:  40.290824193900484\n",
      "Epoch:  892 / 1000\n",
      "w1:  [18.18317479] w2:  [-11.61181079] bias:  [16.54391476] loss:  40.27222825106168\n",
      "Epoch:  893 / 1000\n",
      "w1:  [18.19000353] w2:  [-11.62358823] bias:  [16.54390597] loss:  40.253667740118516\n",
      "Epoch:  894 / 1000\n",
      "w1:  [18.19682592] w2:  [-11.63535435] bias:  [16.54389709] loss:  40.23514259354255\n",
      "Epoch:  895 / 1000\n",
      "w1:  [18.20364196] w2:  [-11.64710917] bias:  [16.5438881] loss:  40.216652743934034\n",
      "Epoch:  896 / 1000\n",
      "w1:  [18.21045166] w2:  [-11.65885269] bias:  [16.543879] loss:  40.198198124021715\n",
      "Epoch:  897 / 1000\n",
      "w1:  [18.21725503] w2:  [-11.67058493] bias:  [16.54386981] loss:  40.1797786666625\n",
      "Epoch:  898 / 1000\n",
      "w1:  [18.22405207] w2:  [-11.68230589] bias:  [16.54386052] loss:  40.161394304841316\n",
      "Epoch:  899 / 1000\n",
      "w1:  [18.23084279] w2:  [-11.69401559] bias:  [16.54385112] loss:  40.143044971670776\n",
      "Epoch:  900 / 1000\n",
      "w1:  [18.23762719] w2:  [-11.70571404] bias:  [16.54384162] loss:  40.124730600391004\n",
      "Epoch:  901 / 1000\n",
      "w1:  [18.24440529] w2:  [-11.71740124] bias:  [16.54383202] loss:  40.10645112436936\n",
      "Epoch:  902 / 1000\n",
      "w1:  [18.25117708] w2:  [-11.72907722] bias:  [16.54382233] loss:  40.08820647710018\n",
      "Epoch:  903 / 1000\n",
      "w1:  [18.25794258] w2:  [-11.74074198] bias:  [16.54381252] loss:  40.06999659220459\n",
      "Epoch:  904 / 1000\n",
      "w1:  [18.26470178] w2:  [-11.75239552] bias:  [16.54380262] loss:  40.0518214034302\n",
      "Epoch:  905 / 1000\n",
      "w1:  [18.2714547] w2:  [-11.76403787] bias:  [16.54379262] loss:  40.03368084465091\n",
      "Epoch:  906 / 1000\n",
      "w1:  [18.27820133] w2:  [-11.77566903] bias:  [16.54378252] loss:  40.01557484986665\n",
      "Epoch:  907 / 1000\n",
      "w1:  [18.2849417] w2:  [-11.78728902] bias:  [16.54377232] loss:  39.997503353203136\n",
      "Epoch:  908 / 1000\n",
      "w1:  [18.29167579] w2:  [-11.79889783] bias:  [16.54376201] loss:  39.97946628891163\n",
      "Epoch:  909 / 1000\n",
      "w1:  [18.29840363] w2:  [-11.8104955] bias:  [16.54375161] loss:  39.961463591368734\n",
      "Epoch:  910 / 1000\n",
      "w1:  [18.30512521] w2:  [-11.82208201] bias:  [16.54374111] loss:  39.9434951950761\n",
      "Epoch:  911 / 1000\n",
      "w1:  [18.31184054] w2:  [-11.8336574] bias:  [16.5437305] loss:  39.92556103466022\n",
      "Epoch:  912 / 1000\n",
      "w1:  [18.31854962] w2:  [-11.84522165] bias:  [16.5437198] loss:  39.907661044872185\n",
      "Epoch:  913 / 1000\n",
      "w1:  [18.32525247] w2:  [-11.8567748] bias:  [16.543709] loss:  39.88979516058746\n",
      "Epoch:  914 / 1000\n",
      "w1:  [18.33194909] w2:  [-11.86831684] bias:  [16.5436981] loss:  39.87196331680562\n",
      "Epoch:  915 / 1000\n",
      "w1:  [18.33863948] w2:  [-11.87984779] bias:  [16.54368709] loss:  39.8541654486501\n",
      "Epoch:  916 / 1000\n",
      "w1:  [18.34532365] w2:  [-11.89136766] bias:  [16.54367599] loss:  39.83640149136805\n",
      "Epoch:  917 / 1000\n",
      "w1:  [18.35200161] w2:  [-11.90287646] bias:  [16.54366479] loss:  39.81867138032997\n",
      "Epoch:  918 / 1000\n",
      "w1:  [18.35867335] w2:  [-11.9143742] bias:  [16.54365349] loss:  39.80097505102958\n",
      "Epoch:  919 / 1000\n",
      "w1:  [18.3653389] w2:  [-11.92586089] bias:  [16.54364209] loss:  39.78331243908354\n",
      "Epoch:  920 / 1000\n",
      "w1:  [18.37199825] w2:  [-11.93733654] bias:  [16.54363059] loss:  39.765683480231196\n",
      "Epoch:  921 / 1000\n",
      "w1:  [18.37865141] w2:  [-11.94880116] bias:  [16.54361899] loss:  39.74808811033441\n",
      "Epoch:  922 / 1000\n",
      "w1:  [18.38529838] w2:  [-11.96025476] bias:  [16.5436073] loss:  39.730526265377236\n",
      "Epoch:  923 / 1000\n",
      "w1:  [18.39193917] w2:  [-11.97169736] bias:  [16.5435955] loss:  39.7129978814658\n",
      "Epoch:  924 / 1000\n",
      "w1:  [18.3985738] w2:  [-11.98312895] bias:  [16.54358361] loss:  39.69550289482796\n",
      "Epoch:  925 / 1000\n",
      "w1:  [18.40520225] w2:  [-11.99454957] bias:  [16.54357162] loss:  39.67804124181313\n",
      "Epoch:  926 / 1000\n",
      "w1:  [18.41182454] w2:  [-12.0059592] bias:  [16.54355953] loss:  39.660612858892044\n",
      "Epoch:  927 / 1000\n",
      "w1:  [18.41844068] w2:  [-12.01735787] bias:  [16.54354734] loss:  39.64321768265652\n",
      "Epoch:  928 / 1000\n",
      "w1:  [18.42505067] w2:  [-12.02874559] bias:  [16.54353505] loss:  39.625855649819215\n",
      "Epoch:  929 / 1000\n",
      "w1:  [18.43165452] w2:  [-12.04012236] bias:  [16.54352267] loss:  39.60852669721343\n",
      "Epoch:  930 / 1000\n",
      "w1:  [18.43825222] w2:  [-12.05148819] bias:  [16.54351019] loss:  39.59123076179282\n",
      "Epoch:  931 / 1000\n",
      "w1:  [18.4448438] w2:  [-12.0628431] bias:  [16.54349761] loss:  39.573967780631264\n",
      "Epoch:  932 / 1000\n",
      "w1:  [18.45142925] w2:  [-12.0741871] bias:  [16.54348493] loss:  39.55673769092252\n",
      "Epoch:  933 / 1000\n",
      "w1:  [18.45800858] w2:  [-12.0855202] bias:  [16.54347215] loss:  39.53954042998005\n",
      "Epoch:  934 / 1000\n",
      "w1:  [18.46458179] w2:  [-12.0968424] bias:  [16.54345928] loss:  39.52237593523684\n",
      "Epoch:  935 / 1000\n",
      "w1:  [18.47114889] w2:  [-12.10815372] bias:  [16.54344631] loss:  39.505244144245076\n",
      "Epoch:  936 / 1000\n",
      "w1:  [18.4777099] w2:  [-12.11945417] bias:  [16.54343324] loss:  39.488144994675984\n",
      "Epoch:  937 / 1000\n",
      "w1:  [18.4842648] w2:  [-12.13074376] bias:  [16.54342008] loss:  39.47107842431961\n",
      "Epoch:  938 / 1000\n",
      "w1:  [18.49081361] w2:  [-12.1420225] bias:  [16.54340681] loss:  39.45404437108451\n",
      "Epoch:  939 / 1000\n",
      "w1:  [18.49735634] w2:  [-12.15329039] bias:  [16.54339345] loss:  39.43704277299764\n",
      "Epoch:  940 / 1000\n",
      "w1:  [18.50389299] w2:  [-12.16454746] bias:  [16.54338] loss:  39.42007356820404\n",
      "Epoch:  941 / 1000\n",
      "w1:  [18.51042357] w2:  [-12.1757937] bias:  [16.54336645] loss:  39.403136694966655\n",
      "Epoch:  942 / 1000\n",
      "w1:  [18.51694807] w2:  [-12.18702914] bias:  [16.5433528] loss:  39.38623209166607\n",
      "Epoch:  943 / 1000\n",
      "w1:  [18.52346651] w2:  [-12.19825378] bias:  [16.54333905] loss:  39.36935969680038\n",
      "Epoch:  944 / 1000\n",
      "w1:  [18.5299789] w2:  [-12.20946763] bias:  [16.54332521] loss:  39.352519448984815\n",
      "Epoch:  945 / 1000\n",
      "w1:  [18.53648524] w2:  [-12.22067069] bias:  [16.54331127] loss:  39.33571128695167\n",
      "Epoch:  946 / 1000\n",
      "w1:  [18.54298553] w2:  [-12.231863] bias:  [16.54329724] loss:  39.31893514954996\n",
      "Epoch:  947 / 1000\n",
      "w1:  [18.54947978] w2:  [-12.24304454] bias:  [16.54328311] loss:  39.30219097574527\n",
      "Epoch:  948 / 1000\n",
      "w1:  [18.555968] w2:  [-12.25421533] bias:  [16.54326888] loss:  39.28547870461952\n",
      "Epoch:  949 / 1000\n",
      "w1:  [18.56245019] w2:  [-12.26537539] bias:  [16.54325456] loss:  39.26879827537074\n",
      "Epoch:  950 / 1000\n",
      "w1:  [18.56892635] w2:  [-12.27652472] bias:  [16.54324014] loss:  39.25214962731283\n",
      "Epoch:  951 / 1000\n",
      "w1:  [18.5753965] w2:  [-12.28766333] bias:  [16.54322562] loss:  39.235532699875364\n",
      "Epoch:  952 / 1000\n",
      "w1:  [18.58186064] w2:  [-12.29879124] bias:  [16.54321101] loss:  39.218947432603336\n",
      "Epoch:  953 / 1000\n",
      "w1:  [18.58831878] w2:  [-12.30990845] bias:  [16.54319631] loss:  39.202393765157\n",
      "Epoch:  954 / 1000\n",
      "w1:  [18.59477091] w2:  [-12.32101497] bias:  [16.54318151] loss:  39.185871637311585\n",
      "Epoch:  955 / 1000\n",
      "w1:  [18.60121705] w2:  [-12.33211082] bias:  [16.54316661] loss:  39.16938098895712\n",
      "Epoch:  956 / 1000\n",
      "w1:  [18.60765721] w2:  [-12.343196] bias:  [16.54315162] loss:  39.152921760098195\n",
      "Epoch:  957 / 1000\n",
      "w1:  [18.61409138] w2:  [-12.35427052] bias:  [16.54313654] loss:  39.13649389085375\n",
      "Epoch:  958 / 1000\n",
      "w1:  [18.62051957] w2:  [-12.3653344] bias:  [16.54312135] loss:  39.12009732145685\n",
      "Epoch:  959 / 1000\n",
      "w1:  [18.62694179] w2:  [-12.37638764] bias:  [16.54310608] loss:  39.103731992254474\n",
      "Epoch:  960 / 1000\n",
      "w1:  [18.63335805] w2:  [-12.38743026] bias:  [16.54309071] loss:  39.0873978437073\n",
      "Epoch:  961 / 1000\n",
      "w1:  [18.63976835] w2:  [-12.39846226] bias:  [16.54307524] loss:  39.07109481638947\n",
      "Epoch:  962 / 1000\n",
      "w1:  [18.64617269] w2:  [-12.40948366] bias:  [16.54305968] loss:  39.0548228509884\n",
      "Epoch:  963 / 1000\n",
      "w1:  [18.65257109] w2:  [-12.42049446] bias:  [16.54304403] loss:  39.03858188830457\n",
      "Epoch:  964 / 1000\n",
      "w1:  [18.65896354] w2:  [-12.43149468] bias:  [16.54302828] loss:  39.02237186925124\n",
      "Epoch:  965 / 1000\n",
      "w1:  [18.66535006] w2:  [-12.44248432] bias:  [16.54301244] loss:  39.006192734854324\n",
      "Epoch:  966 / 1000\n",
      "w1:  [18.67173064] w2:  [-12.4534634] bias:  [16.5429965] loss:  38.99004442625215\n",
      "Epoch:  967 / 1000\n",
      "w1:  [18.6781053] w2:  [-12.46443192] bias:  [16.54298047] loss:  38.97392688469518\n",
      "Epoch:  968 / 1000\n",
      "w1:  [18.68447404] w2:  [-12.4753899] bias:  [16.54296435] loss:  38.95784005154591\n",
      "Epoch:  969 / 1000\n",
      "w1:  [18.69083687] w2:  [-12.48633734] bias:  [16.54294813] loss:  38.94178386827855\n",
      "Epoch:  970 / 1000\n",
      "w1:  [18.69719378] w2:  [-12.49727426] bias:  [16.54293182] loss:  38.925758276478874\n",
      "Epoch:  971 / 1000\n",
      "w1:  [18.70354479] w2:  [-12.50820067] bias:  [16.54291541] loss:  38.90976321784399\n",
      "Epoch:  972 / 1000\n",
      "w1:  [18.70988991] w2:  [-12.51911657] bias:  [16.54289891] loss:  38.893798634182126\n",
      "Epoch:  973 / 1000\n",
      "w1:  [18.71622913] w2:  [-12.53002197] bias:  [16.54288232] loss:  38.877864467412415\n",
      "Epoch:  974 / 1000\n",
      "w1:  [18.72256247] w2:  [-12.5409169] bias:  [16.54286563] loss:  38.861960659564694\n",
      "Epoch:  975 / 1000\n",
      "w1:  [18.72888992] w2:  [-12.55180134] bias:  [16.54284886] loss:  38.84608715277929\n",
      "Epoch:  976 / 1000\n",
      "w1:  [18.7352115] w2:  [-12.56267533] bias:  [16.54283198] loss:  38.8302438893068\n",
      "Epoch:  977 / 1000\n",
      "w1:  [18.74152721] w2:  [-12.57353886] bias:  [16.54281502] loss:  38.81443081150789\n",
      "Epoch:  978 / 1000\n",
      "w1:  [18.74783706] w2:  [-12.58439194] bias:  [16.54279796] loss:  38.79864786185309\n",
      "Epoch:  979 / 1000\n",
      "w1:  [18.75414104] w2:  [-12.59523459] bias:  [16.54278081] loss:  38.782894982922556\n",
      "Epoch:  980 / 1000\n",
      "w1:  [18.76043918] w2:  [-12.60606682] bias:  [16.54276357] loss:  38.76717211740591\n",
      "Epoch:  981 / 1000\n",
      "w1:  [18.76673146] w2:  [-12.61688863] bias:  [16.54274623] loss:  38.751479208102\n",
      "Epoch:  982 / 1000\n",
      "w1:  [18.77301791] w2:  [-12.62770004] bias:  [16.5427288] loss:  38.73581619791867\n",
      "Epoch:  983 / 1000\n",
      "w1:  [18.77929852] w2:  [-12.63850105] bias:  [16.54271128] loss:  38.72018302987261\n",
      "Epoch:  984 / 1000\n",
      "w1:  [18.78557329] w2:  [-12.64929168] bias:  [16.54269367] loss:  38.70457964708908\n",
      "Epoch:  985 / 1000\n",
      "w1:  [18.79184225] w2:  [-12.66007193] bias:  [16.54267597] loss:  38.689005992801775\n",
      "Epoch:  986 / 1000\n",
      "w1:  [18.79810538] w2:  [-12.67084182] bias:  [16.54265817] loss:  38.67346201035258\n",
      "Epoch:  987 / 1000\n",
      "w1:  [18.8043627] w2:  [-12.68160135] bias:  [16.54264028] loss:  38.65794764319134\n",
      "Epoch:  988 / 1000\n",
      "w1:  [18.81061421] w2:  [-12.69235054] bias:  [16.5426223] loss:  38.64246283487571\n",
      "Epoch:  989 / 1000\n",
      "w1:  [18.81685991] w2:  [-12.70308939] bias:  [16.54260423] loss:  38.62700752907089\n",
      "Epoch:  990 / 1000\n",
      "w1:  [18.82309982] w2:  [-12.71381792] bias:  [16.54258606] loss:  38.61158166954948\n",
      "Epoch:  991 / 1000\n",
      "w1:  [18.82933394] w2:  [-12.72453613] bias:  [16.54256781] loss:  38.596185200191236\n",
      "Epoch:  992 / 1000\n",
      "w1:  [18.83556227] w2:  [-12.73524404] bias:  [16.54254946] loss:  38.58081806498287\n",
      "Epoch:  993 / 1000\n",
      "w1:  [18.84178482] w2:  [-12.74594165] bias:  [16.54253102] loss:  38.56548020801785\n",
      "Epoch:  994 / 1000\n",
      "w1:  [18.84800159] w2:  [-12.75662898] bias:  [16.54251249] loss:  38.550171573496215\n",
      "Epoch:  995 / 1000\n",
      "w1:  [18.85421259] w2:  [-12.76730603] bias:  [16.54249387] loss:  38.53489210572434\n",
      "Epoch:  996 / 1000\n",
      "w1:  [18.86041783] w2:  [-12.77797281] bias:  [16.54247516] loss:  38.51964174911474\n",
      "Epoch:  997 / 1000\n",
      "w1:  [18.86661731] w2:  [-12.78862933] bias:  [16.54245636] loss:  38.504420448185904\n",
      "Epoch:  998 / 1000\n",
      "w1:  [18.87281103] w2:  [-12.79927561] bias:  [16.54243747] loss:  38.48922814756204\n",
      "Epoch:  999 / 1000\n",
      "w1:  [18.87899901] w2:  [-12.80991166] bias:  [16.54241848] loss:  38.474064791972914\n",
      "Epoch:  1000 / 1000\n",
      "w1:  [18.88518124] w2:  [-12.82053747] bias:  [16.54239941] loss:  38.45893032625362\n",
      "##### 최종 w1, w2, bias #####\n",
      "[18.88518124] [-12.82053747] [16.54239941]\n"
     ]
    }
   ],
   "source": [
    "w1, w2, bias = gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=1000, verbose=True)\n",
    "print('##### 최종 w1, w2, bias #####')\n",
    "print(w1, w2, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f7832e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PREDICTED_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.298946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>24.270017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>28.842337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>28.551276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>28.244935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "      <td>25.692891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "      <td>21.626138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "      <td>19.827786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "      <td>14.056539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.945095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  PREDICTED_PRICE  \n",
       "0     15.3  396.90   4.98   24.0        26.298946  \n",
       "1     17.8  396.90   9.14   21.6        24.270017  \n",
       "2     17.8  392.83   4.03   34.7        28.842337  \n",
       "3     18.7  394.63   2.94   33.4        28.551276  \n",
       "4     18.7  396.90   5.33   36.2        28.244935  \n",
       "5     18.7  394.12   5.21   28.7        25.692891  \n",
       "6     15.2  395.60  12.43   22.9        21.626138  \n",
       "7     15.2  396.90  19.15   27.1        19.827786  \n",
       "8     15.2  386.63  29.93   16.5        14.056539  \n",
       "9     15.2  386.71  17.10   18.9        19.945095  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
    "bostonDF['PREDICTED_PRICE'] = predicted\n",
    "bostonDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d00fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-09 10:45:17.853049: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-09 10:45:17.855714: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-08-09 10:45:17.958938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 542.1975 - mse: 542.1975\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 529.9670 - mse: 529.9670\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 517.9854 - mse: 517.9854\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 506.2974 - mse: 506.2974\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 494.7792 - mse: 494.7792\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 483.5835 - mse: 483.5835\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 472.6848 - mse: 472.6848\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 461.9260 - mse: 461.9260\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 451.3943 - mse: 451.3943\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 441.1546 - mse: 441.1546\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 431.1149 - mse: 431.1149\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 421.2989 - mse: 421.2989\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 411.6740 - mse: 411.6740\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 402.3942 - mse: 402.3942\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 393.1469 - mse: 393.1469\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 384.1710 - mse: 384.1710\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 375.5016 - mse: 375.5016\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 366.8741 - mse: 366.8741\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 358.4786 - mse: 358.4786\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 350.4427 - mse: 350.4427\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 342.4210 - mse: 342.4210\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 334.6991 - mse: 334.6991\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 327.1260 - mse: 327.1260\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 319.6837 - mse: 319.6837\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 312.4462 - mse: 312.4462\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 305.4709 - mse: 305.4709\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 298.6173 - mse: 298.6173\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 291.9538 - mse: 291.9538\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 285.3959 - mse: 285.3959\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 279.0403 - mse: 279.0403\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 272.8221 - mse: 272.8221\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 266.8483 - mse: 266.8483\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 261.0502 - mse: 261.0502\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 255.3085 - mse: 255.3085\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 249.7296 - mse: 249.7296\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 244.3376 - mse: 244.3376\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 239.1196 - mse: 239.1196\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 233.9835 - mse: 233.9835\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 229.0123 - mse: 229.0123\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 224.1817 - mse: 224.1817\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 219.4392 - mse: 219.4392\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 214.9179 - mse: 214.9179\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 210.5619 - mse: 210.5619\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 206.1558 - mse: 206.1558\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 202.0359 - mse: 202.0359\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 197.9632 - mse: 197.9632\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 193.9955 - mse: 193.9955\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 190.1825 - mse: 190.1825\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 186.4961 - mse: 186.4961\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 182.8700 - mse: 182.8700\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 179.4451 - mse: 179.4451\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 176.0606 - mse: 176.0606\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 172.7725 - mse: 172.7725\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 169.5836 - mse: 169.5836\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 166.4738 - mse: 166.4738\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 163.5353 - mse: 163.5353\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 160.6230 - mse: 160.6230\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 157.8799 - mse: 157.8799\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 155.1292 - mse: 155.1292\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 152.5964 - mse: 152.5964\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 149.9847 - mse: 149.9847\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 147.5875 - mse: 147.5875\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 145.1812 - mse: 145.1812\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 142.9102 - mse: 142.9102\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 140.7013 - mse: 140.7013\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 138.5059 - mse: 138.5059\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 136.4668 - mse: 136.4668\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 134.4777 - mse: 134.4777\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 132.5161 - mse: 132.5161\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 130.6396 - mse: 130.6396\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 128.8341 - mse: 128.8341\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 127.0922 - mse: 127.0922\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 125.3740 - mse: 125.3740\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 123.7794 - mse: 123.7794\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 122.1446 - mse: 122.1446\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 120.6509 - mse: 120.6509\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 119.1558 - mse: 119.1558\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 117.7478 - mse: 117.7478\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 116.3764 - mse: 116.3764\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 115.0091 - mse: 115.0091\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.7756 - mse: 113.7756\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.4983 - mse: 112.4983\n",
      "Epoch 83/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 111.2870 - mse: 111.2870\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.1243 - mse: 110.1243\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.0151 - mse: 109.0151\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.9115 - mse: 107.9115\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 106.8350 - mse: 106.8350\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 105.8511 - mse: 105.8511\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 104.8480 - mse: 104.8480\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 103.9037 - mse: 103.9037\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 102.9554 - mse: 102.9554\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 102.0587 - mse: 102.0587\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 101.1912 - mse: 101.1912\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 100.3397 - mse: 100.3397\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 99.5138 - mse: 99.5138\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 98.7130 - mse: 98.7130\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 97.9414 - mse: 97.9414\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 97.1533 - mse: 97.1533\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 96.4545 - mse: 96.4545\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 95.7156 - mse: 95.7156\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 95.0005 - mse: 95.0005\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 94.3428 - mse: 94.3428\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 93.6951 - mse: 93.6951\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 93.0123 - mse: 93.0123\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 92.4172 - mse: 92.4172\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 91.7746 - mse: 91.7746\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 91.1779 - mse: 91.1779\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 90.5801 - mse: 90.5801\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 90.0262 - mse: 90.0262\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 89.4289 - mse: 89.4289\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 88.8819 - mse: 88.8819\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 88.3595 - mse: 88.3595\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 87.7978 - mse: 87.7978\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 87.2717 - mse: 87.2717\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 86.7559 - mse: 86.7559\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 86.2491 - mse: 86.2491\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 85.7777 - mse: 85.7777\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 85.2476 - mse: 85.2476\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 84.7869 - mse: 84.7869\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 84.3075 - mse: 84.3075\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 83.8474 - mse: 83.8474\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 83.3697 - mse: 83.3697\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 82.8980 - mse: 82.8980\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 82.4705 - mse: 82.4705\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 82.0227 - mse: 82.0227\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 81.5685 - mse: 81.5685\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 81.1259 - mse: 81.1259\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 80.6969 - mse: 80.6969\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 80.2627 - mse: 80.2627\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 79.8550 - mse: 79.8550\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 79.4266 - mse: 79.4266\n",
      "Epoch 132/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 79.0036 - mse: 79.0036\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 78.5982 - mse: 78.5982\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 78.1814 - mse: 78.1814\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 77.7796 - mse: 77.7796\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 77.3669 - mse: 77.3669\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 76.9808 - mse: 76.9808\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 76.5715 - mse: 76.5715\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 76.1871 - mse: 76.1871\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 75.7879 - mse: 75.7879\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 75.3972 - mse: 75.3972\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 75.0105 - mse: 75.0105\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 74.6243 - mse: 74.6243\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 74.2488 - mse: 74.2488\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 73.8609 - mse: 73.8609\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 73.4921 - mse: 73.4921\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 73.1192 - mse: 73.1192\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 72.7571 - mse: 72.7571\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 72.3752 - mse: 72.3752\n",
      "Epoch 150/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 72.0028 - mse: 72.0028\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 71.6451 - mse: 71.6451\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 71.2844 - mse: 71.2844\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 70.9140 - mse: 70.9140\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 70.5578 - mse: 70.5578\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 70.2013 - mse: 70.2013\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 69.8392 - mse: 69.8392\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 69.4913 - mse: 69.4913\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 69.1350 - mse: 69.1350\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 68.7799 - mse: 68.7799\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 68.4395 - mse: 68.4395\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 68.0947 - mse: 68.0947\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 67.7421 - mse: 67.7421\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 67.4056 - mse: 67.4056\n",
      "Epoch 164/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 67.0591 - mse: 67.0591\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 66.7228 - mse: 66.7228\n",
      "Epoch 166/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 66.3889 - mse: 66.3889\n",
      "Epoch 167/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 66.0569 - mse: 66.0569\n",
      "Epoch 168/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 65.7124 - mse: 65.7124\n",
      "Epoch 169/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 65.3921 - mse: 65.3921\n",
      "Epoch 170/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 65.0579 - mse: 65.0579\n",
      "Epoch 171/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 64.7286 - mse: 64.7286\n",
      "Epoch 172/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 64.4035 - mse: 64.4035\n",
      "Epoch 173/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 64.0892 - mse: 64.0892\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 63.7629 - mse: 63.7629\n",
      "Epoch 175/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 63.4373 - mse: 63.4373\n",
      "Epoch 176/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 63.1294 - mse: 63.1294\n",
      "Epoch 177/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 62.8079 - mse: 62.8079\n",
      "Epoch 178/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 62.5053 - mse: 62.5053\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 62.1800 - mse: 62.1800\n",
      "Epoch 180/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 61.8754 - mse: 61.8754\n",
      "Epoch 181/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 61.5667 - mse: 61.5667\n",
      "Epoch 182/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 61.2565 - mse: 61.2565\n",
      "Epoch 183/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 60.9489 - mse: 60.9489\n",
      "Epoch 184/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 60.6564 - mse: 60.6564\n",
      "Epoch 185/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 60.3465 - mse: 60.3465\n",
      "Epoch 186/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 60.0465 - mse: 60.0465\n",
      "Epoch 187/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 59.7510 - mse: 59.7510\n",
      "Epoch 188/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 59.4651 - mse: 59.4651\n",
      "Epoch 189/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 59.1652 - mse: 59.1652\n",
      "Epoch 190/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 58.8648 - mse: 58.8648\n",
      "Epoch 191/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 58.5756 - mse: 58.5756\n",
      "Epoch 192/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 58.2885 - mse: 58.2885\n",
      "Epoch 193/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 58.0045 - mse: 58.0045\n",
      "Epoch 194/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 57.7151 - mse: 57.7151\n",
      "Epoch 195/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 57.4349 - mse: 57.4349\n",
      "Epoch 196/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 57.1551 - mse: 57.1551\n",
      "Epoch 197/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 56.8763 - mse: 56.8763\n",
      "Epoch 198/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 56.6003 - mse: 56.6003\n",
      "Epoch 199/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 56.3199 - mse: 56.3199\n",
      "Epoch 200/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 56.0577 - mse: 56.0577\n",
      "Epoch 201/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 55.7756 - mse: 55.7756\n",
      "Epoch 202/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 55.5017 - mse: 55.5017\n",
      "Epoch 203/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 55.2313 - mse: 55.2313\n",
      "Epoch 204/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 54.9626 - mse: 54.9626\n",
      "Epoch 205/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 54.7040 - mse: 54.7040\n",
      "Epoch 206/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 54.4380 - mse: 54.4380\n",
      "Epoch 207/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 54.1686 - mse: 54.1686\n",
      "Epoch 208/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 53.9136 - mse: 53.9136\n",
      "Epoch 209/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 53.6544 - mse: 53.6544\n",
      "Epoch 210/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 53.3974 - mse: 53.3974\n",
      "Epoch 211/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 53.1383 - mse: 53.1383\n",
      "Epoch 212/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.8891 - mse: 52.8891\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 52.6378 - mse: 52.6378\n",
      "Epoch 214/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.3842 - mse: 52.3842\n",
      "Epoch 215/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 52.1380 - mse: 52.1380\n",
      "Epoch 216/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.8900 - mse: 51.8900\n",
      "Epoch 217/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.6419 - mse: 51.6419\n",
      "Epoch 218/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.4066 - mse: 51.4066\n",
      "Epoch 219/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.1603 - mse: 51.1603\n",
      "Epoch 220/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.9275 - mse: 50.9275\n",
      "Epoch 221/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.6948 - mse: 50.6948\n",
      "Epoch 222/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.4496 - mse: 50.4496\n",
      "Epoch 223/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.2217 - mse: 50.2217\n",
      "Epoch 224/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9894 - mse: 49.9894\n",
      "Epoch 225/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7615 - mse: 49.7615\n",
      "Epoch 226/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5369 - mse: 49.5369\n",
      "Epoch 227/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3082 - mse: 49.3082\n",
      "Epoch 228/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.0860 - mse: 49.0860\n",
      "Epoch 229/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8717 - mse: 48.8717\n",
      "Epoch 230/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6464 - mse: 48.6464\n",
      "Epoch 231/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4213 - mse: 48.4213\n",
      "Epoch 232/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2130 - mse: 48.2130\n",
      "Epoch 233/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9974 - mse: 47.9974\n",
      "Epoch 234/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7828 - mse: 47.7828\n",
      "Epoch 235/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5770 - mse: 47.5770\n",
      "Epoch 236/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3642 - mse: 47.3642\n",
      "Epoch 237/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.1524 - mse: 47.1524\n",
      "Epoch 238/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.9562 - mse: 46.9562\n",
      "Epoch 239/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.7465 - mse: 46.7465\n",
      "Epoch 240/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.5393 - mse: 46.5393\n",
      "Epoch 241/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.3470 - mse: 46.3470\n",
      "Epoch 242/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.1447 - mse: 46.1447\n",
      "Epoch 243/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 45.9496 - mse: 45.9496\n",
      "Epoch 244/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 45.7492 - mse: 45.7492\n",
      "Epoch 245/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 45.5673 - mse: 45.5673\n",
      "Epoch 246/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 45.3658 - mse: 45.3658\n",
      "Epoch 247/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 45.1726 - mse: 45.1726\n",
      "Epoch 248/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 44.9771 - mse: 44.9771\n",
      "Epoch 249/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 44.8016 - mse: 44.8016\n",
      "Epoch 250/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.6058 - mse: 44.6058\n",
      "Epoch 251/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 44.4279 - mse: 44.4279\n",
      "Epoch 252/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 44.2417 - mse: 44.2417\n",
      "Epoch 253/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 44.0594 - mse: 44.0594\n",
      "Epoch 254/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 43.8781 - mse: 43.8781\n",
      "Epoch 255/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 43.7035 - mse: 43.7035\n",
      "Epoch 256/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 43.5288 - mse: 43.5288\n",
      "Epoch 257/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 43.3528 - mse: 43.3528\n",
      "Epoch 258/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 43.1748 - mse: 43.1748\n",
      "Epoch 259/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 43.0073 - mse: 43.0073\n",
      "Epoch 260/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 42.8383 - mse: 42.8383\n",
      "Epoch 261/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42.6671 - mse: 42.6671\n",
      "Epoch 262/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 42.5028 - mse: 42.5028\n",
      "Epoch 263/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42.3436 - mse: 42.3436\n",
      "Epoch 264/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42.1707 - mse: 42.1707\n",
      "Epoch 265/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42.0203 - mse: 42.0203\n",
      "Epoch 266/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 41.8470 - mse: 41.8470\n",
      "Epoch 267/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 41.6918 - mse: 41.6918\n",
      "Epoch 268/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 41.5358 - mse: 41.5358\n",
      "Epoch 269/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 41.3912 - mse: 41.3912\n",
      "Epoch 270/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 41.2257 - mse: 41.2257\n",
      "Epoch 271/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41.0698 - mse: 41.0698\n",
      "Epoch 272/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 40.9218 - mse: 40.9218\n",
      "Epoch 273/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40.7720 - mse: 40.7720\n",
      "Epoch 274/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 40.6230 - mse: 40.6230\n",
      "Epoch 275/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 40.4769 - mse: 40.4769\n",
      "Epoch 276/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 40.3249 - mse: 40.3249\n",
      "Epoch 277/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40.1873 - mse: 40.1873\n",
      "Epoch 278/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 40.0456 - mse: 40.0456\n",
      "Epoch 279/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 39.9007 - mse: 39.9007\n",
      "Epoch 280/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39.7572 - mse: 39.7572\n",
      "Epoch 281/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39.6362 - mse: 39.6362\n",
      "Epoch 282/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39.4875 - mse: 39.4875\n",
      "Epoch 283/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39.3497 - mse: 39.3497\n",
      "Epoch 284/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39.2138 - mse: 39.2138\n",
      "Epoch 285/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39.0919 - mse: 39.0919\n",
      "Epoch 286/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.9613 - mse: 38.9613\n",
      "Epoch 287/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.8255 - mse: 38.8255\n",
      "Epoch 288/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.7032 - mse: 38.7032\n",
      "Epoch 289/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.5671 - mse: 38.5671\n",
      "Epoch 290/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.4488 - mse: 38.4488\n",
      "Epoch 291/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.3218 - mse: 38.3218\n",
      "Epoch 292/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.2031 - mse: 38.2031\n",
      "Epoch 293/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.0789 - mse: 38.0789\n",
      "Epoch 294/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.9622 - mse: 37.9622\n",
      "Epoch 295/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.8456 - mse: 37.8456\n",
      "Epoch 296/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.7289 - mse: 37.7289\n",
      "Epoch 297/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.6138 - mse: 37.6138\n",
      "Epoch 298/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 37.4892 - mse: 37.4892\n",
      "Epoch 299/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.3840 - mse: 37.3840\n",
      "Epoch 300/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.2686 - mse: 37.2686\n",
      "Epoch 301/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.1641 - mse: 37.1641\n",
      "Epoch 302/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.0471 - mse: 37.0471\n",
      "Epoch 303/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 36.9420 - mse: 36.9420\n",
      "Epoch 304/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 36.8409 - mse: 36.8409\n",
      "Epoch 305/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 36.7312 - mse: 36.7312\n",
      "Epoch 306/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 36.6363 - mse: 36.6363\n",
      "Epoch 307/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.5275 - mse: 36.5275\n",
      "Epoch 308/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36.4267 - mse: 36.4267\n",
      "Epoch 309/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 36.3245 - mse: 36.3245\n",
      "Epoch 310/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 36.2272 - mse: 36.2272\n",
      "Epoch 311/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 36.1300 - mse: 36.1300\n",
      "Epoch 312/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 36.0269 - mse: 36.0269\n",
      "Epoch 313/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.9358 - mse: 35.9358\n",
      "Epoch 314/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.8414 - mse: 35.8414\n",
      "Epoch 315/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.7503 - mse: 35.7503\n",
      "Epoch 316/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.6562 - mse: 35.6562\n",
      "Epoch 317/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.5634 - mse: 35.5634\n",
      "Epoch 318/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.4760 - mse: 35.4760\n",
      "Epoch 319/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.3870 - mse: 35.3870\n",
      "Epoch 320/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.3014 - mse: 35.3014\n",
      "Epoch 321/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.2170 - mse: 35.2170\n",
      "Epoch 322/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.1351 - mse: 35.1351\n",
      "Epoch 323/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.0470 - mse: 35.0470\n",
      "Epoch 324/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.9634 - mse: 34.9634\n",
      "Epoch 325/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.8868 - mse: 34.8868\n",
      "Epoch 326/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.8106 - mse: 34.8106\n",
      "Epoch 327/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.7339 - mse: 34.7339\n",
      "Epoch 328/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.6465 - mse: 34.6465\n",
      "Epoch 329/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 34.5810 - mse: 34.5810\n",
      "Epoch 330/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.4936 - mse: 34.4936\n",
      "Epoch 331/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.4205 - mse: 34.4205\n",
      "Epoch 332/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.3545 - mse: 34.3545\n",
      "Epoch 333/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.2769 - mse: 34.2769\n",
      "Epoch 334/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.2056 - mse: 34.2056\n",
      "Epoch 335/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.1422 - mse: 34.1422\n",
      "Epoch 336/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.0811 - mse: 34.0811\n",
      "Epoch 337/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.0019 - mse: 34.0019\n",
      "Epoch 338/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.9344 - mse: 33.9344\n",
      "Epoch 339/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.8680 - mse: 33.8680\n",
      "Epoch 340/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.7999 - mse: 33.7999\n",
      "Epoch 341/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.7387 - mse: 33.7387\n",
      "Epoch 342/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.6790 - mse: 33.6790\n",
      "Epoch 343/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.6125 - mse: 33.6125\n",
      "Epoch 344/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.5548 - mse: 33.5548\n",
      "Epoch 345/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.4897 - mse: 33.4897\n",
      "Epoch 346/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.4377 - mse: 33.4377\n",
      "Epoch 347/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.3736 - mse: 33.3736\n",
      "Epoch 348/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.3219 - mse: 33.3219\n",
      "Epoch 349/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.2601 - mse: 33.2601\n",
      "Epoch 350/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.2090 - mse: 33.2090\n",
      "Epoch 351/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.1551 - mse: 33.1551\n",
      "Epoch 352/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.0938 - mse: 33.0938\n",
      "Epoch 353/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.0419 - mse: 33.0419\n",
      "Epoch 354/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.9909 - mse: 32.9909\n",
      "Epoch 355/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.9421 - mse: 32.9421\n",
      "Epoch 356/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.8911 - mse: 32.8911\n",
      "Epoch 357/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.8457 - mse: 32.8457\n",
      "Epoch 358/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.7858 - mse: 32.7858\n",
      "Epoch 359/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.7434 - mse: 32.7434\n",
      "Epoch 360/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.6907 - mse: 32.6907\n",
      "Epoch 361/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.6461 - mse: 32.6461\n",
      "Epoch 362/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.6088 - mse: 32.6088\n",
      "Epoch 363/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.5575 - mse: 32.5575\n",
      "Epoch 364/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.5148 - mse: 32.5148\n",
      "Epoch 365/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.4820 - mse: 32.4820\n",
      "Epoch 366/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.4473 - mse: 32.4473\n",
      "Epoch 367/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.3881 - mse: 32.3881\n",
      "Epoch 368/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.3461 - mse: 32.3461\n",
      "Epoch 369/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32.3029 - mse: 32.3029\n",
      "Epoch 370/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.2652 - mse: 32.2652\n",
      "Epoch 371/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.2296 - mse: 32.2296\n",
      "Epoch 372/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.1852 - mse: 32.1852\n",
      "Epoch 373/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.1477 - mse: 32.1477\n",
      "Epoch 374/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.1133 - mse: 32.1133\n",
      "Epoch 375/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.0748 - mse: 32.0748\n",
      "Epoch 376/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.0389 - mse: 32.0389\n",
      "Epoch 377/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.0081 - mse: 32.0081\n",
      "Epoch 378/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.9683 - mse: 31.9683\n",
      "Epoch 379/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.9375 - mse: 31.9375\n",
      "Epoch 380/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.9060 - mse: 31.9060\n",
      "Epoch 381/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.8706 - mse: 31.8706\n",
      "Epoch 382/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.8386 - mse: 31.8386\n",
      "Epoch 383/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.8215 - mse: 31.8215\n",
      "Epoch 384/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.7803 - mse: 31.7803\n",
      "Epoch 385/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.7512 - mse: 31.7512\n",
      "Epoch 386/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.7246 - mse: 31.7246\n",
      "Epoch 387/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.6904 - mse: 31.6904\n",
      "Epoch 388/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.6603 - mse: 31.6603\n",
      "Epoch 389/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.6375 - mse: 31.6375\n",
      "Epoch 390/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.6106 - mse: 31.6106\n",
      "Epoch 391/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.5816 - mse: 31.5816\n",
      "Epoch 392/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.5559 - mse: 31.5559\n",
      "Epoch 393/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.5469 - mse: 31.5469\n",
      "Epoch 394/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.5087 - mse: 31.5087\n",
      "Epoch 395/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.4814 - mse: 31.4814\n",
      "Epoch 396/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.4624 - mse: 31.4624\n",
      "Epoch 397/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.4443 - mse: 31.4443\n",
      "Epoch 398/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.4165 - mse: 31.4165\n",
      "Epoch 399/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.4072 - mse: 31.4072\n",
      "Epoch 400/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.3716 - mse: 31.3716\n",
      "Epoch 401/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.3485 - mse: 31.3485\n",
      "Epoch 402/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.3294 - mse: 31.3294\n",
      "Epoch 403/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.3113 - mse: 31.3113\n",
      "Epoch 404/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.2920 - mse: 31.2920\n",
      "Epoch 405/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.2683 - mse: 31.2683\n",
      "Epoch 406/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.2517 - mse: 31.2517\n",
      "Epoch 407/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.2326 - mse: 31.2326\n",
      "Epoch 408/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.2136 - mse: 31.2136\n",
      "Epoch 409/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.1963 - mse: 31.1963\n",
      "Epoch 410/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.1798 - mse: 31.1798\n",
      "Epoch 411/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 31.1604 - mse: 31.1604\n",
      "Epoch 412/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.1469 - mse: 31.1469\n",
      "Epoch 413/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.1376 - mse: 31.1376\n",
      "Epoch 414/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.1196 - mse: 31.1196\n",
      "Epoch 415/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.0994 - mse: 31.0994\n",
      "Epoch 416/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.0832 - mse: 31.0832\n",
      "Epoch 417/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.0694 - mse: 31.0694\n",
      "Epoch 418/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.0726 - mse: 31.0726\n",
      "Epoch 419/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.0428 - mse: 31.0428\n",
      "Epoch 420/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.0258 - mse: 31.0258\n",
      "Epoch 421/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.0135 - mse: 31.0135\n",
      "Epoch 422/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.0032 - mse: 31.0032\n",
      "Epoch 423/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.9894 - mse: 30.9894\n",
      "Epoch 424/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.9780 - mse: 30.9780\n",
      "Epoch 425/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.9636 - mse: 30.9636\n",
      "Epoch 426/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.9524 - mse: 30.9524\n",
      "Epoch 427/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.9419 - mse: 30.9419\n",
      "Epoch 428/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.9307 - mse: 30.9307\n",
      "Epoch 429/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.9216 - mse: 30.9216\n",
      "Epoch 430/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.9047 - mse: 30.9047\n",
      "Epoch 431/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8999 - mse: 30.8999\n",
      "Epoch 432/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8874 - mse: 30.8874\n",
      "Epoch 433/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8762 - mse: 30.8762\n",
      "Epoch 434/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8743 - mse: 30.8743\n",
      "Epoch 435/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8610 - mse: 30.8610\n",
      "Epoch 436/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8490 - mse: 30.8490\n",
      "Epoch 437/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8417 - mse: 30.8417\n",
      "Epoch 438/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8305 - mse: 30.8305\n",
      "Epoch 439/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8377 - mse: 30.8377\n",
      "Epoch 440/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8216 - mse: 30.8216\n",
      "Epoch 441/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8085 - mse: 30.8085\n",
      "Epoch 442/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8000 - mse: 30.8000\n",
      "Epoch 443/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7906 - mse: 30.7906\n",
      "Epoch 444/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7856 - mse: 30.7856\n",
      "Epoch 445/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7745 - mse: 30.7745\n",
      "Epoch 446/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7663 - mse: 30.7663\n",
      "Epoch 447/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7687 - mse: 30.7687\n",
      "Epoch 448/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7537 - mse: 30.7537\n",
      "Epoch 449/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.7513 - mse: 30.7513\n",
      "Epoch 450/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7502 - mse: 30.7502\n",
      "Epoch 451/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.7366 - mse: 30.7366\n",
      "Epoch 452/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7352 - mse: 30.7352\n",
      "Epoch 453/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.7257 - mse: 30.7257\n",
      "Epoch 454/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7188 - mse: 30.7188\n",
      "Epoch 455/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7151 - mse: 30.7151\n",
      "Epoch 456/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7096 - mse: 30.7096\n",
      "Epoch 457/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.7106 - mse: 30.7106\n",
      "Epoch 458/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6995 - mse: 30.6995\n",
      "Epoch 459/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6998 - mse: 30.6998\n",
      "Epoch 460/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6947 - mse: 30.6947\n",
      "Epoch 461/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6887 - mse: 30.6887\n",
      "Epoch 462/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6860 - mse: 30.6860\n",
      "Epoch 463/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6754 - mse: 30.6754\n",
      "Epoch 464/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6729 - mse: 30.6729\n",
      "Epoch 465/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6669 - mse: 30.6669\n",
      "Epoch 466/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6667 - mse: 30.6667\n",
      "Epoch 467/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6655 - mse: 30.6655\n",
      "Epoch 468/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6580 - mse: 30.6580\n",
      "Epoch 469/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6535 - mse: 30.6535\n",
      "Epoch 470/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6515 - mse: 30.6515\n",
      "Epoch 471/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6444 - mse: 30.6444\n",
      "Epoch 472/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6467 - mse: 30.6467\n",
      "Epoch 473/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6368 - mse: 30.6368\n",
      "Epoch 474/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6372 - mse: 30.6372\n",
      "Epoch 475/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6346 - mse: 30.6346\n",
      "Epoch 476/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6369 - mse: 30.6369\n",
      "Epoch 477/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6314 - mse: 30.6314\n",
      "Epoch 478/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6292 - mse: 30.6292\n",
      "Epoch 479/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6198 - mse: 30.6198\n",
      "Epoch 480/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6176 - mse: 30.6176\n",
      "Epoch 481/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6152 - mse: 30.6152\n",
      "Epoch 482/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6135 - mse: 30.6135\n",
      "Epoch 483/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6169 - mse: 30.6169\n",
      "Epoch 484/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6081 - mse: 30.6081\n",
      "Epoch 485/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6066 - mse: 30.6066\n",
      "Epoch 486/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6026 - mse: 30.6026\n",
      "Epoch 487/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6004 - mse: 30.6004\n",
      "Epoch 488/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5987 - mse: 30.5987\n",
      "Epoch 489/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6133 - mse: 30.6133\n",
      "Epoch 490/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5932 - mse: 30.5932\n",
      "Epoch 491/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5920 - mse: 30.5920\n",
      "Epoch 492/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5920 - mse: 30.5920\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5894 - mse: 30.5894\n",
      "Epoch 494/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5924 - mse: 30.5924\n",
      "Epoch 495/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5956 - mse: 30.5956\n",
      "Epoch 496/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5887 - mse: 30.5887\n",
      "Epoch 497/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.6016 - mse: 30.6016\n",
      "Epoch 498/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5812 - mse: 30.5812\n",
      "Epoch 499/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5905 - mse: 30.5905\n",
      "Epoch 500/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5866 - mse: 30.5866\n",
      "Epoch 501/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5848 - mse: 30.5848\n",
      "Epoch 502/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5880 - mse: 30.5880\n",
      "Epoch 503/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5734 - mse: 30.5734\n",
      "Epoch 504/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5736 - mse: 30.5736\n",
      "Epoch 505/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5800 - mse: 30.5800\n",
      "Epoch 506/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5719 - mse: 30.5719\n",
      "Epoch 507/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5680 - mse: 30.5680\n",
      "Epoch 508/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5741 - mse: 30.5741\n",
      "Epoch 509/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5702 - mse: 30.5702\n",
      "Epoch 510/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5654 - mse: 30.5654\n",
      "Epoch 511/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5676 - mse: 30.5676\n",
      "Epoch 512/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5621 - mse: 30.5621\n",
      "Epoch 513/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5753 - mse: 30.5753\n",
      "Epoch 514/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5646 - mse: 30.5646\n",
      "Epoch 515/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5688 - mse: 30.5688\n",
      "Epoch 516/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5605 - mse: 30.5605\n",
      "Epoch 517/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5643 - mse: 30.5643\n",
      "Epoch 518/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5582 - mse: 30.5582\n",
      "Epoch 519/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5599 - mse: 30.5599\n",
      "Epoch 520/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5655 - mse: 30.5655\n",
      "Epoch 521/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5566 - mse: 30.5566\n",
      "Epoch 522/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5540 - mse: 30.5540\n",
      "Epoch 523/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5543 - mse: 30.5543\n",
      "Epoch 524/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5539 - mse: 30.5539\n",
      "Epoch 525/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5751 - mse: 30.5751\n",
      "Epoch 526/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5619 - mse: 30.5619\n",
      "Epoch 527/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5569 - mse: 30.5569\n",
      "Epoch 528/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5594 - mse: 30.5594\n",
      "Epoch 529/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5504 - mse: 30.5504\n",
      "Epoch 530/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5490 - mse: 30.5490\n",
      "Epoch 531/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5555 - mse: 30.5555\n",
      "Epoch 532/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5523 - mse: 30.5523\n",
      "Epoch 533/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5569 - mse: 30.5569\n",
      "Epoch 534/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5456 - mse: 30.5456\n",
      "Epoch 535/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5455 - mse: 30.5455\n",
      "Epoch 536/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5488 - mse: 30.5488\n",
      "Epoch 537/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5459 - mse: 30.5459\n",
      "Epoch 538/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5442 - mse: 30.5442\n",
      "Epoch 539/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5482 - mse: 30.5482\n",
      "Epoch 540/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5471 - mse: 30.5471\n",
      "Epoch 541/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5462 - mse: 30.5462\n",
      "Epoch 542/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5441 - mse: 30.5441\n",
      "Epoch 543/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5468 - mse: 30.5468\n",
      "Epoch 544/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5731 - mse: 30.5731\n",
      "Epoch 545/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5606 - mse: 30.5606\n",
      "Epoch 546/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5596 - mse: 30.5596\n",
      "Epoch 547/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5450 - mse: 30.5450\n",
      "Epoch 548/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5440 - mse: 30.5440\n",
      "Epoch 549/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5418 - mse: 30.5418\n",
      "Epoch 550/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5413 - mse: 30.5413\n",
      "Epoch 551/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5459 - mse: 30.5459\n",
      "Epoch 552/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5509 - mse: 30.5509\n",
      "Epoch 553/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5421 - mse: 30.5421\n",
      "Epoch 554/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5493 - mse: 30.5493\n",
      "Epoch 555/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5372 - mse: 30.5372\n",
      "Epoch 556/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5386 - mse: 30.5386\n",
      "Epoch 557/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5387 - mse: 30.5387\n",
      "Epoch 558/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5418 - mse: 30.5418\n",
      "Epoch 559/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5414 - mse: 30.5414\n",
      "Epoch 560/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5460 - mse: 30.5460\n",
      "Epoch 561/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5380 - mse: 30.5380\n",
      "Epoch 562/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5390 - mse: 30.5390\n",
      "Epoch 563/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5453 - mse: 30.5453\n",
      "Epoch 564/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5388 - mse: 30.5388\n",
      "Epoch 565/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5396 - mse: 30.5396\n",
      "Epoch 566/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5407 - mse: 30.5407\n",
      "Epoch 567/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5390 - mse: 30.5390\n",
      "Epoch 568/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5367 - mse: 30.5367\n",
      "Epoch 569/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5367 - mse: 30.5367\n",
      "Epoch 570/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5397 - mse: 30.5397\n",
      "Epoch 571/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5393 - mse: 30.5393\n",
      "Epoch 572/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5368 - mse: 30.5368\n",
      "Epoch 573/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5399 - mse: 30.5399\n",
      "Epoch 574/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5348 - mse: 30.5348\n",
      "Epoch 575/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5365 - mse: 30.5365\n",
      "Epoch 576/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5399 - mse: 30.5399\n",
      "Epoch 577/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5353 - mse: 30.5353\n",
      "Epoch 578/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5347 - mse: 30.5347\n",
      "Epoch 579/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5427 - mse: 30.5427\n",
      "Epoch 580/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5367 - mse: 30.5367\n",
      "Epoch 581/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5394 - mse: 30.5394\n",
      "Epoch 582/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5344 - mse: 30.5344\n",
      "Epoch 583/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5387 - mse: 30.5387\n",
      "Epoch 584/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5379 - mse: 30.5379\n",
      "Epoch 585/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5353 - mse: 30.5353\n",
      "Epoch 586/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5402 - mse: 30.5402\n",
      "Epoch 587/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5371 - mse: 30.5371\n",
      "Epoch 588/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5355 - mse: 30.5355\n",
      "Epoch 589/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5371 - mse: 30.5371\n",
      "Epoch 590/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5426 - mse: 30.5426\n",
      "Epoch 591/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5341 - mse: 30.5341\n",
      "Epoch 592/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5327 - mse: 30.5327\n",
      "Epoch 593/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5331 - mse: 30.5331\n",
      "Epoch 594/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5412 - mse: 30.5412\n",
      "Epoch 595/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5324 - mse: 30.5324\n",
      "Epoch 596/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5337 - mse: 30.5337\n",
      "Epoch 597/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5455 - mse: 30.5455\n",
      "Epoch 598/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5614 - mse: 30.5614\n",
      "Epoch 599/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5344 - mse: 30.5344\n",
      "Epoch 600/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5352 - mse: 30.5352\n",
      "Epoch 601/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5352 - mse: 30.5352\n",
      "Epoch 602/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5441 - mse: 30.5441\n",
      "Epoch 603/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5323 - mse: 30.5323\n",
      "Epoch 604/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5331 - mse: 30.5331\n",
      "Epoch 605/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5333 - mse: 30.5333\n",
      "Epoch 606/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5348 - mse: 30.5348\n",
      "Epoch 607/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5314 - mse: 30.5314\n",
      "Epoch 608/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5368 - mse: 30.5368\n",
      "Epoch 609/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5379 - mse: 30.5379\n",
      "Epoch 610/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5423 - mse: 30.5423\n",
      "Epoch 611/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5324 - mse: 30.5324\n",
      "Epoch 612/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5358 - mse: 30.5358\n",
      "Epoch 613/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5335 - mse: 30.5335\n",
      "Epoch 614/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5352 - mse: 30.5352\n",
      "Epoch 615/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5370 - mse: 30.5370\n",
      "Epoch 616/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5367 - mse: 30.5367\n",
      "Epoch 617/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5323 - mse: 30.5323\n",
      "Epoch 618/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5356 - mse: 30.5356\n",
      "Epoch 619/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 620/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5373 - mse: 30.5373\n",
      "Epoch 621/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5313 - mse: 30.5313\n",
      "Epoch 622/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5338 - mse: 30.5338\n",
      "Epoch 623/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5306 - mse: 30.5306\n",
      "Epoch 624/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5300 - mse: 30.5300\n",
      "Epoch 625/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 626/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5301 - mse: 30.5301\n",
      "Epoch 627/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5327 - mse: 30.5327\n",
      "Epoch 628/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5388 - mse: 30.5388\n",
      "Epoch 629/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5314 - mse: 30.5314\n",
      "Epoch 630/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5330 - mse: 30.5330\n",
      "Epoch 631/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5306 - mse: 30.5306\n",
      "Epoch 632/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5360 - mse: 30.5360\n",
      "Epoch 633/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5292 - mse: 30.5292\n",
      "Epoch 634/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5321 - mse: 30.5321\n",
      "Epoch 635/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5358 - mse: 30.5358\n",
      "Epoch 636/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5290 - mse: 30.5290\n",
      "Epoch 637/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5342 - mse: 30.5342\n",
      "Epoch 638/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5357 - mse: 30.5357\n",
      "Epoch 639/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5388 - mse: 30.5388\n",
      "Epoch 640/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5287 - mse: 30.5287\n",
      "Epoch 641/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5485 - mse: 30.5485\n",
      "Epoch 642/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5341 - mse: 30.5341\n",
      "Epoch 643/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5315 - mse: 30.5315\n",
      "Epoch 644/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5397 - mse: 30.5397\n",
      "Epoch 645/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5311 - mse: 30.5311\n",
      "Epoch 646/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5291 - mse: 30.5291\n",
      "Epoch 647/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5325 - mse: 30.5325\n",
      "Epoch 648/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5310 - mse: 30.5310\n",
      "Epoch 649/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5298 - mse: 30.5298\n",
      "Epoch 650/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5292 - mse: 30.5292\n",
      "Epoch 651/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5410 - mse: 30.5410\n",
      "Epoch 652/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5313 - mse: 30.5313\n",
      "Epoch 653/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5439 - mse: 30.5439\n",
      "Epoch 654/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5318 - mse: 30.5318\n",
      "Epoch 655/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5356 - mse: 30.5356\n",
      "Epoch 656/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5324 - mse: 30.5324\n",
      "Epoch 657/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5283 - mse: 30.5283\n",
      "Epoch 658/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5314 - mse: 30.5314\n",
      "Epoch 659/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5329 - mse: 30.5329\n",
      "Epoch 660/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5301 - mse: 30.5301\n",
      "Epoch 661/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5298 - mse: 30.5298\n",
      "Epoch 662/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5335 - mse: 30.5335\n",
      "Epoch 663/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5368 - mse: 30.5368\n",
      "Epoch 664/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5297 - mse: 30.5297\n",
      "Epoch 665/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5302 - mse: 30.5302\n",
      "Epoch 666/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5297 - mse: 30.5297\n",
      "Epoch 667/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5332 - mse: 30.5332\n",
      "Epoch 668/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5357 - mse: 30.5357\n",
      "Epoch 669/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5428 - mse: 30.5428\n",
      "Epoch 670/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5308 - mse: 30.5308\n",
      "Epoch 671/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 672/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5286 - mse: 30.5286\n",
      "Epoch 673/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5280 - mse: 30.5280\n",
      "Epoch 674/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5411 - mse: 30.5411\n",
      "Epoch 675/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5292 - mse: 30.5292\n",
      "Epoch 676/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5314 - mse: 30.5314\n",
      "Epoch 677/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5419 - mse: 30.5419\n",
      "Epoch 678/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5438 - mse: 30.5438\n",
      "Epoch 679/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5309 - mse: 30.5309\n",
      "Epoch 680/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5297 - mse: 30.5297\n",
      "Epoch 681/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5381 - mse: 30.5381\n",
      "Epoch 682/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 683/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5333 - mse: 30.5333\n",
      "Epoch 684/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5302 - mse: 30.5302\n",
      "Epoch 685/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5288 - mse: 30.5288\n",
      "Epoch 686/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 687/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5315 - mse: 30.5315\n",
      "Epoch 688/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 689/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5357 - mse: 30.5357\n",
      "Epoch 690/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5338 - mse: 30.5338\n",
      "Epoch 691/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5337 - mse: 30.5337\n",
      "Epoch 692/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5311 - mse: 30.5311\n",
      "Epoch 693/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5295 - mse: 30.5295\n",
      "Epoch 694/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5331 - mse: 30.5331\n",
      "Epoch 695/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 696/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5278 - mse: 30.5278\n",
      "Epoch 697/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5350 - mse: 30.5350\n",
      "Epoch 698/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5304 - mse: 30.5304\n",
      "Epoch 699/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5277 - mse: 30.5277\n",
      "Epoch 700/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5384 - mse: 30.5384\n",
      "Epoch 701/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 702/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5298 - mse: 30.5298\n",
      "Epoch 703/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5267 - mse: 30.5267\n",
      "Epoch 704/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5298 - mse: 30.5298\n",
      "Epoch 705/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5261 - mse: 30.5261\n",
      "Epoch 706/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5288 - mse: 30.5288\n",
      "Epoch 707/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5269 - mse: 30.5269\n",
      "Epoch 708/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5325 - mse: 30.5325\n",
      "Epoch 709/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5373 - mse: 30.5373\n",
      "Epoch 710/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5259 - mse: 30.5259\n",
      "Epoch 711/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5280 - mse: 30.5280\n",
      "Epoch 712/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5253 - mse: 30.5253\n",
      "Epoch 713/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5329 - mse: 30.5329\n",
      "Epoch 714/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5319 - mse: 30.5319\n",
      "Epoch 715/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5303 - mse: 30.5303\n",
      "Epoch 716/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5417 - mse: 30.5417\n",
      "Epoch 717/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5232 - mse: 30.5232\n",
      "Epoch 718/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5278 - mse: 30.5278\n",
      "Epoch 719/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5349 - mse: 30.5349\n",
      "Epoch 720/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5369 - mse: 30.5369\n",
      "Epoch 721/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5308 - mse: 30.5308\n",
      "Epoch 722/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5258 - mse: 30.5258\n",
      "Epoch 723/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5387 - mse: 30.5387\n",
      "Epoch 724/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 725/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5271 - mse: 30.5271\n",
      "Epoch 726/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5316 - mse: 30.5316\n",
      "Epoch 727/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 728/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5319 - mse: 30.5319\n",
      "Epoch 729/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5326 - mse: 30.5326\n",
      "Epoch 730/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5266 - mse: 30.5266\n",
      "Epoch 731/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5299 - mse: 30.5299\n",
      "Epoch 732/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5293 - mse: 30.5293\n",
      "Epoch 733/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5326 - mse: 30.5326\n",
      "Epoch 734/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5263 - mse: 30.5263\n",
      "Epoch 735/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5430 - mse: 30.5430\n",
      "Epoch 736/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5263 - mse: 30.5263\n",
      "Epoch 737/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5370 - mse: 30.5370\n",
      "Epoch 738/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5318 - mse: 30.5318\n",
      "Epoch 739/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5356 - mse: 30.5356\n",
      "Epoch 740/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5267 - mse: 30.5267\n",
      "Epoch 741/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5357 - mse: 30.5357\n",
      "Epoch 742/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5259 - mse: 30.5259\n",
      "Epoch 743/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5350 - mse: 30.5350\n",
      "Epoch 744/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5269 - mse: 30.5269\n",
      "Epoch 745/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5340 - mse: 30.5340\n",
      "Epoch 746/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5351 - mse: 30.5351\n",
      "Epoch 747/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5282 - mse: 30.5282\n",
      "Epoch 748/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5288 - mse: 30.5288\n",
      "Epoch 749/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5298 - mse: 30.5298\n",
      "Epoch 750/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5319 - mse: 30.5319\n",
      "Epoch 751/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5465 - mse: 30.5465\n",
      "Epoch 752/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5257 - mse: 30.5257\n",
      "Epoch 753/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5334 - mse: 30.5334\n",
      "Epoch 754/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5476 - mse: 30.5476\n",
      "Epoch 755/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5252 - mse: 30.5252\n",
      "Epoch 756/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5300 - mse: 30.5300\n",
      "Epoch 757/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 758/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5281 - mse: 30.5281\n",
      "Epoch 759/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5309 - mse: 30.5309\n",
      "Epoch 760/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 761/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 762/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5252 - mse: 30.5252\n",
      "Epoch 763/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5277 - mse: 30.5277\n",
      "Epoch 764/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5286 - mse: 30.5286\n",
      "Epoch 765/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5284 - mse: 30.5284\n",
      "Epoch 766/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5260 - mse: 30.5260\n",
      "Epoch 767/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5541 - mse: 30.5541\n",
      "Epoch 768/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5273 - mse: 30.5273\n",
      "Epoch 769/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5260 - mse: 30.5260\n",
      "Epoch 770/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5258 - mse: 30.5258\n",
      "Epoch 771/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 772/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5297 - mse: 30.5297\n",
      "Epoch 773/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5320 - mse: 30.5320\n",
      "Epoch 774/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5241 - mse: 30.5241\n",
      "Epoch 775/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5276 - mse: 30.5276\n",
      "Epoch 776/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 777/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5315 - mse: 30.5315\n",
      "Epoch 778/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5429 - mse: 30.5429\n",
      "Epoch 779/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5248 - mse: 30.5248\n",
      "Epoch 780/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5247 - mse: 30.5247\n",
      "Epoch 781/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5236 - mse: 30.5236\n",
      "Epoch 782/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5383 - mse: 30.5383\n",
      "Epoch 783/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5226 - mse: 30.5226\n",
      "Epoch 784/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 785/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5279 - mse: 30.5279\n",
      "Epoch 786/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5235 - mse: 30.5235\n",
      "Epoch 787/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5266 - mse: 30.5266\n",
      "Epoch 788/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5316 - mse: 30.5316\n",
      "Epoch 789/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5288 - mse: 30.5288\n",
      "Epoch 790/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5242 - mse: 30.5242\n",
      "Epoch 791/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5382 - mse: 30.5382\n",
      "Epoch 792/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5279 - mse: 30.5279\n",
      "Epoch 793/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 794/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5340 - mse: 30.5340\n",
      "Epoch 795/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5300 - mse: 30.5300\n",
      "Epoch 796/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5277 - mse: 30.5277\n",
      "Epoch 797/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5238 - mse: 30.5238\n",
      "Epoch 798/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5270 - mse: 30.5270\n",
      "Epoch 799/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5268 - mse: 30.5268\n",
      "Epoch 800/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5232 - mse: 30.5232\n",
      "Epoch 801/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5295 - mse: 30.5295\n",
      "Epoch 802/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5353 - mse: 30.5353\n",
      "Epoch 803/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5235 - mse: 30.5235\n",
      "Epoch 804/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5283 - mse: 30.5283\n",
      "Epoch 805/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5271 - mse: 30.5271\n",
      "Epoch 806/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5282 - mse: 30.5282\n",
      "Epoch 807/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5230 - mse: 30.5230\n",
      "Epoch 808/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5291 - mse: 30.5291\n",
      "Epoch 809/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 810/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5234 - mse: 30.5234\n",
      "Epoch 811/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5246 - mse: 30.5246\n",
      "Epoch 812/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5292 - mse: 30.5292\n",
      "Epoch 813/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5254 - mse: 30.5254\n",
      "Epoch 814/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5231 - mse: 30.5231\n",
      "Epoch 815/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 816/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5229 - mse: 30.5229\n",
      "Epoch 817/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5261 - mse: 30.5261\n",
      "Epoch 818/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 819/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5333 - mse: 30.5333\n",
      "Epoch 820/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5359 - mse: 30.5359\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5240 - mse: 30.5240\n",
      "Epoch 822/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5264 - mse: 30.5264\n",
      "Epoch 823/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5394 - mse: 30.5394\n",
      "Epoch 824/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5309 - mse: 30.5309\n",
      "Epoch 825/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5462 - mse: 30.5462\n",
      "Epoch 826/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 827/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5232 - mse: 30.5232\n",
      "Epoch 828/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5301 - mse: 30.5301\n",
      "Epoch 829/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5234 - mse: 30.5234\n",
      "Epoch 830/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5367 - mse: 30.5367\n",
      "Epoch 831/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5236 - mse: 30.5236\n",
      "Epoch 832/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5213 - mse: 30.5213\n",
      "Epoch 833/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5253 - mse: 30.5253\n",
      "Epoch 834/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5248 - mse: 30.5248\n",
      "Epoch 835/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5267 - mse: 30.5267\n",
      "Epoch 836/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5253 - mse: 30.5253\n",
      "Epoch 837/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 838/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 839/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 840/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5376 - mse: 30.5376\n",
      "Epoch 841/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 842/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5240 - mse: 30.5240\n",
      "Epoch 843/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5376 - mse: 30.5376\n",
      "Epoch 844/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5383 - mse: 30.5383\n",
      "Epoch 845/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5258 - mse: 30.5258\n",
      "Epoch 846/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5241 - mse: 30.5241\n",
      "Epoch 847/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 848/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5235 - mse: 30.5235\n",
      "Epoch 849/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 850/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5219 - mse: 30.5219\n",
      "Epoch 851/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5271 - mse: 30.5271\n",
      "Epoch 852/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 853/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 854/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5272 - mse: 30.5272\n",
      "Epoch 855/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5293 - mse: 30.5293\n",
      "Epoch 856/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5373 - mse: 30.5373\n",
      "Epoch 857/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5295 - mse: 30.5295\n",
      "Epoch 858/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5247 - mse: 30.5247\n",
      "Epoch 859/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5242 - mse: 30.5242\n",
      "Epoch 860/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5262 - mse: 30.5262\n",
      "Epoch 861/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5265 - mse: 30.5265\n",
      "Epoch 862/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5245 - mse: 30.5245\n",
      "Epoch 863/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 864/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5286 - mse: 30.5286\n",
      "Epoch 865/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5257 - mse: 30.5257\n",
      "Epoch 866/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 867/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5224 - mse: 30.5224\n",
      "Epoch 868/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5252 - mse: 30.5252\n",
      "Epoch 869/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5261 - mse: 30.5261\n",
      "Epoch 870/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 871/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5220 - mse: 30.5220\n",
      "Epoch 872/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5281 - mse: 30.5281\n",
      "Epoch 873/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5267 - mse: 30.5267\n",
      "Epoch 874/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5244 - mse: 30.5244\n",
      "Epoch 875/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5317 - mse: 30.5317\n",
      "Epoch 876/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5337 - mse: 30.5337\n",
      "Epoch 877/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5224 - mse: 30.5224\n",
      "Epoch 878/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5270 - mse: 30.5270\n",
      "Epoch 879/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5268 - mse: 30.5268\n",
      "Epoch 880/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5329 - mse: 30.5329\n",
      "Epoch 881/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5231 - mse: 30.5231\n",
      "Epoch 882/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5221 - mse: 30.5221\n",
      "Epoch 883/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5269 - mse: 30.5269\n",
      "Epoch 884/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5201 - mse: 30.5201\n",
      "Epoch 885/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5245 - mse: 30.5245\n",
      "Epoch 886/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5237 - mse: 30.5237\n",
      "Epoch 887/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5208 - mse: 30.5208\n",
      "Epoch 888/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5268 - mse: 30.5268\n",
      "Epoch 889/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 890/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5202 - mse: 30.5202\n",
      "Epoch 891/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5207 - mse: 30.5207\n",
      "Epoch 892/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5258 - mse: 30.5258\n",
      "Epoch 893/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5221 - mse: 30.5221\n",
      "Epoch 894/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5295 - mse: 30.5295\n",
      "Epoch 895/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 896/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5255 - mse: 30.5255\n",
      "Epoch 897/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5246 - mse: 30.5246\n",
      "Epoch 898/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5392 - mse: 30.5392\n",
      "Epoch 899/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5307 - mse: 30.5307\n",
      "Epoch 900/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5215 - mse: 30.5215\n",
      "Epoch 901/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5235 - mse: 30.5235\n",
      "Epoch 902/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5307 - mse: 30.5307\n",
      "Epoch 903/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 904/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5197 - mse: 30.5197\n",
      "Epoch 905/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5212 - mse: 30.5212\n",
      "Epoch 906/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5338 - mse: 30.5338\n",
      "Epoch 907/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 908/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5234 - mse: 30.5234\n",
      "Epoch 909/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5246 - mse: 30.5246\n",
      "Epoch 910/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5261 - mse: 30.5261\n",
      "Epoch 911/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5387 - mse: 30.5387\n",
      "Epoch 912/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5261 - mse: 30.5261\n",
      "Epoch 913/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5239 - mse: 30.5239\n",
      "Epoch 914/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5196 - mse: 30.5196\n",
      "Epoch 915/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5238 - mse: 30.5238\n",
      "Epoch 916/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5291 - mse: 30.5291\n",
      "Epoch 917/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5239 - mse: 30.5239\n",
      "Epoch 918/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5212 - mse: 30.5212\n",
      "Epoch 919/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5215 - mse: 30.5215\n",
      "Epoch 920/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5222 - mse: 30.5222\n",
      "Epoch 921/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5208 - mse: 30.5208\n",
      "Epoch 922/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5221 - mse: 30.5221\n",
      "Epoch 923/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5246 - mse: 30.5246\n",
      "Epoch 924/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5239 - mse: 30.5239\n",
      "Epoch 925/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5201 - mse: 30.5201\n",
      "Epoch 926/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5234 - mse: 30.5234\n",
      "Epoch 927/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 928/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 929/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5372 - mse: 30.5372\n",
      "Epoch 930/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5191 - mse: 30.5191\n",
      "Epoch 931/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5313 - mse: 30.5313\n",
      "Epoch 932/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5211 - mse: 30.5211\n",
      "Epoch 933/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5357 - mse: 30.5357\n",
      "Epoch 934/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5228 - mse: 30.5228\n",
      "Epoch 935/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5245 - mse: 30.5245\n",
      "Epoch 936/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 937/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5262 - mse: 30.5262\n",
      "Epoch 938/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5245 - mse: 30.5245\n",
      "Epoch 939/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 940/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5220 - mse: 30.5220\n",
      "Epoch 941/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 942/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5225 - mse: 30.5225\n",
      "Epoch 943/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5201 - mse: 30.5201\n",
      "Epoch 944/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5323 - mse: 30.5323\n",
      "Epoch 945/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5209 - mse: 30.5209\n",
      "Epoch 946/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5253 - mse: 30.5253\n",
      "Epoch 947/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5222 - mse: 30.5222\n",
      "Epoch 948/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5263 - mse: 30.5263\n",
      "Epoch 949/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5255 - mse: 30.5255\n",
      "Epoch 950/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5225 - mse: 30.5225\n",
      "Epoch 951/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5207 - mse: 30.5207\n",
      "Epoch 952/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5242 - mse: 30.5242\n",
      "Epoch 953/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5311 - mse: 30.5311\n",
      "Epoch 954/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5324 - mse: 30.5324\n",
      "Epoch 955/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5271 - mse: 30.5271\n",
      "Epoch 956/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5206 - mse: 30.5206\n",
      "Epoch 957/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5398 - mse: 30.5398\n",
      "Epoch 958/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5227 - mse: 30.5227\n",
      "Epoch 959/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5241 - mse: 30.5241\n",
      "Epoch 960/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5262 - mse: 30.5262\n",
      "Epoch 961/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5293 - mse: 30.5293\n",
      "Epoch 962/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5235 - mse: 30.5235\n",
      "Epoch 963/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5246 - mse: 30.5246\n",
      "Epoch 964/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5191 - mse: 30.5191\n",
      "Epoch 965/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5276 - mse: 30.5276\n",
      "Epoch 966/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5228 - mse: 30.5228\n",
      "Epoch 967/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5361 - mse: 30.5361\n",
      "Epoch 968/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5251 - mse: 30.5251\n",
      "Epoch 969/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5310 - mse: 30.5310\n",
      "Epoch 970/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5230 - mse: 30.5230\n",
      "Epoch 971/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5236 - mse: 30.5236\n",
      "Epoch 972/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5248 - mse: 30.5248\n",
      "Epoch 973/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 974/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5280 - mse: 30.5280\n",
      "Epoch 975/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5196 - mse: 30.5196\n",
      "Epoch 976/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5285 - mse: 30.5285\n",
      "Epoch 977/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5221 - mse: 30.5221\n",
      "Epoch 978/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5215 - mse: 30.5215\n",
      "Epoch 979/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5235 - mse: 30.5235\n",
      "Epoch 980/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5227 - mse: 30.5227\n",
      "Epoch 981/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5226 - mse: 30.5226\n",
      "Epoch 982/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5187 - mse: 30.5187\n",
      "Epoch 983/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5319 - mse: 30.5319\n",
      "Epoch 984/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5196 - mse: 30.5196\n",
      "Epoch 985/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5199 - mse: 30.5199\n",
      "Epoch 986/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5198 - mse: 30.5198\n",
      "Epoch 987/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5222 - mse: 30.5222\n",
      "Epoch 988/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5195 - mse: 30.5195\n",
      "Epoch 989/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 990/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5248 - mse: 30.5248\n",
      "Epoch 991/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.5291 - mse: 30.5291\n",
      "Epoch 992/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5203 - mse: 30.5203\n",
      "Epoch 993/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5227 - mse: 30.5227\n",
      "Epoch 994/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5347 - mse: 30.5347\n",
      "Epoch 995/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5205 - mse: 30.5205\n",
      "Epoch 996/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5192 - mse: 30.5192\n",
      "Epoch 997/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5194 - mse: 30.5194\n",
      "Epoch 998/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5207 - mse: 30.5207\n",
      "Epoch 999/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5265 - mse: 30.5265\n",
      "Epoch 1000/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.5211 - mse: 30.5211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16cfa86d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(1, input_shape=(2, ), activation=None, kernel_initializer='zeros', bias_initializer='ones')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mse'])\n",
    "model.fit(scaled_features, bostonDF['PRICE'].values, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ea1d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-09 10:46:58.170298: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PREDICTED_PRICE</th>\n",
       "      <th>KERAS_PREDICTED_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.298946</td>\n",
       "      <td>28.972961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>24.270017</td>\n",
       "      <td>25.496746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>28.842337</td>\n",
       "      <td>32.629341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>28.551276</td>\n",
       "      <td>32.408020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>28.244935</td>\n",
       "      <td>31.593445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "      <td>25.692891</td>\n",
       "      <td>28.101097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "      <td>21.626138</td>\n",
       "      <td>21.317303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "      <td>19.827786</td>\n",
       "      <td>17.737459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "      <td>14.056539</td>\n",
       "      <td>8.022593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.945095</td>\n",
       "      <td>18.235983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  PREDICTED_PRICE  KERAS_PREDICTED_PRICE  \n",
       "0     15.3  396.90   4.98   24.0        26.298946              28.972961  \n",
       "1     17.8  396.90   9.14   21.6        24.270017              25.496746  \n",
       "2     17.8  392.83   4.03   34.7        28.842337              32.629341  \n",
       "3     18.7  394.63   2.94   33.4        28.551276              32.408020  \n",
       "4     18.7  396.90   5.33   36.2        28.244935              31.593445  \n",
       "5     18.7  394.12   5.21   28.7        25.692891              28.101097  \n",
       "6     15.2  395.60  12.43   22.9        21.626138              21.317303  \n",
       "7     15.2  396.90  19.15   27.1        19.827786              17.737459  \n",
       "8     15.2  386.63  29.93   16.5        14.056539               8.022593  \n",
       "9     15.2  386.71  17.10   18.9        19.945095              18.235983  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict(scaled_features)\n",
    "bostonDF['KERAS_PREDICTED_PRICE'] = predicted\n",
    "bostonDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9c5db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
