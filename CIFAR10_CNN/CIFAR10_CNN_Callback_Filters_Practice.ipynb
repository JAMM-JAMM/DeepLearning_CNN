{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35936b01",
   "metadata": {},
   "source": [
    "### Date Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdba344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268e8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# set seed\n",
    "def set_random_seed(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    python_random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "# data preprocessing to float32\n",
    "def get_preprocessed_data(images, labels):\n",
    "    \n",
    "    images = np.array(images/255.0, dtype=np.float32)\n",
    "\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# data preprocessing to one hot encoding\n",
    "def get_preprocessed_ohe(images, labels):\n",
    "    \n",
    "    images, labels = get_preprocessed_data(images, labels)\n",
    "    oh_labels = to_categorical(labels)\n",
    "    \n",
    "    return images, oh_labels\n",
    "\n",
    "# train/validation/test split\n",
    "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
    "    \n",
    "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
    "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
    "    \n",
    "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
    "    \n",
    "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fdc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "set_random_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3aa38b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset shape:  (50000, 32, 32, 3) (50000, 1)\n",
      "test dataset shape:  (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10 dataset load\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    cifar10.load_data()\n",
    "\n",
    "print('train dataset shape: ', train_images.shape, train_labels.shape)\n",
    "print('test dataset shape: ', test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec3e5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset shape:  (42500, 32, 32, 3) (42500, 10)\n",
      "validation dataset shape:  (7500, 32, 32, 3) (7500, 10)\n",
      "test dataset shape:  (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10 dataset preprocessing & split\n",
    "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
    "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
    "\n",
    "print('train dataset shape: ', tr_images.shape, tr_oh_labels.shape)\n",
    "print('validation dataset shape: ', val_images.shape, val_oh_labels.shape)\n",
    "print('test dataset shape: ', test_images.shape, test_oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f82e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e977e",
   "metadata": {},
   "source": [
    "### Model Create Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0368fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def create_model(verbose=False):\n",
    "    \n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    \n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(300, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "    \n",
    "    output = Dense(10, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2fb0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: *.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!rm *.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dcbe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path:  /Users/jamm/Documents/Github/AI/DeepLearning_CNN/CIFAR10_CNN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print('current path: ', current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee70d54",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27f302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=current_path + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    model='min',\n",
    "    period=1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88870ef6",
   "metadata": {},
   "source": [
    "### Compile & Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "688aaf5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 13:14:44.996645: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-08-20 13:14:44.996741: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/jamm/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2021-08-20 13:14:45.275207: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-20 13:14:45.275398: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   1/1329 [..............................] - ETA: 8:52 - loss: 3.3774 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 13:14:45.494240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - ETA: 0s - loss: 1.5534 - accuracy: 0.4349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 13:15:12.221482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - 29s 21ms/step - loss: 1.5534 - accuracy: 0.4349 - val_loss: 2.1748 - val_accuracy: 0.3211\n",
      "Epoch 2/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 1.1183 - accuracy: 0.6011 - val_loss: 1.2018 - val_accuracy: 0.5916\n",
      "Epoch 3/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.9228 - accuracy: 0.6752 - val_loss: 0.8760 - val_accuracy: 0.6949\n",
      "Epoch 4/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.8246 - accuracy: 0.7134 - val_loss: 0.8571 - val_accuracy: 0.6980\n",
      "Epoch 5/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.7345 - accuracy: 0.7482 - val_loss: 0.7112 - val_accuracy: 0.7583\n",
      "Epoch 6/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.6537 - accuracy: 0.7765 - val_loss: 0.8249 - val_accuracy: 0.7200\n",
      "Epoch 7/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.5961 - accuracy: 0.7974 - val_loss: 0.6224 - val_accuracy: 0.7891\n",
      "Epoch 8/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.5473 - accuracy: 0.8152 - val_loss: 0.7668 - val_accuracy: 0.7513\n",
      "Epoch 9/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.4999 - accuracy: 0.8302 - val_loss: 0.6909 - val_accuracy: 0.7745\n",
      "Epoch 10/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.4606 - accuracy: 0.8443 - val_loss: 0.6413 - val_accuracy: 0.7872\n",
      "Epoch 11/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.4210 - accuracy: 0.8563 - val_loss: 0.7237 - val_accuracy: 0.7817\n",
      "Epoch 12/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.3854 - accuracy: 0.8677 - val_loss: 0.5964 - val_accuracy: 0.8041\n",
      "Epoch 13/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.3636 - accuracy: 0.8767 - val_loss: 0.5546 - val_accuracy: 0.8163\n",
      "Epoch 14/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.3335 - accuracy: 0.8856 - val_loss: 0.5811 - val_accuracy: 0.8124\n",
      "Epoch 15/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.3121 - accuracy: 0.8922 - val_loss: 0.6093 - val_accuracy: 0.8156\n",
      "Epoch 16/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.2874 - accuracy: 0.9019 - val_loss: 0.5117 - val_accuracy: 0.8385\n",
      "Epoch 17/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.2657 - accuracy: 0.9087 - val_loss: 0.9262 - val_accuracy: 0.7605\n",
      "Epoch 18/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.2544 - accuracy: 0.9114 - val_loss: 0.6046 - val_accuracy: 0.8279\n",
      "Epoch 19/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.2417 - accuracy: 0.9160 - val_loss: 0.8248 - val_accuracy: 0.7799\n",
      "Epoch 20/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.2281 - accuracy: 0.9213 - val_loss: 0.5533 - val_accuracy: 0.8312\n",
      "Epoch 21/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.2175 - accuracy: 0.9248 - val_loss: 0.5933 - val_accuracy: 0.8301\n",
      "Epoch 22/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.2061 - accuracy: 0.9284 - val_loss: 0.6900 - val_accuracy: 0.8120\n",
      "Epoch 23/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.1909 - accuracy: 0.9346 - val_loss: 0.6459 - val_accuracy: 0.8211\n",
      "Epoch 24/30\n",
      "1329/1329 [==============================] - 28s 21ms/step - loss: 0.1877 - accuracy: 0.9342 - val_loss: 0.6849 - val_accuracy: 0.8231\n",
      "Epoch 25/30\n",
      "1329/1329 [==============================] - 29s 22ms/step - loss: 0.1758 - accuracy: 0.9407 - val_loss: 0.5750 - val_accuracy: 0.8408\n",
      "Epoch 26/30\n",
      "1329/1329 [==============================] - 30s 22ms/step - loss: 0.1716 - accuracy: 0.9420 - val_loss: 0.6570 - val_accuracy: 0.8288\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=tr_images,\n",
    "    y=tr_oh_labels,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    shuffle=True,\n",
    "    validation_data=(val_images, val_oh_labels),\n",
    "    callbacks=[mcp_cb, rlr_cb, ely_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fd31c",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50693ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7051 - accuracy: 0.8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7050707936286926, 0.8201000094413757]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0877a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 67456\r\n",
      "5892047 drwxr-xr-x  17 jamm  staff      544  8 20 13:27 \u001b[34m.\u001b[m\u001b[m\r\n",
      "5109589 drwxr-xr-x  11 jamm  staff      352  8 20 13:12 \u001b[34m..\u001b[m\u001b[m\r\n",
      "5892142 drwxr-xr-x   7 jamm  staff      224  8 20 12:14 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "5945315 -rw-r--r--   1 jamm  staff    31256  8 16 20:54 CIFAR10_CNN_Batch_Normalization_Practice.ipynb\r\n",
      "6133863 -rw-r--r--   1 jamm  staff    18498  8 20 13:27 CIFAR10_CNN_Callback_Filters_Practice.ipynb\r\n",
      "5926369 -rw-r--r--   1 jamm  staff    44970  8 16 20:54 CIFAR10_CNN_Kernel(Weights)_Initializer_Practice.ipynb\r\n",
      "5892184 -rw-r--r--   1 jamm  staff   996341  8 16 18:31 CIFAR10_CNN_Practice.ipynb\r\n",
      "6091419 -rw-r--r--   1 jamm  staff   222519  8 19 22:11 CIFAR10_CNN_Shuffle_Practice.ipynb\r\n",
      "6137864 -rw-r--r--   1 jamm  staff  3689408  8 20 13:15 weights.01-2.17.hdf5\r\n",
      "6137876 -rw-r--r--   1 jamm  staff  3689408  8 20 13:15 weights.02-1.20.hdf5\r\n",
      "6137887 -rw-r--r--   1 jamm  staff  3689408  8 20 13:16 weights.03-0.88.hdf5\r\n",
      "6137902 -rw-r--r--   1 jamm  staff  3689408  8 20 13:16 weights.04-0.86.hdf5\r\n",
      "6137907 -rw-r--r--   1 jamm  staff  3689408  8 20 13:17 weights.05-0.71.hdf5\r\n",
      "6137921 -rw-r--r--   1 jamm  staff  3689408  8 20 13:18 weights.07-0.62.hdf5\r\n",
      "6137970 -rw-r--r--   1 jamm  staff  3689408  8 20 13:20 weights.12-0.60.hdf5\r\n",
      "6138189 -rw-r--r--   1 jamm  staff  3689408  8 20 13:20 weights.13-0.55.hdf5\r\n",
      "6138432 -rw-r--r--   1 jamm  staff  3689408  8 20 13:22 weights.16-0.51.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c792e",
   "metadata": {},
   "source": [
    "### 최적 weight를 모델로 재로딩한 다음 테스트 데이터로 다시 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c82ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.load_weights(current_path + '/weights.16-0.51.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f7c7c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/313 [>.............................] - ETA: 2s - loss: 0.4846 - accuracy: 0.8486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 13:31:44.399512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.5388 - accuracy: 0.8297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5388439297676086, 0.8297000527381897]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d954954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_history(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.xticks(np.arange(0, 30, 2))\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='valid')\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18154f21",
   "metadata": {},
   "source": [
    "### Filters x 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b69f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def create_model(verbose=False):\n",
    "    \n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=512, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(300, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "    \n",
    "    output = Dense(10, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e6bf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-22 18:48:55.349844: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-08-22 18:48:55.350300: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08718e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 300)               2457900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 4,792,110\n",
      "Trainable params: 4,789,294\n",
      "Non-trainable params: 2,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a9f43",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9aa6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d9d898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamm/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2021-08-22 18:49:03.757949: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-22 18:49:03.760727: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-22 18:49:04.020931: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - ETA: 0s - loss: 1.8591 - accuracy: 0.3072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-22 18:50:22.753457: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - 83s 62ms/step - loss: 1.8591 - accuracy: 0.3072 - val_loss: 1.6300 - val_accuracy: 0.4319\n",
      "Epoch 2/32\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.4375 - accuracy: 0.4539 - val_loss: 1.3616 - val_accuracy: 0.5084\n",
      "Epoch 3/32\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 1.2257 - accuracy: 0.5529 - val_loss: 1.0155 - val_accuracy: 0.6529\n",
      "Epoch 4/32\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 1.0841 - accuracy: 0.6119 - val_loss: 0.9830 - val_accuracy: 0.6600\n",
      "Epoch 5/32\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 0.9764 - accuracy: 0.6552 - val_loss: 0.8433 - val_accuracy: 0.7188\n",
      "Epoch 6/32\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.8628 - accuracy: 0.7020 - val_loss: 0.9044 - val_accuracy: 0.7223\n",
      "Epoch 7/32\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 0.7724 - accuracy: 0.7320 - val_loss: 0.7017 - val_accuracy: 0.7713\n",
      "Epoch 8/32\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.6949 - accuracy: 0.7629 - val_loss: 0.7868 - val_accuracy: 0.7607\n",
      "Epoch 9/32\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.6002 - accuracy: 0.7990 - val_loss: 0.5605 - val_accuracy: 0.8213\n",
      "Epoch 10/32\n",
      "1329/1329 [==============================] - 82s 62ms/step - loss: 0.5008 - accuracy: 0.8375 - val_loss: 0.6434 - val_accuracy: 0.7959\n",
      "Epoch 11/32\n",
      "1329/1329 [==============================] - 83s 62ms/step - loss: 0.4135 - accuracy: 0.8652 - val_loss: 0.6566 - val_accuracy: 0.8097\n",
      "Epoch 12/32\n",
      "1329/1329 [==============================] - 85s 64ms/step - loss: 0.3582 - accuracy: 0.8840 - val_loss: 0.7393 - val_accuracy: 0.8101\n",
      "Epoch 13/32\n",
      "1329/1329 [==============================] - 85s 64ms/step - loss: 0.3077 - accuracy: 0.9017 - val_loss: 0.7203 - val_accuracy: 0.8143\n",
      "Epoch 14/32\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 0.2573 - accuracy: 0.9164 - val_loss: 0.6591 - val_accuracy: 0.8121\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 15/32\n",
      "1329/1329 [==============================] - 85s 64ms/step - loss: 0.1389 - accuracy: 0.9544 - val_loss: 0.5174 - val_accuracy: 0.8724\n",
      "Epoch 16/32\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 0.0967 - accuracy: 0.9666 - val_loss: 0.5488 - val_accuracy: 0.8739\n",
      "Epoch 17/32\n",
      "1329/1329 [==============================] - 84s 64ms/step - loss: 0.0743 - accuracy: 0.9752 - val_loss: 0.5590 - val_accuracy: 0.8777\n",
      "Epoch 18/32\n",
      "1329/1329 [==============================] - 84s 63ms/step - loss: 0.0624 - accuracy: 0.9797 - val_loss: 0.6198 - val_accuracy: 0.8715\n",
      "Epoch 19/32\n",
      "1329/1329 [==============================] - 89s 67ms/step - loss: 0.0502 - accuracy: 0.9833 - val_loss: 0.6787 - val_accuracy: 0.8696\n",
      "Epoch 20/32\n",
      "1329/1329 [==============================] - 89s 67ms/step - loss: 0.0429 - accuracy: 0.9856 - val_loss: 0.6899 - val_accuracy: 0.8755\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 21/32\n",
      "1329/1329 [==============================] - 87s 65ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.6697 - val_accuracy: 0.8799\n",
      "Epoch 22/32\n",
      "1329/1329 [==============================] - 86s 65ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.6877 - val_accuracy: 0.8820\n",
      "Epoch 23/32\n",
      "1329/1329 [==============================] - 89s 67ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.7196 - val_accuracy: 0.8800\n",
      "Epoch 24/32\n",
      "1329/1329 [==============================] - 90s 67ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.7392 - val_accuracy: 0.8804\n",
      "Epoch 25/32\n",
      "1329/1329 [==============================] - 91s 69ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.7474 - val_accuracy: 0.8817\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=tr_images,\n",
    "    y=tr_oh_labels,\n",
    "    batch_size=32,\n",
    "    epochs=32,\n",
    "    shuffle=True,\n",
    "    validation_data=(val_images, val_oh_labels),\n",
    "    callbacks=[rlr_cb, ely_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39b21d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 18ms/step - loss: 0.7890 - accuracy: 0.8740\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_labels)\n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345f26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
