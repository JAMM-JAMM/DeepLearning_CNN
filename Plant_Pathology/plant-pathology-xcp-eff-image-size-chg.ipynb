{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\npath_list = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        path_list.append(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:05.368402Z","iopub.execute_input":"2022-03-19T09:11:05.368642Z","iopub.status.idle":"2022-03-19T09:11:09.880818Z","shell.execute_reply.started":"2022-03-19T09:11:05.368571Z","shell.execute_reply":"2022-03-19T09:11:09.880072Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"path_list[4:9]","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:15.752968Z","iopub.execute_input":"2022-03-19T09:11:15.753494Z","iopub.status.idle":"2022-03-19T09:11:15.761345Z","shell.execute_reply.started":"2022-03-19T09:11:15.753454Z","shell.execute_reply":"2022-03-19T09:11:15.760603Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# import train.csv\n\ntrain_df = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:18.204338Z","iopub.execute_input":"2022-03-19T09:11:18.204909Z","iopub.status.idle":"2022-03-19T09:11:18.223631Z","shell.execute_reply.started":"2022-03-19T09:11:18.204868Z","shell.execute_reply":"2022-03-19T09:11:18.222988Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:18.746682Z","iopub.execute_input":"2022-03-19T09:11:18.747081Z","iopub.status.idle":"2022-03-19T09:11:18.764330Z","shell.execute_reply.started":"2022-03-19T09:11:18.747049Z","shell.execute_reply":"2022-03-19T09:11:18.763665Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:19.139423Z","iopub.execute_input":"2022-03-19T09:11:19.139680Z","iopub.status.idle":"2022-03-19T09:11:19.147857Z","shell.execute_reply.started":"2022-03-19T09:11:19.139650Z","shell.execute_reply":"2022-03-19T09:11:19.147086Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# import test.csv\n\ntest_df = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:19.625056Z","iopub.execute_input":"2022-03-19T09:11:19.625620Z","iopub.status.idle":"2022-03-19T09:11:19.639023Z","shell.execute_reply.started":"2022-03-19T09:11:19.625586Z","shell.execute_reply":"2022-03-19T09:11:19.638352Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:20.109846Z","iopub.execute_input":"2022-03-19T09:11:20.110314Z","iopub.status.idle":"2022-03-19T09:11:20.119873Z","shell.execute_reply.started":"2022-03-19T09:11:20.110277Z","shell.execute_reply":"2022-03-19T09:11:20.119151Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:20.473947Z","iopub.execute_input":"2022-03-19T09:11:20.474492Z","iopub.status.idle":"2022-03-19T09:11:20.480433Z","shell.execute_reply.started":"2022-03-19T09:11:20.474458Z","shell.execute_reply":"2022-03-19T09:11:20.479770Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# train_df에 sum 컬럼 추가\n# healthy, multiple_diseases, rust, scab 컬럼이 one-hot encoding 형식으로 되어있음\n# sum이 1보다 큰지, 아니면 0인지 확인\n\ntrain_df['sum'] = train_df['healthy'] + train_df['multiple_diseases'] + train_df['rust'] + train_df['scab']\n\n# train_df의 sum 컬럼의 value count\ntrain_df['sum'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:20.850445Z","iopub.execute_input":"2022-03-19T09:11:20.851120Z","iopub.status.idle":"2022-03-19T09:11:20.866750Z","shell.execute_reply.started":"2022-03-19T09:11:20.851082Z","shell.execute_reply":"2022-03-19T09:11:20.866107Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# train_df의 target value 값이 중복된 값이 있는지 체크하는 작업\ntrain_df[(train_df['sum'] > 1) | (train_df['sum'] == 0)]","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:21.238194Z","iopub.execute_input":"2022-03-19T09:11:21.238608Z","iopub.status.idle":"2022-03-19T09:11:21.256953Z","shell.execute_reply.started":"2022-03-19T09:11:21.238566Z","shell.execute_reply":"2022-03-19T09:11:21.256262Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# image의 절대 경로를 DataFrame에 추가\npd.set_option('max_colwidth', 100)\n\nIMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\ntrain_df['path'] = IMAGE_DIR + '/' + train_df['image_id'] + '.jpg'\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:21.651269Z","iopub.execute_input":"2022-03-19T09:11:21.651529Z","iopub.status.idle":"2022-03-19T09:11:21.666201Z","shell.execute_reply.started":"2022-03-19T09:11:21.651499Z","shell.execute_reply":"2022-03-19T09:11:21.665435Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# 개별 컬럼 별 0/1 값을 구분하여 클래스 라벨로 생성\n# 이미지의 label을 DataFrame에 추가\n\ndef get_label(x):\n    if x['healthy'] == 1:\n        return 'healthy'\n    elif x['multiple_diseases'] == 1:\n        return 'multiple_diseases'\n    elif x['scab'] == 1:\n        return 'scab'\n    elif x['rust'] == 1:\n        return 'rust'\n    else:\n        return 'None'\n\ntrain_df['label'] = train_df.apply(\n    lambda x: get_label(x), axis=1\n)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:22.162694Z","iopub.execute_input":"2022-03-19T09:11:22.163249Z","iopub.status.idle":"2022-03-19T09:11:22.220593Z","shell.execute_reply.started":"2022-03-19T09:11:22.163213Z","shell.execute_reply":"2022-03-19T09:11:22.219746Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# 학습 이미지 건수 및 label 별 건수 확인\nprint('train df shape: ', train_df.shape)\nprint()\nprint('label 별 건수')\ntrain_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:22.735959Z","iopub.execute_input":"2022-03-19T09:11:22.736416Z","iopub.status.idle":"2022-03-19T09:11:22.745537Z","shell.execute_reply.started":"2022-03-19T09:11:22.736377Z","shell.execute_reply":"2022-03-19T09:11:22.744818Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# 원본 이미지 시각화 function\n\n# 녹병균(rust), 박테리아성 질환(scab), 복합 질병(multiple_diseases), 건강(healthy)\n# 이미지 size는 (1365, 2048)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\n\n\ndef show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n    '''\n    :parameters:\n    \n    image_path_list: image path가 담겨있는 list\n    augmentor: Augmentation 유무\n    ncols: label 별 시각화 할 image 개수\n    title: title 유무\n    '''\n    figure, axs = plt.subplots(\n        figsize=(22, 4),\n        nrows=1,\n        ncols=ncols\n    )\n    \n    for i in range(ncols):\n        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n        if augmentor is not None:\n            image = augmentor(image=image)['image']\n        axs[i].imshow(image)\n        axs[i].set_title(title)\n        print(f\"{title}: {image.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:23.301814Z","iopub.execute_input":"2022-03-19T09:11:23.302327Z","iopub.status.idle":"2022-03-19T09:11:24.431545Z","shell.execute_reply.started":"2022-03-19T09:11:23.302285Z","shell.execute_reply":"2022-03-19T09:11:24.430790Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# label 별 image path list \nrust_image_list = train_df[train_df['label'] == 'rust']['path'].iloc[:6].tolist()\nscab_image_list = train_df[train_df['label'] == 'scab']['path'].iloc[:6].tolist()\nhealthy_image_list = train_df[train_df['label'] == 'healthy']['path'].iloc[:6].tolist()\nmultiple_image_list = train_df[train_df['label'] == 'multiple_diseases']['path'].iloc[:6].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:24.433163Z","iopub.execute_input":"2022-03-19T09:11:24.433400Z","iopub.status.idle":"2022-03-19T09:11:24.445623Z","shell.execute_reply.started":"2022-03-19T09:11:24.433365Z","shell.execute_reply":"2022-03-19T09:11:24.444929Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# label 별 image visualize\nshow_grid_images(rust_image_list, ncols=6, title='rust')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:24.765326Z","iopub.execute_input":"2022-03-19T09:11:24.765861Z","iopub.status.idle":"2022-03-19T09:11:27.769783Z","shell.execute_reply.started":"2022-03-19T09:11:24.765822Z","shell.execute_reply":"2022-03-19T09:11:27.769013Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"show_grid_images(scab_image_list, ncols=6, title='scab')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:27.771542Z","iopub.execute_input":"2022-03-19T09:11:27.771810Z","iopub.status.idle":"2022-03-19T09:11:30.742503Z","shell.execute_reply.started":"2022-03-19T09:11:27.771776Z","shell.execute_reply":"2022-03-19T09:11:30.741681Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"show_grid_images(healthy_image_list, ncols=6, title='healthy')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:30.744009Z","iopub.execute_input":"2022-03-19T09:11:30.744259Z","iopub.status.idle":"2022-03-19T09:11:34.110147Z","shell.execute_reply.started":"2022-03-19T09:11:30.744226Z","shell.execute_reply":"2022-03-19T09:11:34.109547Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"show_grid_images(multiple_image_list, ncols=6, title='multiple_diseases')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:34.111865Z","iopub.execute_input":"2022-03-19T09:11:34.112543Z","iopub.status.idle":"2022-03-19T09:11:37.085818Z","shell.execute_reply.started":"2022-03-19T09:11:34.112502Z","shell.execute_reply":"2022-03-19T09:11:37.085194Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Image Augmentation\n\nimport albumentations as A\n\n\naugmentor_01 = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n    A.Blur(p=0.2)\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:37.086882Z","iopub.execute_input":"2022-03-19T09:11:37.087663Z","iopub.status.idle":"2022-03-19T09:11:37.975611Z","shell.execute_reply.started":"2022-03-19T09:11:37.087624Z","shell.execute_reply":"2022-03-19T09:11:37.974812Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Apply Augmentation(augmentor_01) to image visualize\n\n# rust\nshow_grid_images(rust_image_list, augmentor=None, ncols=6, title='original rust')\nshow_grid_images(rust_image_list, augmentor=augmentor_01, ncols=6, title='augmented rust')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:37.978751Z","iopub.execute_input":"2022-03-19T09:11:37.979240Z","iopub.status.idle":"2022-03-19T09:11:44.866318Z","shell.execute_reply.started":"2022-03-19T09:11:37.979190Z","shell.execute_reply":"2022-03-19T09:11:44.865560Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Apply Augmentation(augmentor_01) to image visualize\n\n# scab\nshow_grid_images(scab_image_list, augmentor=None, ncols=6, title='original scab')\nshow_grid_images(scab_image_list, augmentor=augmentor_01, ncols=6, title='augmented scab')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:11:44.867714Z","iopub.execute_input":"2022-03-19T09:11:44.868158Z","iopub.status.idle":"2022-03-19T09:11:50.793852Z","shell.execute_reply.started":"2022-03-19T09:11:44.868122Z","shell.execute_reply":"2022-03-19T09:11:50.793030Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Sequence 기반의 Dataset 생성\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import Sequence\nimport sklearn\nimport cv2\n\n\nclass Plant_Dataset(Sequence):\n    '''\n        :parameters\n        image_filenames: opencv로 image를 로드할 파일의 절대 경로\n        labels: 해당 image의 label\n        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n        augmentor: albumentations 객체\n        shuffle: 학습 데이터의 경우 epoch 종료 시 마다 데이터를 섞을 지 여부\n    '''\n    def __init__(self, image_filenames, labels, image_size=(224, 224),\n                batch_size=64, augmentor=None, shuffle=False, pre_func=None):\n        \n        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당한다.\n        self.image_filenames = image_filenames\n        self.labels = labels\n        self.image_size = image_size\n        self.batch_size = batch_size\n        self.augmentor = augmentor\n        self.pre_func = pre_func\n        self.shuffle = shuffle\n        \n        # train_data의 경우, 객체 생성 시 한번 데이터를 shuffle\n        if self.shuffle:\n            # self.on_epoch_end()\n            pass\n    \n    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함\n    \n    # __len__()은 전체 데이터 건수가 주어졌을 때, batch_size 단위로 몇 번 데이터를 반환하는지\n    def __len__(self):\n        # batch_size 단위로 데이터를 몇 번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나눈다.\n        # 정수로 정확히 나누어지지 않을 경우, 1회를 더한다.\n        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n    \n    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함.\n    # 인자로 몇 번째 batch 인지 나타내는 index를 입력하면 해당 순서의 batch_size 만큼의 데이터를 가공하여 반환\n    def __getitem__(self, index):\n        '''\n        :parameters\n        index: 몇 번째 batch 인지 나타냄\n        \n        :return: batch_size 개수 만큼의 image_array와 label_array\n        '''\n        \n        # batch_size 만큼 순차적으로 데이터를 가져오기 위해서\n        # 1 index: array[index*self.batch_size:(index+1)*self.batch_size]\n        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n        \n        if self.labels is not None:\n            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n        \n        # label_batch가 None이 될 수 있음\n        else:\n            label_batch = None\n        \n        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면\n        # 아래와 같이 augmentor를 이용하여 image 변환\n        # image_batch 배열은 float32로 설정\n        image_batch = np.zeros(\n            (image_name_batch.shape[0], self.image_size[0], self.image_size[1], 3),\n            dtype='float32'\n        )\n        \n        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load\n        # -> image augmentation 반환 (augmentor가 not None일 경우)\n        # -> image_batch에 담음\n        for image_index in range(image_name_batch.shape[0]):\n            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n            if self.augmentor is not None:\n                image = self.augmentor(image=image)['image']\n            \n            # 원본 이미지와 다르게 resize 적용\n            # array: (너비, 높이)\n            # opencv: (높이, 너비)\n            image = cv2.resize(image, (self.image_size[1], self.image_size[0]))\n            \n            # 만일 preprocessing_input이 pre_func 인자로 들어오면, 이를 이용하여 scailing 적용\n            if self.pre_func is not None:\n                image = self.pre_func(image)\n            \n            image_batch[image_index] = image\n        \n        return image_batch, label_batch\n    \n    # epoch가 한 번 수행이 완료될 때, 모델의 fit()에서 호출\n    def on_epoch_end(self):\n        if (self.shuffle):\n            # 전체 image 파일의 위치와 label의 쌍을 맞춰서 섞는다.\n            # sklearn의 utils.shuffle에서 해당 기능 제공\n            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n        else:\n            pass","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:17:09.077626Z","iopub.execute_input":"2022-03-19T09:17:09.078066Z","iopub.status.idle":"2022-03-19T09:17:09.093385Z","shell.execute_reply.started":"2022-03-19T09:17:09.078028Z","shell.execute_reply":"2022-03-19T09:17:09.092639Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# 학습 데이터용 DataFrame에서 train/validation image path와 Label을 추출하고 이를 Dataset으로 생성\n\n# 이미 학습용 DataFrame에 'healthy', 'multiple_diseases', 'rust', 'scab' 순으로 one-hot encoding 되어있음\n# kaggle에서 test data의 예측 결과를 'healthy', 'multiple_diseases', 'rust', 'scab' 순서로 제출을 요구함\n# 따라서, 이를 다시 별도로 one-hot encoding 해서는 안됨.\n# Augmentation은 앞에서 생성한 augmentor_01 적용\n# pre_func는 xception용 Preprocessing 함수를 적용","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:17:09.407484Z","iopub.execute_input":"2022-03-19T09:17:09.407713Z","iopub.status.idle":"2022-03-19T09:17:09.412312Z","shell.execute_reply.started":"2022-03-19T09:17:09.407685Z","shell.execute_reply":"2022-03-19T09:17:09.411451Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\nsample_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:17:09.875438Z","iopub.execute_input":"2022-03-19T09:17:09.875688Z","iopub.status.idle":"2022-03-19T09:17:09.896405Z","shell.execute_reply.started":"2022-03-19T09:17:09.875659Z","shell.execute_reply":"2022-03-19T09:17:09.895771Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_df.columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:17:11.497312Z","iopub.execute_input":"2022-03-19T09:17:11.497848Z","iopub.status.idle":"2022-03-19T09:17:11.503824Z","shell.execute_reply.started":"2022-03-19T09:17:11.497809Z","shell.execute_reply":"2022-03-19T09:17:11.503058Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"train_df['path'].values","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:17:11.942418Z","iopub.execute_input":"2022-03-19T09:17:11.942844Z","iopub.status.idle":"2022-03-19T09:17:11.948657Z","shell.execute_reply.started":"2022-03-19T09:17:11.942807Z","shell.execute_reply":"2022-03-19T09:17:11.947882Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# train/validation set split\nfrom sklearn.model_selection import train_test_split\n\n\ndef get_train_valid(train_df, valid_size=0.2, random_state=2021):\n    \n    # array type\n    train_path = train_df['path'].values\n    \n    # 별도의 one-hot encoding을 하지 않고, \n    # 'healthy', 'multiple_diseases', 'rust', 'scab' 컬럼들을 모두 \n    # Numpy array로 변환하는 수준으로 label에 one-hot encoding 적용\n    train_label = train_df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n    \n    tr_path, val_path, tr_label, val_label = train_test_split(\n                                                train_path,\n                                                train_label,\n                                                test_size=valid_size,\n                                                random_state=random_state\n                                            )\n    \n    print(\"tr_path shape: \", tr_path.shape)\n    print(\"tr_label shape: \", tr_label.shape)\n    print(\"val_path shape: \", val_path.shape)\n    print(\"val_label shape: \", val_label.shape)\n    \n    return tr_path, val_path, tr_label, val_label","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:17:14.060752Z","iopub.execute_input":"2022-03-19T09:17:14.061155Z","iopub.status.idle":"2022-03-19T09:17:14.071670Z","shell.execute_reply.started":"2022-03-19T09:17:14.061113Z","shell.execute_reply":"2022-03-19T09:17:14.070212Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n\n\n# image size는 224 x 224로 Dataset 생성\nIMAGE_SIZE = (320, 512)\nBATCH_SIZE = 64\n\ntr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:17:26.271452Z","iopub.execute_input":"2022-03-19T09:17:26.271707Z","iopub.status.idle":"2022-03-19T09:17:26.281396Z","shell.execute_reply.started":"2022-03-19T09:17:26.271678Z","shell.execute_reply":"2022-03-19T09:17:26.280650Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"print(Plant_Dataset.__doc__)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:17:28.589021Z","iopub.execute_input":"2022-03-19T09:17:28.591122Z","iopub.status.idle":"2022-03-19T09:17:28.596233Z","shell.execute_reply.started":"2022-03-19T09:17:28.591082Z","shell.execute_reply":"2022-03-19T09:17:28.595418Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"tr_ds = Plant_Dataset(\n    tr_path,\n    tr_label,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    augmentor=augmentor_01,\n    shuffle=True,\n    pre_func=xcp_preprocess_input\n)\n\nval_ds = Plant_Dataset(\n    val_path,\n    val_label,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    augmentor=None,\n    shuffle=False,\n    pre_func=xcp_preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:35:25.407127Z","iopub.execute_input":"2022-03-19T09:35:25.407377Z","iopub.status.idle":"2022-03-19T09:35:25.413018Z","shell.execute_reply.started":"2022-03-19T09:35:25.407349Z","shell.execute_reply":"2022-03-19T09:35:25.411614Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"print(dir(tr_ds))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:35:25.748772Z","iopub.execute_input":"2022-03-19T09:35:25.749417Z","iopub.status.idle":"2022-03-19T09:35:25.753971Z","shell.execute_reply.started":"2022-03-19T09:35:25.749381Z","shell.execute_reply":"2022-03-19T09:35:25.753192Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"for k, v in tr_ds.__dict__.items():\n    print(f\"{k}\")\n    print(f\"{v}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:35:26.123476Z","iopub.execute_input":"2022-03-19T09:35:26.124056Z","iopub.status.idle":"2022-03-19T09:35:26.133237Z","shell.execute_reply.started":"2022-03-19T09:35:26.124022Z","shell.execute_reply":"2022-03-19T09:35:26.132405Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"print(dir(val_ds))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:35:26.475467Z","iopub.execute_input":"2022-03-19T09:35:26.475813Z","iopub.status.idle":"2022-03-19T09:35:26.480183Z","shell.execute_reply.started":"2022-03-19T09:35:26.475784Z","shell.execute_reply":"2022-03-19T09:35:26.479523Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"for k, v in val_ds.__dict__.items():\n    print(f\"{k}\")\n    print(f\"{v}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:35:27.267309Z","iopub.execute_input":"2022-03-19T09:35:27.267832Z","iopub.status.idle":"2022-03-19T09:35:27.277943Z","shell.execute_reply.started":"2022-03-19T09:35:27.267797Z","shell.execute_reply":"2022-03-19T09:35:27.277229Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"if hasattr(tr_ds, '__iter__'):\n    tr_image_batch, tr_label_batch = next(iter(tr_ds))\n\nif hasattr(val_ds, '__iter__'):\n    val_image_batch, val_label_batch = next(iter(val_ds))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:35:46.133289Z","iopub.execute_input":"2022-03-19T09:35:46.133671Z","iopub.status.idle":"2022-03-19T09:35:51.122954Z","shell.execute_reply.started":"2022-03-19T09:35:46.133638Z","shell.execute_reply":"2022-03-19T09:35:51.122083Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"print(\"train_image_batch shape: \", tr_image_batch.shape)\nprint(\"val_image_batch shape: \", val_image_batch.shape)\nprint(\"tr_label_batch shape: \", tr_label_batch.shape)\nprint(\"val_label_batch shape: \", val_label_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:35:51.124421Z","iopub.execute_input":"2022-03-19T09:35:51.124657Z","iopub.status.idle":"2022-03-19T09:35:51.133933Z","shell.execute_reply.started":"2022-03-19T09:35:51.124622Z","shell.execute_reply":"2022-03-19T09:35:51.133065Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# Model Create\n\n# resnet50v2\n# xception\n# efficientnetb0-b7\n\nfrom tensorflow.keras.models import Sequential , Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\nfrom tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\nfrom tensorflow.keras.applications import EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\nimport tensorflow as tf\n\ndef create_model(model_type='efficientnetb0', in_shape=(224, 224, 3), n_classes=4):\n    input_tensor = Input(shape=in_shape)\n    \n    if model_type == 'resnet50v2':\n        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'xception':\n        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb0':\n        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb1':\n        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb2':\n        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb3':\n        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb4':\n        base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb5':\n        base_model = tf.keras.applications.EfficientNetB5(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb6':\n        base_model = tf.keras.applications.EfficientNetB6(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb7':\n        base_model = tf.keras.applications.EfficientNetB7(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    preds = Dense(units=n_classes, activation='softmax')(x)\n    model = Model(inputs=input_tensor, outputs=preds)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-19T10:06:31.019849Z","iopub.execute_input":"2022-03-19T10:06:31.020286Z","iopub.status.idle":"2022-03-19T10:06:31.039446Z","shell.execute_reply.started":"2022-03-19T10:06:31.020250Z","shell.execute_reply":"2022-03-19T10:06:31.038727Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# Learning Rate Scheduler에 적용할 함수 선언\n\ndef lrfn_01(epoch):\n    lr_start = 1e-5\n    lr_max = 1e-4\n    lr_rampup_epochs = 2\n    lr_sustain_epochs = 1\n    lr_step_decay = 0.75\n    \n    def calc_fn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = lr_max * lr_step_decay**((epoch - lr_rampup_epochs - lr_sustain_epochs)//2)\n        return lr\n    \n    return calc_fn(epoch)\n\ndef lrfn_02(epoch):\n    lr_start = 1e-6\n    lr_max = 2e-5\n    lr_rampup_epochs = 2\n    lr_sustain_epochs = 1\n    lr_step_decay = 0.75\n    \n    def calc_fn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = lr_max * lr_step_decay**((epoch - lr_rampup_epochs - lr_sustain_epochs)//2)\n        return lr\n    \n    return calc_fn(epoch)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:45:05.679128Z","iopub.execute_input":"2022-03-19T09:45:05.679573Z","iopub.status.idle":"2022-03-19T09:45:05.687806Z","shell.execute_reply.started":"2022-03-19T09:45:05.679533Z","shell.execute_reply":"2022-03-19T09:45:05.687133Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"# Callbacks - LearningRateScheduler\nimport tensorflow as tf\n\n\nlr01_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_01, verbose=1)\nlr02_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_02, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:57:31.327474Z","iopub.execute_input":"2022-03-19T09:57:31.327726Z","iopub.status.idle":"2022-03-19T09:57:31.333132Z","shell.execute_reply.started":"2022-03-19T09:57:31.327698Z","shell.execute_reply":"2022-03-19T09:57:31.332424Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# Callbacks - ReduceLROnPlateau\n\nrlr_cb = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,\n    patience=3,\n    mode='min',\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:58:36.707468Z","iopub.execute_input":"2022-03-19T09:58:36.707724Z","iopub.status.idle":"2022-03-19T09:58:36.712209Z","shell.execute_reply.started":"2022-03-19T09:58:36.707694Z","shell.execute_reply":"2022-03-19T09:58:36.711525Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# Callbacks - EarlyStopping\n\nely_cb = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    mode='min',\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T09:59:21.438035Z","iopub.execute_input":"2022-03-19T09:59:21.438846Z","iopub.status.idle":"2022-03-19T09:59:21.442912Z","shell.execute_reply.started":"2022-03-19T09:59:21.438797Z","shell.execute_reply":"2022-03-19T09:59:21.442233Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"## Xception","metadata":{}},{"cell_type":"code","source":"# Config를 이용하여 학습 수행\n\n# - Model: Xception\n# - Image Size: (320, 512)\n# - Batch Size: 32\n# - Initial Value of LR: 0.0001\n# - LR Scheduler: Ramp up and Step decay\n# - epochs = 10\n# - not fine tuning\n# - augmentor -> augmentor_01\n\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\nfrom tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n\n\nclass Config:\n    model_type = 'xception'\n    image_size = (320, 512)\n    batch_size = 32\n    n_epochs = 10\n    is_fine_tuning = False\n    first_epochs = 15\n    second_epochs = 15\n    first_callbacks = [lr01_cb, ely_cb]\n    second_callbacks = [lr02_cb, ely_cb]\n    augmentor = augmentor_01\n    pre_func = xcp_preprocess_input\n    initial_lr = 0.0001\n    debug = True","metadata":{"execution":{"iopub.status.busy":"2022-03-19T10:03:51.012372Z","iopub.execute_input":"2022-03-19T10:03:51.012641Z","iopub.status.idle":"2022-03-19T10:03:51.020233Z","shell.execute_reply.started":"2022-03-19T10:03:51.012613Z","shell.execute_reply":"2022-03-19T10:03:51.019410Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":"## EfficientNetB3","metadata":{}},{"cell_type":"code","source":"# Config를 이용하여 학습 수행\n\n# - Model: EfficientNetB3\n# - Image Size: (320, 512)\n# - Batch Size: 16\n# - Initial Value of LR: 0.0001\n# - LR Scheduler: Ramp up and Step decay\n# - epochs = 10\n# - not fine tuning\n# - augmentor -> augmentor_01\n\nclass Config:\n    model_type = 'efficientnetb3'\n    image_size = (320, 512)\n    batch_size = 16 # OOM Issue\n    n_epochs = 10\n    is_fine_tuning = False\n    first_epochs = 15\n    second_epochs = 15\n    first_callbacks = [lr01_cb, ely_cb]\n    second_callbacks = [lr02_cb, ely_cb]\n    augmentor = augmentor_01\n    pre_func = eff_preprocess_input\n    initial_lr = 0.0001\n    debug = True","metadata":{"execution":{"iopub.status.busy":"2022-03-19T11:48:42.467545Z","iopub.execute_input":"2022-03-19T11:48:42.468157Z","iopub.status.idle":"2022-03-19T11:48:42.473345Z","shell.execute_reply.started":"2022-03-19T11:48:42.468119Z","shell.execute_reply":"2022-03-19T11:48:42.472688Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"## EfficientNet B5","metadata":{}},{"cell_type":"code","source":"# Config를 이용하여 학습 수행\n\n# - Model: EfficientNetB5\n# - Image Size: (456, 456)\n# - Batch Size: 8\n# - Initial Value of LR: 0.0001\n# - LR Scheduler: Ramp up and Step decay\n# - epochs = 10\n# - not fine tuning\n# - augmentor -> augmentor_01\n\nclass Config:\n    model_type = 'efficientnetb3'\n    image_size = (456, 456)\n    batch_size = 8 # OOM Issue\n    n_epochs = 10\n    is_fine_tuning = False\n    first_epochs = 15\n    second_epochs = 15\n    first_callbacks = [lr01_cb, ely_cb]\n    second_callbacks = [lr02_cb, ely_cb]\n    augmentor = augmentor_01\n    pre_func = eff_preprocess_input\n    initial_lr = 0.0001\n    debug = True","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:17:06.372184Z","iopub.execute_input":"2022-03-19T12:17:06.372438Z","iopub.status.idle":"2022-03-19T12:17:06.377628Z","shell.execute_reply.started":"2022-03-19T12:17:06.372409Z","shell.execute_reply":"2022-03-19T12:17:06.376952Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":"## EfficientNet B7","metadata":{}},{"cell_type":"code","source":"# Config를 이용하여 학습 수행\n\n# - Model: EfficientNetB7\n# - Image Size: (456, 456)\n# - Batch Size: 4\n# - Initial Value of LR: 0.0001\n# - LR Scheduler: Ramp up and Step decay\n# - epochs = 15\n# - not fine tuning\n# - augmentor -> augmentor_01\n\nclass Config:\n    model_type = 'efficientnetb3'\n    image_size = (456, 456)\n    batch_size = 4 # OOM Issue\n    n_epochs = 15\n    is_fine_tuning = False\n    first_epochs = 15\n    second_epochs = 15\n    first_callbacks = [lr01_cb, ely_cb]\n    second_callbacks = [lr02_cb, ely_cb]\n    augmentor = augmentor_01\n    pre_func = eff_preprocess_input\n    initial_lr = 0.0001\n    debug = True","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:42:16.376553Z","iopub.execute_input":"2022-03-19T12:42:16.376837Z","iopub.status.idle":"2022-03-19T12:42:16.383303Z","shell.execute_reply.started":"2022-03-19T12:42:16.376806Z","shell.execute_reply":"2022-03-19T12:42:16.382554Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"# Model Train\nfrom tensorflow.keras.metrics import AUC\n\n\ndef train_model(train_df, config=Config):\n    \n    # Train & Validation Split\n    tr_path, val_path, tr_label, val_label = \\\n    get_train_valid(train_df, valid_size=0.2, random_state=2021)\n    \n    # Create Dataset based on Sequence\n    tr_ds = Plant_Dataset(\n        tr_path,\n        tr_label,\n        image_size=config.image_size,\n        batch_size=config.batch_size,\n        augmentor=config.augmentor,\n        shuffle=True,\n        pre_func=config.pre_func\n    )\n    \n    val_ds = Plant_Dataset(\n        val_path,\n        val_label,\n        image_size=config.image_size,\n        batch_size=config.batch_size,\n        augmentor=None,\n        shuffle=False,\n        pre_func=config.pre_func\n    )\n    \n    print()\n    # Debugging for prepared dataset based on sequence\n    if config.debug:\n        print('####################Debugging for prepared dataset based on sequence####################')\n        if hasattr(tr_ds, '__iter__'):\n            tr_image_batch = next(iter(tr_ds))[0]\n            print(\"train image batch shape: \", tr_image_batch.shape)\n        if hasattr(val_ds, '__iter__'):\n            val_image_batch = next(iter(val_ds))[0]\n            print(\"validation image batch shape: \", val_image_batch.shape)\n    \n    print()\n    # Create Model\n    # - Optimizer: Adam\n    print(f'####################{config.model_type}####################')\n    model = create_model(\n        model_type=config.model_type,\n        in_shape=(config.image_size[0], config.image_size[1], 3),\n        n_classes=4\n    )\n    print('####################Optimizer: Adam####################')\n    model.compile(\n        optimizer=Adam(lr=config.initial_lr),\n        loss='categorical_crossentropy',\n        metrics=[AUC()]\n    )\n    \n    print()\n    # Fine Tuning\n    if config.is_fine_tuning:\n        print('####################Fine Tuning Train Start!####################')\n        \n        # First Fine Tuning\n        for layer in model.layers[:-4]:\n            layer.trainable = False # Feature Extractor Layer=False\n            \n        print('####################First Fine Tuning - Training Classification Layer####################')\n        history = model.fit(\n            tr_ds,\n            epochs=config.first_epochs,\n            steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.batch_size)),\n            validation_data=val_ds,\n            validation_steps=int(np.ceil(val_path.shape[0]/config.batch_size)),\n            callbacks=config.first_callbacks,\n            verbose=1\n        )\n        \n        # Second Fine Tuning\n        for layer in model.layers:\n            if config.model_type in 'efficientnet':\n                if not isinstance(layer, layers.BatchNormalization):\n                    layer.trainable=True\n            else:\n                layer.trainable=True\n        \n        print('####################Second Fine Tuning - Training All Layers####################')\n        history = model.fit(\n            tr_ds,\n            epochs=config.second_epochs,\n            steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.batch_size)),\n            validation_data=val_ds,\n            validation_steps=int(np.ceil(val_path.shape[0]/config.batch_size)),\n            callbacks=config.second_callbacks,\n            verbose=1\n        )\n    \n    # Not Fine Tuning\n    else:\n        print('####################Training Start - Not Fine Tuning####################')\n        history = model.fit(\n            tr_ds,\n            epochs=config.n_epochs,\n            steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.batch_size)),\n            validation_data=val_ds,\n            validation_steps=int(np.ceil(val_path.shape[0]/config.batch_size)),\n            callbacks=config.first_callbacks,\n            verbose=1\n        )\n    \n    return model, history        ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:42:17.063501Z","iopub.execute_input":"2022-03-19T12:42:17.063824Z","iopub.status.idle":"2022-03-19T12:42:17.081540Z","shell.execute_reply.started":"2022-03-19T12:42:17.063779Z","shell.execute_reply":"2022-03-19T12:42:17.080624Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"# xcp_model_02, history = train_model(train_df, config=Config)\neffb7_model, history = train_model(train_df, config=Config)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:42:22.562433Z","iopub.execute_input":"2022-03-19T12:42:22.562683Z","iopub.status.idle":"2022-03-19T13:14:37.150270Z","shell.execute_reply.started":"2022-03-19T12:42:22.562653Z","shell.execute_reply":"2022-03-19T13:14:37.149497Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"# Create Test Dataset\n\nIMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\n\ntest_df['path'] = IMAGE_DIR + \"/\" + test_df['image_id'] + '.jpg'\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:14:37.153696Z","iopub.execute_input":"2022-03-19T13:14:37.153920Z","iopub.status.idle":"2022-03-19T13:14:37.165786Z","shell.execute_reply.started":"2022-03-19T13:14:37.153891Z","shell.execute_reply":"2022-03-19T13:14:37.165059Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:14:37.167281Z","iopub.execute_input":"2022-03-19T13:14:37.167999Z","iopub.status.idle":"2022-03-19T13:14:37.182798Z","shell.execute_reply.started":"2022-03-19T13:14:37.167954Z","shell.execute_reply":"2022-03-19T13:14:37.181949Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"# Make submit file\n\ndef make_submit_df(test_df, model, config=Config):\n    test_path = test_df['path'].values\n    \n    # Test Dataset: Labels are None\n    test_ds = Plant_Dataset(\n        image_filenames=test_path,\n        labels=None,\n        image_size=config.image_size,\n        batch_size=config.batch_size,\n        augmentor=None,\n        shuffle=False,\n        pre_func=config.pre_func\n    )\n    \n    # Predict\n    preds = model.predict(test_ds)\n    \n    # Make submit dataframe format\n    preds_df = pd.DataFrame(preds)\n    preds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n    \n    submit_df = pd.concat([test_df['image_id'], preds_df], axis=1)\n    \n    return submit_df","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:26:13.925124Z","iopub.execute_input":"2022-03-19T13:26:13.925610Z","iopub.status.idle":"2022-03-19T13:26:13.933166Z","shell.execute_reply.started":"2022-03-19T13:26:13.925569Z","shell.execute_reply":"2022-03-19T13:26:13.932406Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"submit_df = make_submit_df(test_df, effb7_model, config=Config)\n\nsubmit_df.to_csv('submit_eff_b7.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:26:14.936327Z","iopub.execute_input":"2022-03-19T13:26:14.937063Z","iopub.status.idle":"2022-03-19T13:27:24.177294Z","shell.execute_reply.started":"2022-03-19T13:26:14.937015Z","shell.execute_reply":"2022-03-19T13:27:24.176572Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}