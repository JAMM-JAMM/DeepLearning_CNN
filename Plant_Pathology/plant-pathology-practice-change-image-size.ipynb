{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# /kaggle/input/plant-pathology-2020-fgvc7/images/Test_1743.jpg\n# /kaggle/input/plant-pathology-2020-fgvc7/images/Train_1524.jpg","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:39:37.853004Z","iopub.execute_input":"2022-03-15T11:39:37.853465Z","iopub.status.idle":"2022-03-15T11:39:38.704807Z","shell.execute_reply.started":"2022-03-15T11:39:37.853429Z","shell.execute_reply":"2022-03-15T11:39:38.704287Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\n\ntest_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\ntrain_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:39:46.977199Z","iopub.execute_input":"2022-03-15T11:39:46.977807Z","iopub.status.idle":"2022-03-15T11:39:46.995116Z","shell.execute_reply.started":"2022-03-15T11:39:46.977770Z","shell.execute_reply":"2022-03-15T11:39:46.994471Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:39:48.559419Z","iopub.execute_input":"2022-03-15T11:39:48.559857Z","iopub.status.idle":"2022-03-15T11:39:48.575419Z","shell.execute_reply.started":"2022-03-15T11:39:48.559820Z","shell.execute_reply":"2022-03-15T11:39:48.574553Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# healthy, multiple_diseases, rust, scab 컬럼이 one-hot encoding 형식으로 되어있음\n# 검증: healthy, multiple_diseases, rust, scab 컬럼을 합해서 sum을 만들고\n# sum이 1보다 큰지, 아니면 0인지 확인\n\ntrain_df['sum'] = train_df['healthy'] + train_df['multiple_diseases'] + train_df['rust'] + train_df['scab']\ntrain_df[(train_df['sum'] > 1) | (train_df['sum'] == 0)]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:39:49.950745Z","iopub.execute_input":"2022-03-15T11:39:49.951316Z","iopub.status.idle":"2022-03-15T11:39:49.968480Z","shell.execute_reply.started":"2022-03-15T11:39:49.951274Z","shell.execute_reply":"2022-03-15T11:39:49.967742Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# 이미지의 절대 경로를 DataFrame에 추가하고, 개별 컬럼 별 0/1 값을 구분하여 클래스 라벨로 생성\n\npd.set_option('max_colwidth', 100)\n\nIMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\ntrain_df['path'] = IMAGE_DIR + '/' + train_df['image_id'] + '.jpg'\n\ntrain_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:39:51.356084Z","iopub.execute_input":"2022-03-15T11:39:51.356618Z","iopub.status.idle":"2022-03-15T11:39:51.377384Z","shell.execute_reply.started":"2022-03-15T11:39:51.356569Z","shell.execute_reply":"2022-03-15T11:39:51.376566Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# 이미지의 label을 DataFrame에 추가\n\ndef get_label(x):\n    if x['healthy'] == 1:\n        return 'healthy'\n    elif x['multiple_diseases'] == 1:\n        return 'multiple_diseases'\n    elif x['scab'] == 1:\n        return 'scab'\n    elif x['rust'] == 1:\n        return 'rust'\n    else:\n        return 'None'\n\ntrain_df['label'] = train_df.apply(lambda x: get_label(x), axis=1)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:39:52.738211Z","iopub.execute_input":"2022-03-15T11:39:52.738489Z","iopub.status.idle":"2022-03-15T11:39:52.793126Z","shell.execute_reply.started":"2022-03-15T11:39:52.738457Z","shell.execute_reply":"2022-03-15T11:39:52.792398Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# 학습 이미지 건수 및 label 별 건수 확인\nprint('train shape: ', train_df.shape)\nprint()\nprint('label 별 건수')\ntrain_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:39:54.107243Z","iopub.execute_input":"2022-03-15T11:39:54.107793Z","iopub.status.idle":"2022-03-15T11:39:54.120304Z","shell.execute_reply.started":"2022-03-15T11:39:54.107755Z","shell.execute_reply":"2022-03-15T11:39:54.119113Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# 원본 이미지 시각화\n\n# 녹병균(Rust), 박테리아성 질환(scab), 복합질병(multiple_diseases), 건강(healthy)\n# 이미지 size는 (1365, 2048)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\n\ndef show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n    for i in range(ncols):\n        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n        if augmentor is not None:\n            image = augmentor(image=image)['image']\n        axs[i].imshow(image)\n        axs[i].set_title(title)\n        print(image.shape)\n\nrust_image_list = train_df[train_df['label'] == 'rust']['path'].iloc[:6].tolist()\nscab_image_list = train_df[train_df['label'] == 'scab']['path'].iloc[:6].tolist()\nhealthy_image_list = train_df[train_df['label'] == 'healthy']['path'].iloc[:6].tolist()\nmultiple_image_list = train_df[train_df['label'] == 'multiple_diseases']['path'].iloc[:6].tolist()\n\nshow_grid_images(rust_image_list, ncols=6, title='rust')\nshow_grid_images(scab_image_list, ncols=6, title='scab')\nshow_grid_images(healthy_image_list, ncols=6, title='healthy')\nshow_grid_images(multiple_image_list, ncols=6, title='multiple')","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:39:57.263570Z","iopub.execute_input":"2022-03-15T11:39:57.264103Z","iopub.status.idle":"2022-03-15T11:40:09.268804Z","shell.execute_reply.started":"2022-03-15T11:39:57.264066Z","shell.execute_reply":"2022-03-15T11:40:09.267927Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# 이미지 Augmentation 적용\n\n# cutout과 같은 noise는 나뭇잎의 병균 반점과 헷갈릴 수 있으므로 사용하지 않음\n# 전체 이미지가 초록색 계열이고 병균 반점이 특정 색깔을 가지고 있으므로, 색상의 변화는 적용하지 않음\n# 전반적으로 판별하려는 나뭇잎이 전체 이미지의 중앙에 있으므로, scale등의 적용을 고려\n\nimport albumentations as A\n\n\naugmentor_01 = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n    A.Blur(p=0.2)\n])\n\n# Apply augmentor_01 to rust images\nshow_grid_images(rust_image_list, augmentor=None, ncols=6, title='original rust')\nshow_grid_images(rust_image_list, augmentor=augmentor_01, ncols=6, title='augmented rust')\n\n# Apply augmentor_01 to scab images\nshow_grid_images(scab_image_list, augmentor=None, ncols=6, title='original scab')\nshow_grid_images(scab_image_list, augmentor=augmentor_01, ncols=6, title='augmented scab')","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:40:51.142422Z","iopub.execute_input":"2022-03-15T11:40:51.142734Z","iopub.status.idle":"2022-03-15T11:41:02.561234Z","shell.execute_reply.started":"2022-03-15T11:40:51.142679Z","shell.execute_reply":"2022-03-15T11:41:02.560609Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Sequence 기반의 Dataset 생성\n\n# image size의 높이와 너비가 다를 수 있을 경우를 고려하여, image_size를 튜플로 입력\n# opencv의 resize()는 인자로 이미지 크기를 입력 받는데, 가로 x 세로 (너비 x 높이)의 개념으로 입력\n# image array의 경우에는 행 x 열 (높이 x 너비)이므로 resize() 호출 시 이를 감안해야 함.\n# kaggle competition의 test data의 결과를 submit 하므로 test data의 label이 없음\n# 따라서, Dataset의 label_batch 값이 None이 될 수 있는 경우를 감안하여 코드 재수정 필요\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import Sequence\nimport sklearn\nimport cv2\n\n\nclass Plant_Dataset(Sequence):\n    def __init__(self, image_filenames, labels, image_size=(224, 224),\n                batch_size=64, augmentor=None, shuffle=False, pre_func=None):\n        '''\n        :parameters\n        image_filenames: opencv로 image를 로드할 파일의 절대 경로\n        labels: 해당 image의 label\n        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n        augmentor: albumentations 객체\n        shuffle: 학습 데이터의 경우 epoch 종료 시 마다 데이터를 섞을 지 여부\n        '''\n        \n        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당\n        self.image_filenames = image_filenames\n        self.labels = labels\n        self.image_size = image_size\n        self.batch_size = batch_size\n        self.augmentor = augmentor\n        self.pre_func = pre_func\n        self.shuffle = shuffle\n        \n        # train_data의 경우, 객체 생성 시 한번 데이터를 shuffle\n        if self.shuffle:\n            # self.on_epoch_end()\n            pass\n        \n    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리\n\n    # __len__()은 전체 데이터 건수가 주어졌을 때, batch_size 단위로 몇 번 데이터를 반환하는지\n    def __len__(self):\n        # batch_size 단위로 데이터를 몇 번 가져와야하는지 계산하기 위해\n        # 전체 데이터 건수를 batch_size로 나눈다.\n        # 정수로 정확히 나눠지지 않을 경우, 1회를 더해준다.\n        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n\n    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환\n    # 인자로 몇 번째 batch 인지 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만틈의\n    # 데이터를 가공하여 반환한다.\n    # -> batch_size 개수 만큼 변환된 image_array와 label_array 반환\n    def __getitem__(self, index):\n        '''\n        :parameters\n        index: 몇 번째 batch 인지 나타냄\n        '''\n\n        # batch_size 만큼 순차적으로 데이터를 가져오기 위해서 array에서\n        # index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져온다.\n        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n\n        if self.labels is not None:\n            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n\n        # label_batch가 None이 될 수 있음\n        else:\n            label_batch = None\n\n        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n        # image_batch 배열은 float32로 설정\n        image_batch = np.zeros(\n            (image_name_batch.shape[0], self.image_size[0], self.image_size[1], 3),\n            dtype='float32'\n        )\n\n        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load\n        # -> image augmentation 변환 (augmentor가 not None일 경우)\n        # -> image_batch에 담음\n        for image_index in range(image_name_batch.shape[0]):\n            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n            if self.augmentor is not None:\n                image = self.augmentor(image=image)['image']\n            # 원본 이미지와 다르게 resize 적용\n            # opencv의 resize는 (가로, 세로)의 개념\n            # 배열(array)은 (높이;행, 너비;열)의 개념이므로 이에 주의하여 opencv resize 인자를 입력 필요\n            image = cv2.resize(image, (self.image_size[1], self.image_size[0]))\n            # 만일 preprocessing_input이 pre_func 인자로 들어오면 이를 이용하여 scaling 적용\n            if self.pre_func is not None:\n                image = self.pre_func(image)\n\n            image_batch[image_index] = image\n\n        return image_batch, label_batch\n    \n    # epoch가 한 번 수행이 완료 될 때, 모델의 fit()에서 호출\n    def on_epoch_end(self):\n        if (self.shuffle):\n            # 전체 image 파일의 위치와 label의 쌍을 맞춰서 섞어준다.\n            # sklearn의 utils.shuffle에서 해당 기능을 제공\n            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n        else:\n            pass","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:41:33.936240Z","iopub.execute_input":"2022-03-15T11:41:33.936491Z","iopub.status.idle":"2022-03-15T11:41:33.951736Z","shell.execute_reply.started":"2022-03-15T11:41:33.936462Z","shell.execute_reply":"2022-03-15T11:41:33.951012Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# 학습 데이터용 DataFrame에서 학습용/검증용 이미지 절대 경로와 Label 추출하고 이를 Dataset으로 생성\n\n# 이미 학습용 DataFrame에 'healthy', 'multiple_disseases', 'rust', 'scab' 순으로 one-hot encoding 되어 있음\n# kaggle에서 테스트 데이터의 예측 겨과를 'healthy', 'multiple_diseases', 'rust', 'scab' 순서로 제출을 요구하므로,\n# 이를 별도로 다시 one-hot encoding 해서는 안됨.\n# Augmentation은 앞에서 생성한 augmentor_01을 적용\n# pre_func는 xception용 Preprocessing 함수 적용","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:41:37.617513Z","iopub.execute_input":"2022-03-15T11:41:37.618172Z","iopub.status.idle":"2022-03-15T11:41:37.621929Z","shell.execute_reply.started":"2022-03-15T11:41:37.618132Z","shell.execute_reply":"2022-03-15T11:41:37.621125Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\nsample_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:41:38.296174Z","iopub.execute_input":"2022-03-15T11:41:38.296486Z","iopub.status.idle":"2022-03-15T11:41:38.328267Z","shell.execute_reply.started":"2022-03-15T11:41:38.296450Z","shell.execute_reply":"2022-03-15T11:41:38.327613Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\ndef get_train_valid(train_df, valid_size=0.2, random_state=2021):\n    \n    train_path = train_df['path'].values\n    \n    # 별도의 one-hot encoding을 하지 않고\n    # 'healthy', 'multiple_diseases', 'rust', 'scab' 컬럼들을 모두 \n    # Numpy array로 변환하는 수준으로 label을 one-hot encoding 적용\n    train_label = train_df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n    \n    tr_path, val_path, tr_label, val_label = train_test_split(\n                                                train_path,\n                                                train_label,\n                                                test_size=valid_size,\n                                                random_state=random_state\n                                            )\n    \n    print('tr_path shape: ', tr_path.shape)\n    print('tr_label shape: ', tr_label.shape)\n    print('val_path shape: ', val_path.shape)\n    print('val_label shape: ', val_label.shape)\n    \n    return tr_path, val_path, tr_label, val_label\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:41:40.434476Z","iopub.execute_input":"2022-03-15T11:41:40.434763Z","iopub.status.idle":"2022-03-15T11:41:40.441427Z","shell.execute_reply.started":"2022-03-15T11:41:40.434728Z","shell.execute_reply":"2022-03-15T11:41:40.440691Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n\n\n# image size는 224 x 224로 Dataset 생성\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 64\n\ntr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state = 2021)\n\ntr_ds = Plant_Dataset(\n    tr_path,\n    tr_label,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    augmentor=augmentor_01, shuffle=True,\n    pre_func=xcp_preprocess_input\n)\n\nval_ds = Plant_Dataset(\n    val_path,\n    val_label,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    augmentor=None,\n    shuffle=False,\n    pre_func=xcp_preprocess_input\n)\n\ntr_image_batch, tr_label_batch = next(iter(tr_ds))\nval_image_batch, val_label_batch = next(iter(val_ds))\n\nprint('tr_image_batch shape: ', tr_image_batch.shape)\nprint('val_image_batch shape: ', val_image_batch.shape)\nprint('tr_label_batch shape: ', tr_label_batch.shape)\nprint('val_label_batch shape: ', val_label_batch.shape)\nprint()\nprint(tr_image_batch[0], val_image_batch[0])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:41:44.561400Z","iopub.execute_input":"2022-03-15T11:41:44.561656Z","iopub.status.idle":"2022-03-15T11:41:49.512776Z","shell.execute_reply.started":"2022-03-15T11:41:44.561627Z","shell.execute_reply":"2022-03-15T11:41:49.511781Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# create_model() 함수 생성\n\n# resnet50v2, xception, efficientnetb0~b7 등의 Pretrained 모델을 생성\nfrom tensorflow.keras.models import Sequential , Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\nfrom tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\nfrom tensorflow.keras.applications import EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\nimport tensorflow as tf\n\ndef create_model(model_type='efficientnetb0', in_shape=(224, 224, 3), n_classes=4):\n    input_tensor = Input(shape=in_shape)\n    \n    if model_type == 'resnet50v2':\n        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'xception':\n        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb0':\n        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb1':\n        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb2':\n        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb3':\n        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb4':\n        base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb5':\n        base_model = tf.keras.applications.EfficientNetB5(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb6':\n        base_model = tf.keras.applications.EfficientNetB6(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb7':\n        base_model = tf.keras.applications.EfficientNetB7(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    preds = Dense(units=n_classes, activation='softmax')(x)\n    model = Model(inputs=input_tensor, outputs=preds)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:41:59.812228Z","iopub.execute_input":"2022-03-15T11:41:59.812481Z","iopub.status.idle":"2022-03-15T11:41:59.828453Z","shell.execute_reply.started":"2022-03-15T11:41:59.812452Z","shell.execute_reply":"2022-03-15T11:41:59.827772Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# xception model create and train\n\n# - inmage size = (224, 224, 4)\n# - Learning Rate Scheduler: ReduceLROnPlateau -> Learning Rate: 0.0001\n# - epochs: 10\n# - metrics: ROC-AUC\n\nfrom tensorflow.keras.metrics import AUC\n\nxcp_model_01 = create_model(model_type='xception', in_shape=(224, 224, 3))\nxcp_model_01.compile(\n    optimizer=Adam(lr=0.0001),\n    loss='categorical_crossentropy',\n    metrics=[AUC()]\n)\n\n# 3번의 iteration 내에 validation loss가 향상되지 않으면 learning rate를 기존 learning rate * 0.2로 감소\nrlr_cb = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,\n    patience=3,\n    mode='min',\n    verbose=1\n)\n\n# 10번의 iteration 내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\nely_cb = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    mode='min',\n    verbose=1\n)\n\nhistory = xcp_model_01.fit(\n    tr_ds,\n    epochs=10,\n    steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)),\n    validation_data=val_ds,\n    validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n    callbacks=([rlr_cb, ely_cb]),\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:42:03.683234Z","iopub.execute_input":"2022-03-15T11:42:03.683813Z","iopub.status.idle":"2022-03-15T11:57:43.815001Z","shell.execute_reply.started":"2022-03-15T11:42:03.683777Z","shell.execute_reply":"2022-03-15T11:57:43.814120Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# 테스트 데이터로 Plant의 질병을 예측하고 Kaggle에 제출할 submit.csv 파일 만들기\n\n# - 테스트용 DataFrame에 이미지 경로 추가\n# - 테스트용 Dataset 생성. label은 테스트 데이터에서 알 수 없으므로 None으로 입력\n\nsample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\nsample_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:59:06.003177Z","iopub.execute_input":"2022-03-15T11:59:06.003440Z","iopub.status.idle":"2022-03-15T11:59:06.026560Z","shell.execute_reply.started":"2022-03-15T11:59:06.003413Z","shell.execute_reply":"2022-03-15T11:59:06.025766Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"IMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\n# test_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\ntest_df['path'] = IMAGE_DIR + \"/\" + test_df['image_id'] + '.jpg'\n\ntest_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:59:20.464126Z","iopub.execute_input":"2022-03-15T11:59:20.464393Z","iopub.status.idle":"2022-03-15T11:59:20.479448Z","shell.execute_reply.started":"2022-03-15T11:59:20.464367Z","shell.execute_reply":"2022-03-15T11:59:20.478770Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# 테스트용 Dataset을 생성하고, 이를 이용하여 model의 predict()를 호출하여 이미지 예측을 수행\n\ntest_path = test_df['path'].values\n\n# labels는 None을 입력하고 Dataset을 생성\ntest_ds = Plant_Dataset(\n    image_filenames=test_path,\n    labels=None,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    augmentor=None,\n    shuffle=False,\n    pre_func=xcp_preprocess_input\n)\n\n# predict()로 예측 수행\npreds = xcp_model_01.predict(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T12:02:38.033311Z","iopub.execute_input":"2022-03-15T12:02:38.033952Z","iopub.status.idle":"2022-03-15T12:03:53.498605Z","shell.execute_reply.started":"2022-03-15T12:02:38.033915Z","shell.execute_reply":"2022-03-15T12:03:53.497841Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"preds # numpy array","metadata":{"execution":{"iopub.status.busy":"2022-03-15T12:05:01.148877Z","iopub.execute_input":"2022-03-15T12:05:01.149182Z","iopub.status.idle":"2022-03-15T12:05:01.156426Z","shell.execute_reply.started":"2022-03-15T12:05:01.149150Z","shell.execute_reply":"2022-03-15T12:05:01.155569Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성\n\npreds_df = pd.DataFrame(preds)\npreds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n\n# 테스트용 DataFrame에 바로 위에서 생성한 결과 DataFrame을 합친 뒤 이를 이용하여 submit용 DataFrame 생성\nsubmit_df = pd.concat([test_df['image_id'], preds_df], axis=1)\nsubmit_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T12:08:58.220626Z","iopub.execute_input":"2022-03-15T12:08:58.221290Z","iopub.status.idle":"2022-03-15T12:08:58.237869Z","shell.execute_reply.started":"2022-03-15T12:08:58.221253Z","shell.execute_reply":"2022-03-15T12:08:58.237100Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# kaggle 제출용 csv 생성 후, kaggle에 제출 및 테스트 성능 확인\n\nsubmit_df.to_csv('submit_01.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T12:11:45.012606Z","iopub.execute_input":"2022-03-15T12:11:45.013468Z","iopub.status.idle":"2022-03-15T12:11:45.036353Z","shell.execute_reply.started":"2022-03-15T12:11:45.013413Z","shell.execute_reply":"2022-03-15T12:11:45.035687Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Image 사이즈를 변경하여 재학습 수행\n\n# - xception 모델을 사용하되, 원본 이미지(1365, 2048)의 ratio를 어느정도 유지하면서 변경\n# - 이미지 사이즈를 320, 512로 변경\n\nfrom tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n\nIMAGE_SIZE = (320, 512)\nBATCH_SIZE = 64\n\ntr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n\ntr_ds = Plant_Dataset(\n    tr_path,\n    tr_label,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    augmentor=augmentor_01,\n    shuffle=True,\n    pre_func=xcp_preprocess_input\n)\n\nval_ds = Plant_Dataset(\n    val_path,\n    val_label,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    augmentor=None,\n    shuffle=False,\n    pre_func=xcp_preprocess_input\n)\n\ntr_image_batch, tr_label_batch = next(iter(tr_ds))\nval_image_batch, val_label_batch = next(iter(val_ds))\n\nprint(\"train_image_batch shape: \", tr_image_batch.shape)\nprint(\"val_image_batch shape: \", val_image_batch.shape)\nprint(\"tr_label_batch shape: \", tr_label_batch.shape)\nprint(\"val_label_batch shape: \", val_label_batch.shape)\nprint(tr_image_batch[0])\nprint(val_image_batch[0])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T12:35:26.511797Z","iopub.execute_input":"2022-03-15T12:35:26.512442Z","iopub.status.idle":"2022-03-15T12:35:31.525145Z","shell.execute_reply.started":"2022-03-15T12:35:26.512408Z","shell.execute_reply":"2022-03-15T12:35:31.524297Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Config를 이용하여 학습 수행\n\n# - 모델은 xception, image size는 (320, 512)\n# - 초기 LR은 0.0001 -> LR Scheduler는 Ramp up and Step decay\n# - epochs 10\n# - not fine tuning\n# - augmentor -> augmentor_01\n\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\nfrom tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nimport tensorflow as tf\n\n# learning rate scheduler에 적용할 함수 선언\ndef lrfn_01(epoch):\n    LR_START = 1e-5\n    LR_MAX = 1e-4\n    LR_RAMPUP_EPOCHS = 2\n    LR_SUSTAIN_EPOCHS = 1\n    LR_STEP_DECAY = 0.75\n    \n    def calc_fn(epoch):\n        if epoch < LR_RAMPUP_EPOCHS:\n            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n            lr = LR_MAX\n        else:\n            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n        return lr\n    \n    return calc_fn(epoch)\n\ndef lrfn_02(epoch):\n    LR_START = 1e-6\n    LR_MAX = 2e-5\n    LR_RAMPUP_EPOCHS = 2\n    LR_SUSTAIN_EPOCHS = 1\n    LR_STEP_DECAY = 0.75\n    \n    def calc_fn(epoch):\n        if epoch < LR_RAMPUP_EPOCHS:\n            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n            lr = LR_MAX\n        else:\n            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n        return lr\n    \n    return calc_fn(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:12:41.159746Z","iopub.execute_input":"2022-03-15T13:12:41.160542Z","iopub.status.idle":"2022-03-15T13:12:41.174403Z","shell.execute_reply.started":"2022-03-15T13:12:41.160496Z","shell.execute_reply":"2022-03-15T13:12:41.173593Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# Config에 입력할 callback 생성\nlr01_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_01, verbose=1)\nlr02_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_02, verbose=1)\nrlr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\nely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n\n# Augmentor 생성\naugmentor_01 = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n    A.Blur(p=0.2)\n])\n\n# Config 생성\nclass Config:\n    MODEL_TYPE = 'xception'\n    IMAGE_SIZE = (320, 512)\n    BATCH_SIZE = 32 # 이미지 사이즈가 커졌기 때문에, 메모리 이슈로 32로 감소\n    N_EPOCHS = 10 # fine tuning을 수행하지 않을 경우, 전체 수행 epoch 횟수 설정\n    IS_FINE_TUNING = False\n    FIRST_EPOCHS = 15 # fine tuning 일 경우, 첫 번째 epoch 횟수\n    SECOND_EPOCHS = 15 # fine tuning일 경우, 두 번째 epoch 횟수\n    FIRST_CALLBACKS = [lr01_cb, ely_cb] # 모델 train 시, 적용될 callback 객체 리스트\n    SECOND_CALLBACKS = [lr02_cb, ely_cb] # 만일 Fine tuning 시 첫 번째 학습과 두 번째 학습의 Learning rate scheduler가 서로 다를 경우 사용\n    AUGMENTOR = augmentor_01\n    PRE_FUNC = xcp_preprocess_input\n    INITIAL_LR = 0.0001\n    DEBUG = True","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:12:41.611408Z","iopub.execute_input":"2022-03-15T13:12:41.611970Z","iopub.status.idle":"2022-03-15T13:12:41.621072Z","shell.execute_reply.started":"2022-03-15T13:12:41.611933Z","shell.execute_reply":"2022-03-15T13:12:41.620141Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def train_model(train_df, config=Config):\n    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n    \n    tr_ds = Plant_Dataset(tr_path, tr_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n    val_ds = Plant_Dataset(val_path, val_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n                          augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n    \n    if config.DEBUG:\n        tr_image_batch = next(iter(tr_ds))[0]\n        val_image_batch = next(iter(val_ds))[0]\n        print(\"train_image_batch shape: \", tr_image_batch.shape)\n        print(\"validation_image_batch shape: \", val_image_batch.shape)\n        print(tr_image_batch[0])\n        print(val_image_batch[0])\n\n    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE[0], config.IMAGE_SIZE[1],3), n_classes=4)\n    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=[AUC()])\n\n    # 만일 Fine tuning일 경우, 아래 로직 적용\n    if config.IS_FINE_TUNING:\n        print(\"########## Fine tuning 학습 시작 ##########\")\n        # 첫 번째 Fine Tuning\n        # Feature Extractor를 제외한 classification layer를 학습.\n        # Feature Extractor layer들을 trainable=False\n        for layer in model.layers[:-4]:\n            layer.trainable = False\n            \n            print(\"############ Classification Layer들의 학습 시작 #############\")\n            history = model.fit(\n                    tr_ds,\n                    epochs=config.FIRST_EPOCHS,\n                    steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)),\n                    validation_data=val_ds,\n                    validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n                    callbacks=(config.FIRST_CALLBACKS),\n                    verbose=1\n                )\n            \n        # 두 번째, 전체 Layer를 학습\n        # 전체 layer를 trainable=True로 수정\n        # 모델이 EfficientNet 계열일 경우 Batch Normalization layer는 학습 제외\n        for layer in model.layers:\n            if config.MODEL_TYPE in 'efficientnet':\n                if not isinstance(layer, layers.BatchNormalization):\n                    layer.trainable = True\n            else:\n                layer.trainable = True\n\n        print(\"############ 전체 Layer들의 학습을 시작 ############\")\n        history = model.fit(\n            tr_ds,\n            epochs=config.SECOND_EPOCHS,\n            steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)),\n            validation_data=val_ds,\n            validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n            callbacks=(config.SECOND_CALLBACKS),\n            verbose=1\n        )\n    \n    else:\n        print(\"############### 학습 시작 #################\")\n        history = model.fit(\n            tr_ds,\n            epochs=config.N_EPOCHS,\n            steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)),\n            validation_data=val_ds,\n            validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n            callbacks=(config.FIRST_CALLBACKS),\n            verbose=1\n        )\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:12:42.220085Z","iopub.execute_input":"2022-03-15T13:12:42.220334Z","iopub.status.idle":"2022-03-15T13:12:42.236234Z","shell.execute_reply.started":"2022-03-15T13:12:42.220305Z","shell.execute_reply":"2022-03-15T13:12:42.235382Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"xcp_model_02, history = train_model(train_df, config=Config)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:12:42.939805Z","iopub.execute_input":"2022-03-15T13:12:42.940301Z","iopub.status.idle":"2022-03-15T13:32:57.072593Z","shell.execute_reply.started":"2022-03-15T13:12:42.940266Z","shell.execute_reply":"2022-03-15T13:32:57.071856Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# 학습된 모델을 이용하여 테스트 이미지 예측 및 결과 제출\n\ndef make_submit_df(test_df, model, config=Config):\n    test_path = test_df['path'].values\n    # labels는 None을 입력하고 Dataset 생성\n    test_ds = Plant_Dataset(\n        image_filenames=test_path,\n        labels=None,\n        image_size=config.IMAGE_SIZE,\n        batch_size=config.BATCH_SIZE,\n        augmentor=None,\n        shuffle=False,\n        pre_func=config.PRE_FUNC\n    )\n    \n    # predict로 예측 수행\n    preds = model.predict(test_ds)\n    \n    # 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성\n    preds_df = pd.DataFrame(preds)\n    preds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n    \n    # 테스트용 DataFrame에 바로 위에서 생성한 결과 DataFrame을 합친 뒤, 이를 이용하여 submit용 DataFrame을 생성\n    submit_df = pd.concat([test_df['image_id'], preds_df], axis=1)\n    \n    return submit_df","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:39:18.479649Z","iopub.execute_input":"2022-03-15T13:39:18.480193Z","iopub.status.idle":"2022-03-15T13:39:18.486418Z","shell.execute_reply.started":"2022-03-15T13:39:18.480158Z","shell.execute_reply":"2022-03-15T13:39:18.485768Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"submit_df = make_submit_df(test_df, xcp_model_02, config=Config)\n\nsubmit_df.to_csv('submit_xcp_02.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T13:39:18.782673Z","iopub.execute_input":"2022-03-15T13:39:18.783325Z","iopub.status.idle":"2022-03-15T13:40:27.787260Z","shell.execute_reply.started":"2022-03-15T13:39:18.783288Z","shell.execute_reply":"2022-03-15T13:40:27.786555Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}